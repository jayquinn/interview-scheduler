#!/usr/bin/env python3
"""
ìŠ¤ì¼€ì¤„ ë°ì´í„° ë¬¸ì œ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
group_sizeì™€ ì¤‘ë³µ ID ë¬¸ì œì˜ ì›ì¸ì„ íŒŒì•…í•©ë‹ˆë‹¤.
"""

import pandas as pd
import sys

def analyze_schedule_data():
    """í…ŒìŠ¤íŠ¸ ê²°ê³¼ì—ì„œ ë‚˜ì˜¨ ìŠ¤ì¼€ì¤„ ë°ì´í„°ë¥¼ ì¬ì‹¤í–‰í•˜ì—¬ ë¶„ì„"""
    
    try:
        # í…ŒìŠ¤íŠ¸ ì¬ì‹¤í–‰
        from test_app_default_data import create_app_default_data, test_config_building
        from solver.api import solve_for_days_v2
        
        print("ğŸ”§ ë””í´íŠ¸ ë°ì´í„°ë¡œ ì¬ì‹¤í–‰...")
        session_state = create_app_default_data()
        
        # Config ë¹Œë“œ
        import core
        cfg = core.build_config(session_state)
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰
        params = {
            "min_gap_min": 5,
            "time_limit_sec": 30,
            "max_stay_hours": 5,
            "group_min_size": 4,
            "group_max_size": 6
        }
        
        status, result_df, logs, limit = solve_for_days_v2(cfg, params, debug=True)
        
        if status != "SUCCESS" or result_df is None or result_df.empty:
            print("âŒ ìŠ¤ì¼€ì¤„ë§ ì‹¤íŒ¨")
            return
        
        print("âœ… ìŠ¤ì¼€ì¤„ë§ ì„±ê³µ: {}ê°œ í•­ëª©".format(len(result_df)))
        
        # ï¿½ï¿½ ì¶”ê°€: ê·¸ë£¹ ìƒì„± ê³¼ì • ìƒì„¸ ë¶„ì„ (TODO: ë³€ìˆ˜ëª… ìˆ˜ì • í•„ìš”)
        # print("\n" + "="*60)
        # print("ğŸ“Š ê·¸ë£¹ ìƒì„± ê³¼ì • ìƒì„¸ ë¶„ì„")
        # print("="*60)
        # 
        # # Level2 ê²°ê³¼ì—ì„œ ê·¸ë£¹ ì •ë³´ ì¶”ì¶œ
        # if hasattr(result, 'results') and result.results:
        #     for date, single_result in result.results.items():
        #         if hasattr(single_result, 'level2_result') and single_result.level2_result:
        #             level2_result = single_result.level2_result
        #             print(f"\nğŸ“… ë‚ ì§œ: {date.strftime('%Y-%m-%d')}")
        #             print(f"ê·¸ë£¹ ê²°ê³¼ ìˆ˜: {len(level2_result.group_results)}")
        #             
        #             for i, group_result in enumerate(level2_result.group_results):
        #                 print(f"\nğŸ¯ í™œë™ {i+1}: {group_result.activity_name}")
        #                 print(f"  - ë°°ì • ìˆ˜: {len(group_result.assignments)}")
        #                 
        #                 for j, assignment in enumerate(group_result.assignments):
        #                     print(f"  - ê·¸ë£¹ {j+1}: {assignment.group.id}")
        #                     print(f"    * ê·¸ë£¹ í¬ê¸°: {assignment.group.size}")
        #                     print(f"    * ì‹¤ì œ ì§€ì›ì ìˆ˜: {len(assignment.group.applicants)}")
        #                     print(f"    * ë”ë¯¸ ID: {getattr(assignment.group, 'dummy_ids', [])}")
        #                     print(f"    * ë°©: {assignment.room.name}")
        #                     print(f"    * ì‹œê°„: {assignment.start_time} ~ {assignment.end_time}")
        #                     
        #                     # ê° ì§€ì›ì ì •ë³´
        #                     for k, applicant in enumerate(assignment.group.applicants):
        #                         print(f"      - ì§€ì›ì {k+1}: {applicant.id} ({applicant.job_code})")
        
        # ì›ë³¸ ë°ì´í„° ë¶„ì„
        print("\n" + "="*60)
        print("ğŸ“Š ì›ë³¸ ìŠ¤ì¼€ì¤„ ë°ì´í„° ë¶„ì„")
        print("="*60)
        
        print(f"ì´ í•­ëª© ìˆ˜: {len(result_df)}")
        print(f"ì»¬ëŸ¼: {list(result_df.columns)}")
        print()
        
        # ì§€ì›ìë³„ ë¶„ì„
        print("ğŸ‘¥ ì§€ì›ìë³„ ë¶„ì„:")
        applicant_counts = result_df['applicant_id'].value_counts()
        print(f"  - ì´ ì§€ì›ì: {len(applicant_counts)}ëª…")
        print(f"  - ì§€ì›ìë³„ í•­ëª© ìˆ˜: {applicant_counts.values}")
        print()
        
        # í™œë™ë³„ ë¶„ì„
        print("ğŸ¯ í™œë™ë³„ ë¶„ì„:")
        activity_counts = result_df['activity_name'].value_counts()
        for activity, count in activity_counts.items():
            print(f"  - {activity}: {count}ê°œ í•­ëª©")
        print()
        
        # ë°©ë³„ ë¶„ì„
        print("ğŸ  ë°©ë³„ ë¶„ì„:")
        room_counts = result_df['room_name'].value_counts()
        for room, count in room_counts.items():
            print(f"  - {room}: {count}ê°œ í•­ëª©")
        print()
        
        # ì‹œê°„ë³„ ë¶„ì„
        print("â° ì‹œê°„ë³„ ë¶„ì„:")
        time_counts = result_df['start_time'].value_counts().sort_index()
        for start_time, count in time_counts.items():
            print(f"  - {start_time}: {count}ê°œ í•­ëª©")
        print()
        
        # ê·¸ë£¹í•‘ í‚¤ ë¶„ì„ (ì—‘ì…€ ë³€í™˜ì—ì„œ ì‚¬ìš©ë˜ëŠ” ë°©ì‹)
        print("ğŸ”‘ ê·¸ë£¹í•‘ í‚¤ ë¶„ì„ (ì—‘ì…€ ë³€í™˜ ë°©ì‹):")
        result_df['group_key'] = (
            result_df['interview_date'].astype(str) + "_" +
            result_df['activity_name'] + "_" +
            result_df['room_name'] + "_" +
            result_df['start_time'].astype(str)
        )
        
        group_key_counts = result_df['group_key'].value_counts()
        print(f"ìœ ë‹ˆí¬ ê·¸ë£¹ í‚¤: {len(group_key_counts)}ê°œ")
        print("ê·¸ë£¹ë³„ í•­ëª© ìˆ˜:")
        for key, count in group_key_counts.head(10).items():
            print(f"  - {key}: {count}ê°œ")
        
        if len(group_key_counts) > 10:
            print(f"  ... ë° {len(group_key_counts) - 10}ê°œ ë”")
        print()
        
        # ì‹œê°„ ì¤‘ë³µ í™•ì¸
        print("ğŸ” ì‹œê°„ ì¤‘ë³µ í™•ì¸:")
        duplicates = result_df.groupby(['applicant_id', 'start_time', 'end_time']).size()
        duplicates = duplicates[duplicates > 1]
        if len(duplicates) > 0:
            print(f"âŒ ì‹œê°„ ì¤‘ë³µ ë°œê²¬: {len(duplicates)}ê±´")
            for (applicant, start, end), count in duplicates.items():
                print(f"  - {applicant}: {start}~{end} ({count}ê°œ ì¤‘ë³µ)")
        else:
            print("âœ… ì‹œê°„ ì¤‘ë³µ ì—†ìŒ")
        print()
        
        # í™œë™ ì¢…ë¥˜ë³„ ì„¸ë¶€ ë¶„ì„
        print("ğŸ“ˆ í™œë™ë³„ ì„¸ë¶€ ë¶„ì„:")
        for activity in result_df['activity_name'].unique():
            activity_df = result_df[result_df['activity_name'] == activity]
            
            print(f"\n{activity}:")
            print(f"  - ì´ í•­ëª©: {len(activity_df)}ê°œ")
            print(f"  - ì§€ì›ì ìˆ˜: {activity_df['applicant_id'].nunique()}ëª…")
            print(f"  - ë°© ìˆ˜: {activity_df['room_name'].nunique()}ê°œ")
            print(f"  - ì‹œê°„ ìŠ¬ë¡¯ ìˆ˜: {activity_df['start_time'].nunique()}ê°œ")
            
            # ë°©ë³„ ì‹œê°„ë³„ ë¶„í¬
            room_time_groups = activity_df.groupby(['room_name', 'start_time']).size()
            print(f"  - ë°©ë³„/ì‹œê°„ë³„ ê·¸ë£¹:")
            for (room, start_time), count in room_time_groups.items():
                print(f"    * {room} {start_time}: {count}ëª…")
        
        # ì˜ˆìƒ group_size ê³„ì‚°
        print("\n" + "="*60)
        print("ğŸ“Š ì˜ˆìƒ group_size ë¶„ì„")
        print("="*60)
        
        expected_groups = result_df.groupby(['interview_date', 'activity_name', 'room_name', 'start_time']).size()
        print("ë‚ ì§œ/í™œë™/ë°©/ì‹œê°„ë³„ ì˜ˆìƒ ê·¸ë£¹ í¬ê¸°:")
        for (date, activity, room, start_time), size in expected_groups.items():
            print(f"  - {date} {activity} {room} {start_time}: {size}ëª…")
        
        return result_df
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    print("ìŠ¤ì¼€ì¤„ ë°ì´í„° ë¬¸ì œ ë¶„ì„ ì‹œì‘...")
    result = analyze_schedule_data()
    if result is not None:
        print("\nâœ… ë¶„ì„ ì™„ë£Œ!")
    else:
        print("\nâŒ ë¶„ì„ ì‹¤íŒ¨!") 