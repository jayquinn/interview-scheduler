#!/usr/bin/env python3
"""
ì‹¤ì œ UI ë””í´íŠ¸ ë°ì´í„°ì˜ ì²´ë¥˜ì‹œê°„ ë¶„ì„ (Float ì‹œê°„ í˜•ì‹ ì§€ì›)
ì €ì¥ëœ ìŠ¤ì¼€ì¤„ ê²°ê³¼ë¥¼ ì½ì–´ì„œ ì²´ë¥˜ì‹œê°„ íŒ¨í„´ì„ ë¶„ì„í•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import traceback

def load_schedule_result():
    """ì €ì¥ëœ ìŠ¤ì¼€ì¤„ ê²°ê³¼ ë¡œë“œ"""
    try:
        df = pd.read_excel("complete_ui_defaults_test_result.xlsx")
        print(f"âœ… ìŠ¤ì¼€ì¤„ ê²°ê³¼ ë¡œë“œ: {len(df)}ê°œ í•­ëª©")
        print(f"ì»¬ëŸ¼: {list(df.columns)}")
        return df
    except Exception as e:
        print(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def calculate_stay_duration_analysis(schedule_df):
    """ì²´ë¥˜ì‹œê°„ ë¶„ì„ (Float ì‹œê°„ í˜•ì‹ ì§€ì›)"""
    stats_data = []
    
    # ì»¬ëŸ¼ëª… í™•ì¸
    id_col = 'applicant_id'
    job_col = 'job_code' 
    date_col = 'interview_date'
    
    print(f"âœ… ë¶„ì„ ì»¬ëŸ¼: ID={id_col}, JOB={job_col}, DATE={date_col}")
    
    # ì§€ì›ìë³„ ì²´ë¥˜ì‹œê°„ ê³„ì‚°
    for candidate_id, candidate_data in schedule_df.groupby(id_col):
        if len(candidate_data) == 0:
            continue
            
        # í•´ë‹¹ ì§€ì›ìì˜ ëª¨ë“  ì‹œê°„ ì •ë³´ ìˆ˜ì§‘
        all_times = []
        
        for _, row in candidate_data.iterrows():
            # start_timeê³¼ end_timeì—ì„œ ì‹œê°„ ì •ë³´ ì¶”ì¶œ
            start_time = row.get('start_time')
            end_time = row.get('end_time')
            
            if pd.notna(start_time):
                try:
                    # float í˜•íƒœ ì‹œê°„ ì²˜ë¦¬ (í•˜ë£¨ì˜ ë¹„ìœ¨: 0.375 = 9:00)
                    if isinstance(start_time, (float, int)):
                        minutes = start_time * 24 * 60  # í•˜ë£¨ ë¹„ìœ¨ â†’ ë¶„ ë‹¨ìœ„
                        all_times.append(minutes)
                except:
                    continue
            
            if pd.notna(end_time):
                try:
                    # float í˜•íƒœ ì‹œê°„ ì²˜ë¦¬ (í•˜ë£¨ì˜ ë¹„ìœ¨: 0.375 = 9:00)
                    if isinstance(end_time, (float, int)):
                        minutes = end_time * 24 * 60  # í•˜ë£¨ ë¹„ìœ¨ â†’ ë¶„ ë‹¨ìœ„
                        all_times.append(minutes)
                except:
                    continue
        
        if len(all_times) >= 2:  # ìµœì†Œ ì‹œì‘/ì¢…ë£Œ ì‹œê°„ì´ ìˆì–´ì•¼ í•¨
            # ì²´ë¥˜ì‹œê°„ = ìµœëŒ€ ì‹œê°„ - ìµœì†Œ ì‹œê°„
            stay_duration_minutes = max(all_times) - min(all_times)
            
            # ë©”íƒ€ ì •ë³´ ì¶”ì¶œ
            job_code = candidate_data.iloc[0].get(job_col, 'Unknown')
            interview_date = candidate_data.iloc[0].get(date_col, 'Unknown')
            
            # ì‹œê°„ ë³€í™˜ (ë¶„ â†’ ì‹œ:ë¶„ í˜•ì‹)
            def minutes_to_time_str(minutes):
                hours = int(minutes // 60)
                mins = int(minutes % 60)
                return f"{hours:02d}:{mins:02d}"
            
            stats_data.append({
                'candidate_id': candidate_id,
                'job_code': job_code,
                'interview_date': interview_date,
                'stay_duration_minutes': stay_duration_minutes,
                'start_time_minutes': min(all_times),
                'end_time_minutes': max(all_times),
                'start_time_str': minutes_to_time_str(min(all_times)),
                'end_time_str': minutes_to_time_str(max(all_times)),
                'num_activities': len(candidate_data)
            })
    
    if not stats_data:
        print("âŒ ì²´ë¥˜ì‹œê°„ì„ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    
    stats_df = pd.DataFrame(stats_data)
    
    # ì§ë¬´ë³„ í†µê³„ ê³„ì‚°
    job_stats = []
    for job_code, job_data in stats_df.groupby('job_code'):
        durations = job_data['stay_duration_minutes']
        job_stats.append({
            'job_code': job_code,
            'count': len(job_data),
            'min_duration': durations.min(),
            'max_duration': durations.max(),
            'avg_duration': durations.mean(),
            'median_duration': durations.median(),
            'std_duration': durations.std()
        })
    
    job_stats_df = pd.DataFrame(job_stats)
    
    return job_stats_df, stats_df

def analyze_problematic_cases(individual_stats_df, threshold_hours=4):
    """ë¬¸ì œê°€ ë˜ëŠ” ì¥ì‹œê°„ ì²´ë¥˜ ì¼€ì´ìŠ¤ ë¶„ì„"""
    threshold_minutes = threshold_hours * 60
    
    problematic = individual_stats_df[individual_stats_df['stay_duration_minutes'] > threshold_minutes].copy()
    
    if len(problematic) == 0:
        print(f"âœ… {threshold_hours}ì‹œê°„ ì´ìƒ ì²´ë¥˜í•˜ëŠ” ì§€ì›ìê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    problematic['stay_duration_hours'] = problematic['stay_duration_minutes'] / 60
    problematic = problematic.sort_values('stay_duration_minutes', ascending=False)
    
    print(f"\nğŸš¨ {threshold_hours}ì‹œê°„ ì´ìƒ ì²´ë¥˜í•˜ëŠ” ì§€ì›ì: {len(problematic)}ëª…")
    print("ìƒìœ„ 10ëª…:")
    
    display_cols = ['candidate_id', 'job_code', 'interview_date', 'stay_duration_hours', 'start_time_str', 'end_time_str']
    print(problematic[display_cols].head(10).to_string(index=False))
    
    return problematic

def identify_optimization_opportunities(individual_stats_df, job_stats_df):
    """ìµœì í™” ê¸°íšŒ ì‹ë³„"""
    print("\nğŸ” ìµœì í™” ê¸°íšŒ ë¶„ì„")
    
    # 1. ì§ë¬´ë³„ ì²´ë¥˜ì‹œê°„ í¸ì°¨ ë¶„ì„
    print("\nğŸ“Š ì§ë¬´ë³„ ì²´ë¥˜ì‹œê°„ í¸ì°¨:")
    high_variance_jobs = job_stats_df[job_stats_df['std_duration'] > 30].sort_values('std_duration', ascending=False)
    
    if len(high_variance_jobs) > 0:
        print("í¸ì°¨ê°€ í° ì§ë¬´ë“¤ (30ë¶„ ì´ìƒ):")
        for _, row in high_variance_jobs.iterrows():
            print(f"  {row['job_code']}: í‰ê·  {row['avg_duration']:.1f}ë¶„, í¸ì°¨ {row['std_duration']:.1f}ë¶„ ({row['min_duration']:.1f}~{row['max_duration']:.1f}ë¶„)")
    else:
        print("í¸ì°¨ê°€ í° ì§ë¬´ê°€ ì—†ìŠµë‹ˆë‹¤ (ëª¨ë“  ì§ë¬´ê°€ 30ë¶„ ë¯¸ë§Œ í¸ì°¨)")
    
    # 2. ì‹œê°„ëŒ€ë³„ ë¶„í¬ ë¶„ì„
    print("\nâ° ì‹œê°„ëŒ€ë³„ ì‹œì‘/ì¢…ë£Œ ë¶„í¬:")
    start_times = individual_stats_df['start_time_minutes']
    end_times = individual_stats_df['end_time_minutes']
    
    print(f"ì‹œì‘ ì‹œê°„: {start_times.min()/60:.1f}ì‹œ ~ {start_times.max()/60:.1f}ì‹œ")
    print(f"ì¢…ë£Œ ì‹œê°„: {end_times.min()/60:.1f}ì‹œ ~ {end_times.max()/60:.1f}ì‹œ")
    
    # 3. ë‚ ì§œë³„ ì²´ë¥˜ì‹œê°„ ë¶„ì„
    if 'interview_date' in individual_stats_df.columns:
        print("\nğŸ“… ë‚ ì§œë³„ ì²´ë¥˜ì‹œê°„ ë¶„ì„:")
        date_stats = individual_stats_df.groupby('interview_date')['stay_duration_minutes'].agg(['count', 'mean', 'max', 'std']).round(1)
        print(date_stats.to_string())
    
    # 4. ê°œì„  ì œì•ˆ
    print("\nğŸ’¡ ê°œì„  ì œì•ˆ:")
    
    # ì¥ì‹œê°„ ì²´ë¥˜ì ë¹„ìœ¨
    long_stay_ratio = len(individual_stats_df[individual_stats_df['stay_duration_minutes'] > 300]) / len(individual_stats_df)
    print(f"  - 5ì‹œê°„ ì´ìƒ ì²´ë¥˜ì ë¹„ìœ¨: {long_stay_ratio:.1%}")
    
    # í‰ê·  ì²´ë¥˜ì‹œê°„
    avg_stay = individual_stats_df['stay_duration_minutes'].mean()
    print(f"  - ì „ì²´ í‰ê·  ì²´ë¥˜ì‹œê°„: {avg_stay:.1f}ë¶„ ({avg_stay/60:.1f}ì‹œê°„)")
    
    if avg_stay > 240:  # 4ì‹œê°„ ì´ìƒ
        print("  âš ï¸ í‰ê·  ì²´ë¥˜ì‹œê°„ì´ 4ì‹œê°„ì„ ì´ˆê³¼í•©ë‹ˆë‹¤. ìµœì í™” í•„ìš”!")
    elif avg_stay > 180:  # 3ì‹œê°„ ì´ìƒ
        print("  âš¡ í‰ê·  ì²´ë¥˜ì‹œê°„ì´ 3ì‹œê°„ì„ ì´ˆê³¼í•©ë‹ˆë‹¤. ìµœì í™” ê³ ë ¤ í•„ìš”")
    else:
        print("  âœ… í‰ê·  ì²´ë¥˜ì‹œê°„ì´ ì ë‹¹í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤")
    
    return {
        'high_variance_jobs': high_variance_jobs,
        'long_stay_ratio': long_stay_ratio,
        'avg_stay_minutes': avg_stay
    }

def analyze_time_gaps(individual_stats_df, schedule_df):
    """í™œë™ ê°„ ì‹œê°„ ê°„ê²© ë¶„ì„"""
    print("\nâ³ í™œë™ ê°„ ì‹œê°„ ê°„ê²© ë¶„ì„")
    
    gap_data = []
    
    for candidate_id in individual_stats_df['candidate_id']:
        candidate_activities = schedule_df[schedule_df['applicant_id'] == candidate_id].copy()
        
        if len(candidate_activities) > 1:
            # ì‹œì‘ ì‹œê°„ìœ¼ë¡œ ì •ë ¬
            candidate_activities['start_minutes'] = candidate_activities['start_time'] * 24 * 60
            candidate_activities['end_minutes'] = candidate_activities['end_time'] * 24 * 60
            candidate_activities = candidate_activities.sort_values('start_minutes')
            
            # ì—°ì†ëœ í™œë™ ê°„ ê°„ê²© ê³„ì‚°
            for i in range(len(candidate_activities) - 1):
                current_end = candidate_activities.iloc[i]['end_minutes']
                next_start = candidate_activities.iloc[i+1]['start_minutes']
                gap_minutes = next_start - current_end
                
                gap_data.append({
                    'candidate_id': candidate_id,
                    'gap_minutes': gap_minutes,
                    'activity_1': candidate_activities.iloc[i]['activity_name'],
                    'activity_2': candidate_activities.iloc[i+1]['activity_name']
                })
    
    if gap_data:
        gap_df = pd.DataFrame(gap_data)
        
        print(f"ì´ {len(gap_df)}ê°œì˜ í™œë™ ê°„ê²© ë°œê²¬")
        print(f"í‰ê·  ê°„ê²©: {gap_df['gap_minutes'].mean():.1f}ë¶„")
        print(f"ìµœì†Œ ê°„ê²©: {gap_df['gap_minutes'].min():.1f}ë¶„")
        print(f"ìµœëŒ€ ê°„ê²©: {gap_df['gap_minutes'].max():.1f}ë¶„")
        
        # ê¸´ ê°„ê²©ì´ ìˆëŠ” ì¼€ì´ìŠ¤
        long_gaps = gap_df[gap_df['gap_minutes'] > 60]
        if len(long_gaps) > 0:
            print(f"\nğŸš¨ 1ì‹œê°„ ì´ìƒ ê°„ê²©ì´ ìˆëŠ” ì¼€ì´ìŠ¤: {len(long_gaps)}ê°œ")
            print(long_gaps.head().to_string(index=False))
        
        return gap_df
    else:
        print("í™œë™ ê°„ê²©ì„ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

def main():
    """ë©”ì¸ ë¶„ì„ ì‹¤í–‰"""
    print("=" * 80)
    print("ğŸ” UI ë””í´íŠ¸ ë°ì´í„° ì²´ë¥˜ì‹œê°„ ë¶„ì„ (Float ì‹œê°„ í˜•ì‹)")
    print("=" * 80)
    
    # 1. ë°ì´í„° ë¡œë“œ
    schedule_df = load_schedule_result()
    if schedule_df is None:
        return
    
    # 2. ì²´ë¥˜ì‹œê°„ ë¶„ì„
    print("\nğŸ“Š ì²´ë¥˜ì‹œê°„ ë¶„ì„ ì¤‘...")
    job_stats_df, individual_stats_df = calculate_stay_duration_analysis(schedule_df)
    
    if job_stats_df is None:
        return
    
    # 3. ê¸°ë³¸ í†µê³„ ì¶œë ¥
    print(f"\nâœ… ë¶„ì„ ì™„ë£Œ: {len(individual_stats_df)}ëª… ì§€ì›ì")
    print("\nğŸ“‹ ì§ë¬´ë³„ ì²´ë¥˜ì‹œê°„ í†µê³„:")
    display_job_stats = job_stats_df.copy()
    for col in ['min_duration', 'max_duration', 'avg_duration', 'median_duration', 'std_duration']:
        display_job_stats[col] = display_job_stats[col].round(1)
    print(display_job_stats.to_string(index=False))
    
    # 4. ì „ì²´ ìš”ì•½ í†µê³„
    print(f"\nğŸ¯ ì „ì²´ ìš”ì•½:")
    total_min = individual_stats_df['stay_duration_minutes'].min()
    total_max = individual_stats_df['stay_duration_minutes'].max()
    total_avg = individual_stats_df['stay_duration_minutes'].mean()
    total_median = individual_stats_df['stay_duration_minutes'].median()
    
    print(f"  ìµœì†Œ ì²´ë¥˜ì‹œê°„: {total_min:.1f}ë¶„ ({total_min/60:.1f}ì‹œê°„)")
    print(f"  ìµœëŒ€ ì²´ë¥˜ì‹œê°„: {total_max:.1f}ë¶„ ({total_max/60:.1f}ì‹œê°„)")
    print(f"  í‰ê·  ì²´ë¥˜ì‹œê°„: {total_avg:.1f}ë¶„ ({total_avg/60:.1f}ì‹œê°„)")
    print(f"  ì¤‘ê°„ ì²´ë¥˜ì‹œê°„: {total_median:.1f}ë¶„ ({total_median/60:.1f}ì‹œê°„)")
    
    # 5. ë¬¸ì œ ì¼€ì´ìŠ¤ ë¶„ì„
    problematic = analyze_problematic_cases(individual_stats_df, threshold_hours=3)
    
    # 6. ìµœì í™” ê¸°íšŒ ì‹ë³„
    optimization_info = identify_optimization_opportunities(individual_stats_df, job_stats_df)
    
    # 7. í™œë™ ê°„ ê°„ê²© ë¶„ì„
    gap_df = analyze_time_gaps(individual_stats_df, schedule_df)
    
    # 8. ê²°ê³¼ ì €ì¥
    try:
        job_stats_df.to_excel("stay_time_job_stats.xlsx", index=False)
        individual_stats_df.to_excel("stay_time_individual_stats.xlsx", index=False)
        if problematic is not None:
            problematic.to_excel("stay_time_problematic_cases.xlsx", index=False)
        if gap_df is not None:
            gap_df.to_excel("stay_time_gaps.xlsx", index=False)
        print(f"\nâœ… ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    print("=" * 80)
    
    return job_stats_df, individual_stats_df, optimization_info

if __name__ == "__main__":
    main() 