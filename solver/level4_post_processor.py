"""
Level 4: í›„ì²˜ë¦¬ ì¡°ì • ëª¨ë“ˆ

ì „ì²´ ìŠ¤ì¼€ì¤„ë§(Level 1-3) ì™„ë£Œ í›„ ì²´ë¥˜ì‹œê°„ ìµœì í™”ë¥¼ ìœ„í•œ í›„ì²˜ë¦¬ ì¡°ì •
ì£¼ìš” ê¸°ëŠ¥:
- ì²´ë¥˜ì‹œê°„ ë¶„ì„ ë° ë¬¸ì œ ì¼€ì´ìŠ¤ ì‹ë³„
- Batched ê·¸ë£¹ ì‹œê°„ ì´ë™ ì‹œë®¬ë ˆì´ì…˜
- ì œì•½ ì¡°ê±´ ê²€ì¦ ë° ìµœì  ì¡°ì • ì‹¤í–‰
"""

import logging
from typing import Dict, List, Optional, Tuple, Set
from datetime import datetime, timedelta
from collections import defaultdict
import pandas as pd
import time # Added for timing

from .types import (
    DateConfig, ScheduleItem, Room, Activity, ActivityMode,
    PrecedenceRule, GroupAssignment, StayTimeAnalysis,
    GroupMoveCandidate, Level4Result
)


class Level4PostProcessor:
    """Level 4 í›„ì²˜ë¦¬ ì¡°ì • í”„ë¡œì„¸ì„œ"""
    
    def __init__(self, logger: Optional[logging.Logger] = None):
        self.logger = logger or logging.getLogger(__name__)
        
    def _get_activity_max_capacity(self, activity_name: str, config: DateConfig) -> Optional[int]:
        """í™œë™ë³„ ìµœëŒ€ ìš©ëŸ‰ ë°˜í™˜"""
        for activity in config.activities:
            if activity.name == activity_name:
                return activity.max_capacity
        return None
    
    def _calculate_improvement_potential(self, items: List[ScheduleItem], config: DateConfig) -> float:
        """ê°œì„  ê°€ëŠ¥ì„± ê³„ì‚° - ë™ì  ê¸°ì¤€ ì ìš©"""
        if len(items) < 2:
            return 0.0
        
        # í™œë™ ê°„ ê°„ê²© ê³„ì‚°
        items_sorted = sorted(items, key=lambda x: x.start_time)
        gaps = []
        
        for i in range(len(items_sorted) - 1):
            gap_hours = (items_sorted[i+1].start_time - items_sorted[i].end_time).total_seconds() / 3600
            gaps.append(gap_hours)
        
        # ê°œì„  ê°€ëŠ¥ì„± = ê°€ì¥ ê¸´ ê°„ê²©ì—ì„œ ê¸°ë³¸ ëŒ€ê¸°ì‹œê°„(1ì‹œê°„) ì œì™¸
        max_gap = max(gaps) if gaps else 0.0
        
        # ğŸ”§ ë™ì  ê¸°ì¤€: 3ì‹œê°„ â†’ 2ì‹œê°„ìœ¼ë¡œ ë‹¨ì¶• (ë” ê³µê²©ì )
        # ë¦¬ìŠ¤í¬ ë¶„ì„: ê°„ê²©ì´ 1.5ì‹œê°„ ì´ìƒì´ë©´ ê°œì„  ê°€ëŠ¥
        improvement_threshold = 1.5  # ê¸°ì¡´ 2.0ì—ì„œ 1.5ë¡œ ë‹¨ì¶•
        
        improvement_potential = max(0.0, max_gap - improvement_threshold)
        
        # ğŸ“Š ê°œì„  ê°€ëŠ¥ì„± ë¡œê¹…
        if improvement_potential > 0:
            self.logger.debug(f"ê°œì„  ê°€ëŠ¥ì„± ê³„ì‚°: ìµœëŒ€ê°„ê²©={max_gap:.1f}h, ì„ê³„ê°’={improvement_threshold:.1f}h, "
                             f"ê°œì„ ì ì¬ë ¥={improvement_potential:.1f}h")
        
        return improvement_potential
    
    def _analyze_risk_factors(self, analyses: List[StayTimeAnalysis], config: DateConfig) -> dict:
        """ì²´ë¥˜ì‹œê°„ ê¸°ì¤€ ë³€ê²½ì— ë”°ë¥¸ ë¦¬ìŠ¤í¬ ë¶„ì„"""
        if not analyses:
            return {}
        
        stay_times = [a.stay_time_hours for a in analyses]
        
        # ë‹¤ì–‘í•œ ê¸°ì¤€ì— ë”°ë¥¸ ì˜í–¥ ë¶„ì„
        risk_analysis = {}
        
        # ê¸°ì¤€ë³„ ëŒ€ìƒì ìˆ˜ ê³„ì‚°
        thresholds = [2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 6.0]
        for threshold in thresholds:
            candidates = [a for a in analyses if a.stay_time_hours >= threshold]
            risk_analysis[f"threshold_{threshold}"] = {
                'count': len(candidates),
                'percentage': len(candidates) / len(analyses) * 100,
                'avg_improvement': sum(a.improvement_potential for a in candidates) / len(candidates) if candidates else 0
            }
        
        # í†µê³„ì  ê¸°ì¤€ ë¶„ì„
        import statistics
        mean_stay = statistics.mean(stay_times)
        std_dev = statistics.stdev(stay_times) if len(stay_times) > 1 else 0
        
        # ìƒìœ„ í¼ì„¼íƒ€ì¼ ë¶„ì„
        sorted_times = sorted(stay_times, reverse=True)
        percentiles = [10, 20, 30, 40, 50]
        
        for p in percentiles:
            idx = int(len(sorted_times) * p / 100)
            percentile_value = sorted_times[min(idx, len(sorted_times) - 1)]
            candidates = [a for a in analyses if a.stay_time_hours >= percentile_value]
            
            risk_analysis[f"percentile_{p}"] = {
                'threshold': percentile_value,
                'count': len(candidates),
                'percentage': len(candidates) / len(analyses) * 100
            }
        
        # ë¦¬ìŠ¤í¬ ìš”ì•½
        risk_analysis['summary'] = {
            'total_candidates': len(analyses),
            'mean_stay': mean_stay,
            'std_dev': std_dev,
            'min_stay': min(stay_times),
            'max_stay': max(stay_times),
            'statistical_threshold': mean_stay + std_dev,
            'recommended_threshold': max(3.0, min(mean_stay + std_dev, 
                                                 sorted_times[int(len(sorted_times) * 0.3)]))
        }
        
        return risk_analysis
    
    def _calculate_dynamic_stay_time_threshold(self, analyses: List[StayTimeAnalysis]) -> float:
        """ë™ì  ì²´ë¥˜ì‹œê°„ ê¸°ì¤€ ê³„ì‚° - ê°œì„ ëœ ë²„ì „"""
        if not analyses:
            return 3.0  # ê¸°ë³¸ê°’ 3ì‹œê°„
        
        stay_times = [analysis.stay_time_hours for analysis in analyses]
        
        # ë¦¬ìŠ¤í¬ ë¶„ì„ ìˆ˜í–‰
        risk_analysis = self._analyze_risk_factors(analyses, None)
        
        # í†µê³„ ê¸°ë°˜ ì„ê³„ê°’ ê³„ì‚°
        import statistics
        mean_stay = statistics.mean(stay_times)
        median_stay = statistics.median(stay_times)
        
        # ìƒìœ„ 30% ì§€ì  ê³„ì‚°
        sorted_times = sorted(stay_times, reverse=True)
        percentile_30_index = int(len(sorted_times) * 0.3)
        percentile_30_value = sorted_times[min(percentile_30_index, len(sorted_times) - 1)]
        
        # ë™ì  ì„ê³„ê°’ ê³„ì‚° ì „ëµ
        std_dev = statistics.stdev(stay_times) if len(stay_times) > 1 else 0
        statistical_threshold = mean_stay + 0.5 * std_dev  # ë” ê³µê²©ì ìœ¼ë¡œ ë³€ê²½ (ê¸°ì¡´ 1.0 â†’ 0.5)
        
        # ğŸ”§ 3ì‹œê°„ ê¸°ì¤€ ì ìš©: í†µê³„ì  ì„ê³„ê°’ê³¼ ìƒìœ„ 30% ì¤‘ ì‘ì€ ê°’, ìµœì†Œ 3ì‹œê°„
        dynamic_threshold = max(3.0, min(statistical_threshold, percentile_30_value))
        
        # ğŸ“Š ìƒì„¸ ë¡œê¹…
        self.logger.info(f"ğŸ“Š ì²´ë¥˜ì‹œê°„ í†µê³„ ë° ë¦¬ìŠ¤í¬ ë¶„ì„:")
        self.logger.info(f"   í‰ê· ={mean_stay:.1f}h, ì¤‘ê°„ê°’={median_stay:.1f}h, í‘œì¤€í¸ì°¨={std_dev:.1f}h")
        self.logger.info(f"   ìƒìœ„30%={percentile_30_value:.1f}h, í†µê³„ì ì„ê³„ê°’={statistical_threshold:.1f}h")
        self.logger.info(f"   ìµœì¢… ë™ì ì„ê³„ê°’={dynamic_threshold:.1f}h")
        
        # ë¦¬ìŠ¤í¬ ë¶„ì„ ê²°ê³¼ ë¡œê¹…
        if 'summary' in risk_analysis:
            summary = risk_analysis['summary']
            self.logger.info(f"   ê¶Œì¥ì„ê³„ê°’={summary['recommended_threshold']:.1f}h")
        
        # 3ì‹œê°„ ê¸°ì¤€ ì ìš© ì‹œ ì˜ˆìƒ ì˜í–¥
        candidates_3h = len([t for t in stay_times if t >= 3.0])
        candidates_4h = len([t for t in stay_times if t >= 4.0])
        
        self.logger.info(f"ğŸ“ˆ ê¸°ì¤€ë³„ ëŒ€ìƒì ìˆ˜:")
        self.logger.info(f"   3ì‹œê°„ ê¸°ì¤€: {candidates_3h}ëª… ({candidates_3h/len(stay_times)*100:.1f}%)")
        self.logger.info(f"   4ì‹œê°„ ê¸°ì¤€: {candidates_4h}ëª… ({candidates_4h/len(stay_times)*100:.1f}%)")
        
        if candidates_3h > candidates_4h * 2:
            self.logger.warning(f"âš ï¸ 3ì‹œê°„ ê¸°ì¤€ ì‹œ ëŒ€ìƒìê°€ {candidates_3h - candidates_4h}ëª… ì¦ê°€ - ì„±ëŠ¥ ì£¼ì˜ í•„ìš”")
        
        return dynamic_threshold

    def _validate_schedule_integrity(self, schedule: List[ScheduleItem], config: DateConfig) -> List[str]:
        """ìŠ¤ì¼€ì¤„ ë¬´ê²°ì„± ê²€ì‚¬ - ê·¸ë£¹ í¬ê¸° ì´ˆê³¼ì™€ ì¤‘ë³µ ë°°ì • ê²€ì‚¬"""
        issues = []
        
        # ê·¸ë£¹ë³„ í¬ê¸° ê²€ì‚¬
        group_sizes = defaultdict(int)
        for item in schedule:
            if item.group_id and not item.applicant_id.startswith('dummy'):
                group_sizes[item.group_id] += 1
        
        # Batched í™œë™ ê·¸ë£¹ í¬ê¸° ê²€ì‚¬ (í™œë™ë³„ ìµœëŒ€ ìš©ëŸ‰ ê¸°ì¤€)
        for group_id, size in group_sizes.items():
            # í•´ë‹¹ ê·¸ë£¹ì˜ í™œë™ ì •ë³´ í™•ì¸
            group_items = [item for item in schedule if item.group_id == group_id]
            if group_items:
                activity_name = group_items[0].activity_name
                # í™œë™ë³„ ìµœëŒ€ ìš©ëŸ‰ í™•ì¸
                max_capacity = self._get_activity_max_capacity(activity_name, config)
                if max_capacity and size > max_capacity:
                    issues.append(f"âš ï¸ {activity_name} ê·¸ë£¹ {group_id} í¬ê¸° ì´ˆê³¼: {size}ëª… (ìµœëŒ€ {max_capacity}ëª…)")
        
        # ì‹œê°„-ë°© ì¤‘ë³µ ë°°ì • ê²€ì‚¬
        time_room_groups = defaultdict(list)
        for item in schedule:
            if not item.applicant_id.startswith('dummy'):
                key = (item.room_name, item.start_time, item.end_time)
                time_room_groups[key].append(item.group_id)
        
        for (room, start_time, end_time), group_ids in time_room_groups.items():
            unique_groups = set(group_ids)
            if len(unique_groups) > 1:
                issues.append(f"âš ï¸ ì‹œê°„-ë°© ì¤‘ë³µ: {room} {start_time} - ê·¸ë£¹ {', '.join(unique_groups)}")
        
        return issues

    def optimize_stay_times(
        self,
        schedule: List[ScheduleItem],
        config: DateConfig,
        target_improvement_hours: float = 1.0
    ) -> Level4Result:
        """
        ì²´ë¥˜ì‹œê°„ ìµœì í™” - ì•ˆì „ì¥ì¹˜ ê°•í™” ë° ë™ì  ì„ê³„ê°’ ì ìš©
        """
        start_time = time.time()
        
        # ğŸ”§ CRITICAL: ì…ë ¥ ìŠ¤ì¼€ì¤„ ë¬´ê²°ì„± ê²€ì‚¬
        input_issues = self._validate_schedule_integrity(schedule, config)
        if input_issues:
            self.logger.error(f"ì…ë ¥ ìŠ¤ì¼€ì¤„ ë¬´ê²°ì„± ì˜¤ë¥˜: {input_issues}")
            return Level4Result(
                success=False,
                original_schedule=schedule,
                optimized_schedule=schedule,
                total_improvement_hours=0.0,
                adjusted_groups=0,
                improvements=[],
                logs=[]
            )
        
        self.logger.info("Level 4 í›„ì²˜ë¦¬ ì¡°ì • ì‹œì‘")
        
        try:
            # 1. í˜„ì¬ ì²´ë¥˜ì‹œê°„ ë¶„ì„
            analyses = self._analyze_stay_times(schedule)
            self.logger.info(f"ì²´ë¥˜ì‹œê°„ ë¶„ì„ ì™„ë£Œ: {len(analyses)}ëª…")
            
            if not analyses:
                self.logger.info("ë¶„ì„í•  ì§€ì›ìê°€ ì—†ìŠµë‹ˆë‹¤")
                return Level4Result(
                    success=False,
                    original_schedule=schedule,
                    optimized_schedule=schedule,
                    total_improvement_hours=0.0,
                    adjusted_groups=0,
                    improvements=[],
                    logs=[]
                )
            
            # 2. ë¬¸ì œ ì¼€ì´ìŠ¤ ì‹ë³„ (ë™ì  ì„ê³„ê°’ ì ìš©)
            problem_cases = self._identify_problem_cases_dynamic(analyses)
            self.logger.info(f"ë¬¸ì œ ì¼€ì´ìŠ¤ {len(problem_cases)}ê°œ ì‹ë³„")
            
            if not problem_cases:
                self.logger.info("ì²´ë¥˜ì‹œê°„ ê°œì„ ì´ í•„ìš”í•œ ì¼€ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤")
                return Level4Result(
                    success=False,
                    original_schedule=schedule,
                    optimized_schedule=schedule,
                    total_improvement_hours=0.0,
                    adjusted_groups=0,
                    improvements=[],
                    logs=[]
                )
            
            # 3. ì¡°ì • ê°€ëŠ¥í•œ Batched ê·¸ë£¹ ì°¾ê¸°
            move_candidates = self._find_move_candidates(schedule, problem_cases, config)
            self.logger.info(f"ì´ë™ í›„ë³´ ê·¸ë£¹: {len(move_candidates)}ê°œ")
            
            if not move_candidates:
                self.logger.info("ì´ë™ ê°€ëŠ¥í•œ ê·¸ë£¹ì´ ì—†ìŠµë‹ˆë‹¤")
                return Level4Result(
                    success=False,
                    original_schedule=schedule,
                    optimized_schedule=schedule,
                    total_improvement_hours=0.0,
                    adjusted_groups=0,
                    improvements=[],
                    logs=[]
                )
            
            # 4. ìµœì  ì´ë™ ì‹œë®¬ë ˆì´ì…˜
            optimal_moves = self._simulate_optimal_moves(move_candidates, config)
            self.logger.info(f"ìµœì  ì´ë™ ì„ íƒ: {len(optimal_moves)}ê°œ")
            
            if not optimal_moves:
                self.logger.info("ì ìš© ê°€ëŠ¥í•œ ì´ë™ì´ ì—†ìŠµë‹ˆë‹¤")
                return Level4Result(
                    success=False,
                    original_schedule=schedule,
                    optimized_schedule=schedule,
                    total_improvement_hours=0.0,
                    adjusted_groups=0,
                    improvements=[],
                    logs=[]
                )
            
            # 5. ì œì•½ ì¡°ê±´ ê²€ì¦ ë° ì ìš©
            optimized_schedule = self._apply_moves(schedule, optimal_moves, config)
            
            # ğŸ”§ CRITICAL: ìµœì¢… ìŠ¤ì¼€ì¤„ ë¬´ê²°ì„± ê²€ì‚¬
            final_issues = self._validate_schedule_integrity(optimized_schedule, config)
            if final_issues:
                self.logger.error(f"ìµœì¢… ìŠ¤ì¼€ì¤„ ë¬´ê²°ì„± ì˜¤ë¥˜: {final_issues}")
                # ì›ë³¸ ìŠ¤ì¼€ì¤„ ë³µì›
                return Level4Result(
                    success=False,
                    original_schedule=schedule,
                    optimized_schedule=schedule,
                    total_improvement_hours=0.0,
                    adjusted_groups=0,
                    improvements=[],
                    logs=[]
                )
            
            # 6. ê²°ê³¼ ìƒì„±
            total_improvement = sum(move.estimated_improvement for move in optimal_moves)
            
            elapsed_time = time.time() - start_time
            self.logger.info(f"Level 4 í›„ì²˜ë¦¬ ì¡°ì • ì™„ë£Œ: {elapsed_time:.2f}ì´ˆ, {total_improvement:.1f}ì‹œê°„ ê°œì„ ")
            
            result = Level4Result(
                original_schedule=schedule,
                optimized_schedule=optimized_schedule,
                improvements=optimal_moves,
                total_improvement_hours=total_improvement,
                adjusted_groups=len(optimal_moves),
                success=True,
                logs=[f"Level 4 í›„ì²˜ë¦¬ ì¡°ì • ì™„ë£Œ: {total_improvement:.1f}ì‹œê°„ ê°œì„ "]
            )
            
            return result
            
        except Exception as e:
            self.logger.error(f"Level 4 í›„ì²˜ë¦¬ ì¡°ì • ì‹¤íŒ¨: {str(e)}")
            return Level4Result(
                original_schedule=schedule,
                optimized_schedule=schedule,
                improvements=[],
                total_improvement_hours=0.0,
                adjusted_groups=0,
                success=False,
                logs=[f"Level 4 í›„ì²˜ë¦¬ ì¡°ì • ì‹¤íŒ¨: {str(e)}"]
            )
    
    def _analyze_stay_times(self, schedule: List[ScheduleItem]) -> List[StayTimeAnalysis]:
        """ì²´ë¥˜ì‹œê°„ ë¶„ì„"""
        applicant_schedules = defaultdict(list)
        
        # ì§€ì›ìë³„ ìŠ¤ì¼€ì¤„ ê·¸ë£¹í™”
        for item in schedule:
            if not item.applicant_id.startswith('dummy'):
                applicant_schedules[item.applicant_id].append(item)
        
        analyses = []
        for applicant_id, items in applicant_schedules.items():
            # ì‹œê°„ ìˆœ ì •ë ¬
            items.sort(key=lambda x: x.start_time)
            
            if items:
                first_start = items[0].start_time
                last_end = items[-1].end_time
                stay_time = (last_end - first_start).total_seconds() / 3600
                
                # ê°œì„  ê°€ëŠ¥ì„± ê³„ì‚° (ë‹¨ìˆœíˆ ë§ˆì§€ë§‰ í™œë™ì„ ì•ìœ¼ë¡œ ë‹¹ê¸¸ ìˆ˜ ìˆëŠ” ì‹œê°„)
                improvement_potential = self._calculate_improvement_potential(items, None) # Pass config=None
                
                analysis = StayTimeAnalysis(
                    applicant_id=applicant_id,
                    job_code=items[0].job_code,
                    first_activity_start=first_start,
                    last_activity_end=last_end,
                    stay_time_hours=stay_time,
                    activities=items,
                    improvement_potential=improvement_potential
                )
                analyses.append(analysis)
        
        return analyses
    
    def _identify_problem_cases_dynamic(self, analyses: List[StayTimeAnalysis]) -> List[StayTimeAnalysis]:
        """ë™ì  ì„ê³„ê°’ ê¸°ë°˜ ë¬¸ì œ ì¼€ì´ìŠ¤ ì‹ë³„"""
        # ë™ì  ì²´ë¥˜ì‹œê°„ ì„ê³„ê°’ ê³„ì‚°
        dynamic_threshold = self._calculate_dynamic_stay_time_threshold(analyses)
        
        # ì²´ë¥˜ì‹œê°„ ê¸°ì¤€ ì •ë ¬
        sorted_analyses = sorted(analyses, key=lambda x: x.stay_time_hours, reverse=True)
        
        # ìƒìœ„ 30% ë˜ëŠ” ë™ì  ì„ê³„ê°’ ì´ìƒì¸ ê²½ìš°ë¥¼ ë¬¸ì œ ì¼€ì´ìŠ¤ë¡œ ì‹ë³„
        percentile_threshold = sorted_analyses[int(len(sorted_analyses) * 0.3)].stay_time_hours if sorted_analyses else 0
        final_threshold = max(dynamic_threshold, percentile_threshold)
        
        problem_cases = [
            analysis for analysis in sorted_analyses 
            if analysis.stay_time_hours >= final_threshold and analysis.improvement_potential > 0.3
        ]
        
        self.logger.info(f"ğŸ“Š ìµœì¢… ì„ê³„ê°’: {final_threshold:.1f}ì‹œê°„ (ë™ì ={dynamic_threshold:.1f}h, ìƒìœ„30%={percentile_threshold:.1f}h)")
        
        return problem_cases
    
    def _find_move_candidates(
        self, 
        schedule: List[ScheduleItem], 
        problem_cases: List[StayTimeAnalysis],
        config: DateConfig
    ) -> List[GroupMoveCandidate]:
        """ì¡°ì • ê°€ëŠ¥í•œ Batched ê·¸ë£¹ ì°¾ê¸°"""
        candidates = []
        
        # Batched í™œë™ë§Œ í•„í„°ë§
        batched_items = [item for item in schedule if self._is_batched_activity(item, config)]
        
        # ê·¸ë£¹ë³„ë¡œ ì •ë¦¬
        group_items = defaultdict(list)
        for item in batched_items:
            if item.group_id:
                group_items[item.group_id].append(item)
        
        for group_id, items in group_items.items():
            if not items:
                continue
                
            # ê·¸ë£¹ì˜ í˜„ì¬ ì‹œê°„
            current_start = min(item.start_time for item in items)
            current_end = max(item.end_time for item in items)
            
            # ì´ ê·¸ë£¹ì— ì†í•œ ë¬¸ì œ ì¼€ì´ìŠ¤ë“¤
            affected_applicants = []
            total_improvement = 0.0
            
            for problem_case in problem_cases:
                if any(item.applicant_id == problem_case.applicant_id for item in items):
                    affected_applicants.append(problem_case.applicant_id)
                    total_improvement += problem_case.improvement_potential
            
            if affected_applicants:
                # ì´ë™ ëª©í‘œ ì‹œê°„ ê³„ì‚° (ì˜¤í›„ ì‹œê°„ëŒ€ë¡œ ì´ë™)
                target_start = self._calculate_target_time(current_start, config)
                target_end = target_start + (current_end - current_start)
                
                candidate = GroupMoveCandidate(
                    group_id=group_id,
                    activity_name=items[0].activity_name,
                    current_start=current_start,
                    current_end=current_end,
                    target_start=target_start,
                    target_end=target_end,
                    affected_applicants=affected_applicants,
                    estimated_improvement=total_improvement
                )
                candidates.append(candidate)
        
        return candidates
    
    def _simulate_optimal_moves(
        self, 
        candidates: List[GroupMoveCandidate],
        config: DateConfig
    ) -> List[GroupMoveCandidate]:
        """ìµœì  ì´ë™ ì‹œë®¬ë ˆì´ì…˜"""
        # ê°œì„  íš¨ê³¼ ëŒ€ë¹„ ë¦¬ìŠ¤í¬ê°€ ë‚®ì€ í›„ë³´ë“¤ ì„ íƒ
        valid_candidates = []
        
        for candidate in candidates:
            # ìš´ì˜ì‹œê°„ ë‚´ ì²´í¬
            if candidate.target_end <= config.operating_hours[1]:
                # ë‹¤ë¥¸ í™œë™ê³¼ ì¶©ëŒ ì²´í¬ (ë‹¨ìˆœí™”)
                if self._check_time_conflicts(candidate, config):
                    valid_candidates.append(candidate)
        
        # ê°œì„  íš¨ê³¼ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìµœëŒ€ 6ê°œ ê·¸ë£¹ ì„ íƒ (ë” ê³µê²©ì  ì„¤ì •)
        valid_candidates.sort(key=lambda x: x.estimated_improvement, reverse=True)
        return valid_candidates[:6]
    
    def _apply_moves(
        self, 
        original_schedule: List[ScheduleItem], 
        moves: List[GroupMoveCandidate],
        config: DateConfig
    ) -> List[ScheduleItem]:
        """ì´ë™ ì ìš© - ì¶©ëŒ ë°©ì§€ ê°•í™”"""
        optimized_schedule = original_schedule.copy()
        used_time_rooms = set()  # ğŸ”§ CRITICAL FIX: ì‹œê°„-ë°© ì¶©ëŒ ì¶”ì 
        
        for move in moves:
            # í•´ë‹¹ ê·¸ë£¹ì˜ ìŠ¤ì¼€ì¤„ ì•„ì´í…œë“¤ ì°¾ê¸°
            group_items = [
                item for item in optimized_schedule 
                if item.group_id == move.group_id
            ]
            
            if not group_items:
                continue
                
            # ğŸ”§ SAFETY CHECK: ê·¸ë£¹ í¬ê¸° ê²€ì¦ (í™œë™ë³„ ìµœëŒ€ ìš©ëŸ‰ ê¸°ì¤€)
            max_capacity = self._get_activity_max_capacity(move.activity_name, config)
            if max_capacity and len(group_items) > max_capacity:
                self.logger.warning(f"âš ï¸ ê·¸ë£¹ {move.group_id} í¬ê¸° ì´ˆê³¼ ({len(group_items)}ëª… > {max_capacity}ëª…), ì´ë™ ê±´ë„ˆëœ€")
                continue
                
            # ì‹œê°„ ì´ë™ ì ìš©
            time_delta = move.target_start - move.current_start
            
            # ìƒˆë¡œìš´ ì‹œê°„ê³¼ ë°© ì¡°í•© í™•ì¸
            sample_item = group_items[0]
            new_start = sample_item.start_time + time_delta
            new_end = sample_item.end_time + time_delta
            room_time_key = (sample_item.room_name, new_start, new_end)
            
            # ğŸ”§ CRITICAL FIX: ì‹œê°„-ë°© ì¶©ëŒ ì²´í¬
            if room_time_key in used_time_rooms:
                self.logger.warning(f"âš ï¸ ê·¸ë£¹ {move.group_id} ì‹œê°„-ë°© ì¶©ëŒ, ì´ë™ ê±´ë„ˆëœ€: {sample_item.room_name} {new_start}")
                continue
                
            # ì¶©ëŒì´ ì—†ìœ¼ë©´ ì´ë™ ì‹¤í–‰
            used_time_rooms.add(room_time_key)
            
            for item in group_items:
                # ìƒˆë¡œìš´ ì‹œê°„ìœ¼ë¡œ ì—…ë°ì´íŠ¸ (min_gap_min ì œì•½ ì ìš©)
                new_start_time, new_end_time = self._apply_min_gap_constraint(
                    item.start_time + time_delta, item.end_time + time_delta, 5
                )
                
                new_item = ScheduleItem(
                    applicant_id=item.applicant_id,
                    job_code=item.job_code,
                    activity_name=item.activity_name,
                    room_name=item.room_name,
                    start_time=new_start_time,
                    end_time=new_end_time,
                    group_id=item.group_id
                )
                
                # ê¸°ì¡´ ì•„ì´í…œ êµì²´
                idx = optimized_schedule.index(item)
                optimized_schedule[idx] = new_item
                
                self.logger.info(f"ê·¸ë£¹ {move.group_id} ì´ë™: {item.start_time} â†’ {new_item.start_time}")
        
        return optimized_schedule
    
    def _is_batched_activity(self, item: ScheduleItem, config: DateConfig) -> bool:
        """Batched í™œë™ì¸ì§€ í™•ì¸"""
        for activity in config.activities:
            if activity.name == item.activity_name:
                return activity.mode == ActivityMode.BATCHED
        return False
    
    def _calculate_target_time(self, current_start: timedelta, config: DateConfig) -> timedelta:
        """ëª©í‘œ ì´ë™ ì‹œê°„ ê³„ì‚° - ì¶©ëŒ ë°©ì§€ ê°œì„ """
        # ğŸ”§ CRITICAL FIX: ëª¨ë“  ê·¸ë£¹ì„ 14:00ë¡œ ë³´ë‚´ëŠ” ë²„ê·¸ ìˆ˜ì •
        # í˜„ì¬ ì‹œê°„ë³´ë‹¤ ëŠ¦ì€ ì‹œê°„ëŒ€ë¡œë§Œ ì´ë™ (ì˜¤í›„ë¡œ ì´ë™)
        
        # ì˜¤í›„ ì‹œê°„ëŒ€ í›„ë³´ë“¤ (5ë¶„ ë‹¨ìœ„ë¡œ ë¼ìš´ë”©)
        afternoon_slots = [
            self._round_to_5min(timedelta(hours=13, minutes=0)),
            self._round_to_5min(timedelta(hours=13, minutes=30)), 
            self._round_to_5min(timedelta(hours=14, minutes=0)),
            self._round_to_5min(timedelta(hours=14, minutes=30)),
            self._round_to_5min(timedelta(hours=15, minutes=0)),
            self._round_to_5min(timedelta(hours=15, minutes=30)),
            self._round_to_5min(timedelta(hours=16, minutes=0))
        ]
        
        # í˜„ì¬ ì‹œê°„ë³´ë‹¤ ëŠ¦ì€ ì‹œê°„ëŒ€ ì¤‘ ê°€ì¥ ê°€ê¹Œìš´ ê²ƒ ì„ íƒ
        valid_slots = [slot for slot in afternoon_slots 
                      if slot > current_start and slot <= config.operating_hours[1] - timedelta(hours=1)]
        
        if valid_slots:
            return valid_slots[0]  # ê°€ì¥ ê°€ê¹Œìš´ ì‹œê°„ëŒ€
        else:
            # ëŒ€ì•ˆ: í˜„ì¬ ì‹œê°„ + 2ì‹œê°„
            target = current_start + timedelta(hours=2)
            if target <= config.operating_hours[1] - timedelta(hours=1):
                return target
            else:
                return current_start  # ì´ë™í•˜ì§€ ì•ŠìŒ
    
    def _apply_min_gap_constraint(self, start_time: timedelta, end_time: timedelta, global_gap_min: int = 5) -> Tuple[timedelta, timedelta]:
        """
        min_gap_min ì œì•½ì„ ì ìš©í•˜ì—¬ ì‹œê°„ì„ 5ë¶„ ë‹¨ìœ„ë¡œ ì¡°ì •
        
        Args:
            start_time: ì‹œì‘ ì‹œê°„
            end_time: ì¢…ë£Œ ì‹œê°„
            global_gap_min: ìµœì†Œ ê°„ê²© (ë¶„)
            
        Returns:
            Tuple[timedelta, timedelta]: ì¡°ì •ëœ ì‹œì‘/ì¢…ë£Œ ì‹œê°„
        """
        # ì‹œì‘ ì‹œê°„ì„ 5ë¶„ ë‹¨ìœ„ë¡œ ì¡°ì •
        start_minutes = start_time.total_seconds() / 60
        adjusted_start_minutes = round(start_minutes / global_gap_min) * global_gap_min
        adjusted_start = timedelta(minutes=adjusted_start_minutes)
        
        # ì¢…ë£Œ ì‹œê°„ì„ 5ë¶„ ë‹¨ìœ„ë¡œ ì¡°ì •
        end_minutes = end_time.total_seconds() / 60
        adjusted_end_minutes = round(end_minutes / global_gap_min) * global_gap_min
        adjusted_end = timedelta(minutes=adjusted_end_minutes)
        
        return adjusted_start, adjusted_end
    
    def _round_to_5min(self, time_delta: timedelta) -> timedelta:
        """
        timedeltaë¥¼ 5ë¶„ ë‹¨ìœ„ë¡œ ë°˜ì˜¬ë¦¼ (í•˜ìœ„ í˜¸í™˜ì„±)
        
        Args:
            time_delta: ë°˜ì˜¬ë¦¼í•  ì‹œê°„
            
        Returns:
            timedelta: 5ë¶„ ë‹¨ìœ„ë¡œ ë°˜ì˜¬ë¦¼ëœ ì‹œê°„
        """
        total_minutes = time_delta.total_seconds() / 60
        rounded_minutes = round(total_minutes / 5) * 5
        return timedelta(minutes=rounded_minutes)
    
    def _check_time_conflicts(self, candidate: GroupMoveCandidate, config: DateConfig) -> bool:
        """ì‹œê°„ ì¶©ëŒ ì²´í¬ (ë‹¨ìˆœí™”ëœ ë²„ì „)"""
        # ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ì¶©ëŒ ê²€ì‚¬ í•„ìš”
        # í˜„ì¬ëŠ” ê¸°ë³¸ì ì¸ ìš´ì˜ì‹œê°„ ì²´í¬ë§Œ ìˆ˜í–‰
        return (candidate.target_start >= config.operating_hours[0] and 
                candidate.target_end <= config.operating_hours[1]) 