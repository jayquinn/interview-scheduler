# solver/solver.py  â€“  UI ë°ì´í„°ë§Œìœ¼ë¡œ OR-Tools ì‹¤í–‰
from datetime import timedelta, datetime
import pandas as pd
import traceback, sys, streamlit as st
from interview_opt_test_v4 import build_model
import contextlib, io
from pathlib import Path



def _derive_internal_tables(cfg_ui: dict, the_date: pd.Timestamp, *, debug: bool = False) -> dict:
    """
    Streamlit UI ê°’ìœ¼ë¡œë¶€í„° build_model ì´ ë°”ë¡œ ì“¸ 4ê°œ í‘œë¥¼ ìƒì„±.
    debug=True ì´ë©´ ë¸Œë¼ìš°ì €ì— cfg_map / cfg_avail ë¯¸ë¦¬ë³´ê¸° ì¶œë ¥.
    """
    import pandas as pd
    import streamlit as st

    # â‘  í™œë™ â†” ì†Œìš”ì‹œê°„ ----------------------------
    cfg_duration = cfg_ui["activities"][["activity", "duration_min"]].copy()

    # â–¶ room_type ëª©ë¡ì„ Activities í‘œì—ì„œ ìë™ ì¶”ì¶œ
    room_types_ui = cfg_ui["activities"]["room_type"].dropna().unique()

    # â‘¡ í™œë™ â†” loc(room_type) ----------------------
    base_map = cfg_ui["activities"][["activity", "room_type"]]

    if "space_avail" in cfg_ui and not cfg_ui["space_avail"].empty:
        sa = cfg_ui["space_avail"]
        rows = [
            {"activity": act, "loc": loc}
            for _, row in base_map.iterrows()
            for act, base in [(row["activity"], row["room_type"])]
            for loc in sa["loc"].unique()
            if str(loc).startswith(base)
        ]
        cfg_map = pd.DataFrame(rows)
    else:
        rp, rows = cfg_ui["room_plan"], []
        for _, r in rp.iterrows():
            for base in room_types_ui:
                n = int(r.get(f"{base}_count", 0))
                if n == 0:
                    continue
                for i in range(1, n + 1):
                    loc = f"{base}{i}" if n > 1 else base
                    rows.append({"room_type": base, "loc": loc})
        
        exploded = pd.DataFrame(rows, columns=['room_type', 'loc']).drop_duplicates("loc") if rows else pd.DataFrame(columns=['room_type', 'loc'])

        cfg_map = (
            base_map.merge(exploded, on="room_type", how="left")
                    .drop(columns=["room_type"])
        )
        if cfg_map['loc'].isnull().any():
            failed_acts = cfg_map[cfg_map['loc'].isnull()]['activity'].unique().tolist()
            st.error(f"**ì„¤ì • ì˜¤ë¥˜:** ë‹¤ìŒ í™œë™ì— í• ë‹¹ëœ ì¥ì†Œ(Room Type)ë¥¼ 'Room Plan'ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: **`{', '.join(failed_acts)}`**. 'Activities' í˜ì´ì§€ì™€ 'Room Plan' í˜ì´ì§€ì˜ Room Type ì´ë¦„ì´ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”. (ì˜ˆ: 'ì‹¬ì¸µë©´ì ‘ì‹¤'ì€ ë™ì¼í•´ì•¼ í•¨)")
            st.stop()

    # â‘¢ ë‚ ì§œÂ·ë°©ë³„ capacity --------------------------
    if "space_avail" in cfg_ui and not cfg_ui["space_avail"].empty:
        cfg_avail = cfg_ui["space_avail"][["loc", "date", "capacity_max"]].copy()
        cfg_avail["capacity_override"] = pd.NA
    else:
        rp, rows = cfg_ui["room_plan"], []
        for _, r in rp.iterrows():
            date = pd.to_datetime(r["date"])
            for base in room_types_ui:
                n   = int(r.get(f"{base}_count", 0))
                if n == 0:
                    continue
                cap = int(r.get(f"{base}_cap", 1))
                for i in range(1, n + 1):
                    loc = f"{base}{i}" if n > 1 else base
                    rows.append(
                        {"loc": loc, "date": date,
                         "capacity_max": cap, "capacity_override": pd.NA}
                    )
        cfg_avail = pd.DataFrame(rows)

    # â‘£ ì „í˜•(code) Ã— ë‚ ì§œë³„ ìš´ì˜ì‹œê°„ -----------------
    raw_oper = cfg_ui["oper_window"].copy()
    for old, new in [("start", "start_time"), ("end", "end_time")]:
        if old in raw_oper.columns and new in raw_oper.columns:
            raw_oper = raw_oper.drop(columns=[old])
    cfg_oper = (
        raw_oper.dropna(subset=["code", "date",
                                "start" if "start" in raw_oper.columns else "start_time",
                                "end"   if "end"   in raw_oper.columns else "end_time"])
                .query("code != ''")
                .drop_duplicates(["code", "date"])
                .reset_index(drop=True)
                .rename(columns={"start": "start_time", "end": "end_time"})
    )
    cfg_oper["date"] = pd.to_datetime(cfg_oper["date"])
    cfg_oper["start_time"] = cfg_oper["start_time"].astype(str)
    cfg_oper["end_time"]   = cfg_oper["end_time"].astype(str)

    # â”€â”€â”€â”€â”€â”€ ğŸ”  ë””ë²„ê·¸ ë¯¸ë¦¬ë³´ê¸° (ë¸Œë¼ìš°ì €) â”€â”€â”€â”€â”€â”€
    if debug:
        st.markdown("---")
        st.markdown(f"### ğŸ ë””ë²„ê·¸ ì •ë³´ (ì²˜ë¦¬ ë‚ ì§œ: {the_date.date()})")
        st.markdown("#### `cfg_map` (activity â†” loc) â€“ ìƒìœ„ 20í–‰")
        st.dataframe(cfg_map.sort_values(["activity", "loc"]).head(20),
                     use_container_width=True)

        st.markdown("#### `cfg_avail` â€“ ìƒìœ„ 20í–‰")
        cfg_avail_today = cfg_avail[cfg_avail['date'] == the_date]
        
        if not cfg_avail_today.empty:
            st.dataframe(cfg_avail_today.sort_values("loc").head(20),
                     use_container_width=True)
        else:
            st.markdown(f"**ê²½ê³ :** `{the_date.date()}`ì— í•´ë‹¹í•˜ëŠ” ì¥ì†Œ(Room) ì •ë³´ê°€ 'Room Plan'ì— ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("---")

    # ê²°ê³¼ ë°˜í™˜ --------------------------------------
    return dict(
        cfg_duration=cfg_duration,
        cfg_map=cfg_map,
        cfg_avail=cfg_avail,
        cfg_oper=cfg_oper,
        group_meta=cfg_ui["activities"].copy(),
    )

def generate_virtual_candidates(job_acts_map: pd.DataFrame) -> pd.DataFrame:
    """'ì§ë¬´ë³„ ë©´ì ‘í™œë™' ì„¤ì •ìœ¼ë¡œë¶€í„° ê°€ìƒ ì§€ì›ì ëª©ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    all_candidates = []
    for _, row in job_acts_map.iterrows():
        code = row['code']
        count = int(row['count'])
        activities = [act for act, required in row.items() if act not in ['code', 'count'] and required]
        
        for i in range(1, count + 1):
            candidate_id = f"{code}_{str(i).zfill(3)}"
            for act in activities:
                all_candidates.append({'id': candidate_id, 'code': code, 'activity': act})
    
    if not all_candidates:
        return pd.DataFrame(columns=['id', 'code', 'activity'])

    return pd.DataFrame(all_candidates)

def _calculate_dynamic_daily_limit(
    room_plan_tpl: pd.DataFrame, 
    oper_window_tpl: pd.DataFrame, 
    activities_df: pd.DataFrame, 
    job_acts_map: pd.DataFrame
) -> int:
    """ì‚¬ìš© ê°€ëŠ¥í•œ ìì›(ì‹œê°„, ê³µê°„)ê³¼ ì§€ì›ìë³„ í•„ìš” ìì›ì„ ê¸°ë°˜ìœ¼ë¡œ ì¼ì¼ ì²˜ë¦¬ ê°€ëŠ¥ ì¸ì›ì„ ë™ì ìœ¼ë¡œ ì¶”ì •í•©ë‹ˆë‹¤."""
    from datetime import date, datetime
    
    # 1. ì´ ê°€ìš© ì‹œê°„ ê³„ì‚°
    start_time_str = oper_window_tpl['start_time'].iloc[0]
    end_time_str = oper_window_tpl['end_time'].iloc[0]

    if isinstance(start_time_str, str):
        start_time = pd.to_datetime(start_time_str).time()
    else:
        start_time = start_time_str

    if isinstance(end_time_str, str):
        end_time = pd.to_datetime(end_time_str).time()
    else:
        end_time = end_time_str

    if not start_time or not end_time:
        return 20 # Fallback

    total_oper_minutes = (datetime.combine(date.min, end_time) - datetime.combine(date.min, start_time)).total_seconds() / 60
    
    room_types = activities_df.query("use==True")['room_type'].dropna().unique()
    total_room_minutes = 0
    for rt in room_types:
        count_col = f"{rt}_count"
        if count_col in room_plan_tpl:
            try:
                num_rooms = pd.to_numeric(room_plan_tpl[count_col].iloc[0], errors='coerce')
                if pd.notna(num_rooms):
                    total_room_minutes += num_rooms * total_oper_minutes
            except (ValueError, IndexError):
                pass
            
    if total_room_minutes <= 0:
        return 20

    # 2. ì§€ì›ì 1ëª…ë‹¹ í‰ê·  í•„ìš” ì‹œê°„ ê³„ì‚°
    job_acts_map_copy = job_acts_map.copy()
    
    if 'total_duration' not in job_acts_map_copy.columns:
        job_acts_map_copy['total_duration'] = 0
        for idx, row in job_acts_map_copy.iterrows():
            total_duration = 0
            activities = [act for act, required in row.items() if required and act not in ['code', 'count', 'total_duration']]
            
            for act_name in activities:
                act_info = activities_df[activities_df['activity'] == act_name]
                if not act_info.empty:
                    duration = act_info['duration_min'].iloc[0]
                    total_duration += duration
            job_acts_map_copy.loc[idx, 'total_duration'] = total_duration

    total_applicants = job_acts_map_copy['count'].sum()
    if total_applicants == 0:
        return 20
        
    weighted_avg_duration = (job_acts_map_copy['total_duration'] * job_acts_map_copy['count']).sum() / total_applicants
    
    if weighted_avg_duration <= 0:
        return 20

    # 3. ì¼ì¼ ì²˜ë¦¬ ê°€ëŠ¥ ì¸ì› ì¶”ì‚° (ì•ˆì „ ë§ˆì§„ 80% ì ìš©)
    daily_capacity = int((total_room_minutes / weighted_avg_duration) * 0.8)
    
    return max(10, daily_capacity)

def solve_for_days(cfg_ui: dict, params: dict, debug: bool):
    """
    ìµœì†Œ ìš´ì˜ì¼ì„ ì¶”ì •í•˜ê¸° ìœ„í•œ ë©”ì¸ ì†”ë²„ í•¨ìˆ˜.
    Day 1ë¶€í„° ì‹œì‘í•˜ì—¬ ëª¨ë“  ì§€ì›ìê°€ ë°°ì •ë  ë•Œê¹Œì§€ ë‚ ì§œë¥¼ ëŠ˜ë ¤ê°€ë©° ì‹œë„.
    """
    logger = st.logger.get_logger("solver")
    
    # 1. ê°€ìƒ ì§€ì›ì ìƒì„±
    job_acts_map = cfg_ui.get("job_acts_map")
    if job_acts_map is None or job_acts_map.empty:
        st.error("â›” 'â‘¡ ì§ë¬´ë³„ ë©´ì ‘í™œë™'ì—ì„œ ì¸ì›ìˆ˜ ì„¤ì •ì„ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.")
        return "NO_JOB_DATA", None, "ì§ë¬´ë³„ ì¸ì› ì •ë³´ ì—†ìŒ", 0
        
    candidates_df = generate_virtual_candidates(job_acts_map)
    if candidates_df.empty:
        st.info("ì²˜ë¦¬í•  ì§€ì›ì ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return "NO_CANDIDATES", None, "ì§€ì›ì ì—†ìŒ", 0

    # 2. ê³ ì • ì„¤ì •ê°’ ì¤€ë¹„ (í…œí”Œë¦¿)
    room_plan_tpl = cfg_ui.get("room_plan")
    oper_window_tpl = cfg_ui.get("oper_window")
    activities_df = cfg_ui.get("activities")
    rules = cfg_ui.get('precedence', pd.DataFrame())
    
    if room_plan_tpl is None or room_plan_tpl.empty:
        st.error("â›” 'â‘¢ ìš´ì˜ê³µê°„ì„¤ì •'ì—ì„œ ê³µê°„ í…œí”Œë¦¿ ì„¤ì •ì„ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.")
        return "NO_ROOM_PLAN", None, "ìš´ì˜ ê³µê°„ í…œí”Œë¦¿ ì—†ìŒ", 0
    if oper_window_tpl is None or oper_window_tpl.empty:
        st.error("â›” 'â‘£ ìš´ì˜ì‹œê°„ì„¤ì •'ì—ì„œ ì‹œê°„ í…œí”Œë¦¿ ì„¤ì •ì„ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.")
        return "NO_OPER_WINDOW", None, "ìš´ì˜ ì‹œê°„ í…œí”Œë¦¿ ì—†ìŒ", 0

    # +++ ë™ì  ì¼ì¼ ì²˜ë¦¬ëŸ‰ ê³„ì‚° +++
    daily_candidate_limit = 0
    try:
        daily_candidate_limit = _calculate_dynamic_daily_limit(
            room_plan_tpl=room_plan_tpl,
            oper_window_tpl=oper_window_tpl,
            activities_df=activities_df.query("use==True"),
            job_acts_map=job_acts_map
        )
    except Exception as e:
        logger.warning(f"ë™ì  ì¼ì¼ ì²˜ë¦¬ëŸ‰ ê³„ì‚° ì‹¤íŒ¨: {e}. ê¸°ë³¸ê°’(70)ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        daily_candidate_limit = 70
    # ++++++++++++++++++++++++++++++

    # 3. ë‚ ì§œë¥¼ ëŠ˜ë ¤ê°€ë©° ìŠ¤ì¼€ì¤„ë§ ì‹œë„
    all_scheduled_cands_long = pd.DataFrame()
    log_messages = []
    
    max_days = 30
    all_scheduled_ids = set()
    
    for day_num in range(1, max_days + 1):
        the_date = pd.to_datetime("2025-01-01") + timedelta(days=day_num - 1)

        unscheduled_cands = candidates_df[~candidates_df['id'].isin(all_scheduled_ids)]
        if unscheduled_cands.empty:
            log_messages.append("âœ… ëª¨ë“  ì§€ì›ì ë°°ì • ì™„ë£Œ. ì‹œë®¬ë ˆì´ì…˜ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        candidate_ids_for_day = unscheduled_cands['id'].unique()[:daily_candidate_limit]
        cands_to_schedule_df = unscheduled_cands[unscheduled_cands['id'].isin(candidate_ids_for_day)]

        candidate_info = {
            cid: {'job_code': group['code'].iloc[0], 'activities': group['activity'].tolist()}
            for cid, group in cands_to_schedule_df.groupby('id')
        }

        room_types = activities_df.query("use==True")['room_type'].dropna().unique()
        room_info_list = []
        for rt in room_types:
            count = int(room_plan_tpl.get(f"{rt}_count", 0).iloc[0])
            cap = int(room_plan_tpl.get(f"{rt}_cap", 1).iloc[0])
            for i in range(1, count + 1):
                loc = f"{rt}{i}" if count > 1 else rt
                room_info_list.append({'loc': loc, 'capacity': cap})
        room_info = {row['loc']: {'capacity': row['capacity']} for row in room_info_list}

        act_info = {
            row['activity']: {
                'duration': int(row['duration_min']),
                'required_rooms': [row['room_type']]
            }
            for _, row in activities_df.iterrows() if row['use']
        }
        
        base_time = pd.to_datetime('00:00:00').time()
        start_time_str = oper_window_tpl['start_time'].iloc[0]
        end_time_str = oper_window_tpl['end_time'].iloc[0]
        
        start_dt = datetime.combine(the_date.date(), pd.to_datetime(start_time_str).time())
        end_dt = datetime.combine(the_date.date(), pd.to_datetime(end_time_str).time())
        start_minutes = int((start_dt - datetime.combine(the_date.date(), base_time)).total_seconds() / 60)
        end_minutes = int((end_dt - datetime.combine(the_date.date(), base_time)).total_seconds() / 60)
        
        oper_hours = {code: (start_minutes, end_minutes) for code in job_acts_map['code'].unique()}
        
        config = {
            'the_date': the_date,
            'min_gap_min': params.get('min_gap_min', 5),
            'act_info': act_info,
            'candidate_info': candidate_info,
            'room_info': room_info,
            'oper_hours': oper_hours,
            'rules': [tuple(x) for x in rules.to_records(index=False)],
            'debug_mode': debug,
            'num_cpus': params.get('num_cpus', 8),
            'optimize_for_max_scheduled': True,
            'time_limit_sec': 60.0
        }
        
        log_messages.append(f"--- Day {day_num} ({the_date.date()}) ---")
        log_messages.append(f"ì¼ì¼ ìµœëŒ€ ì²˜ë¦¬ ê°€ëŠ¥ ì¸ì›: {daily_candidate_limit}ëª…")
        log_messages.append(f"ì‹œë„ ëŒ€ìƒ ì§€ì›ì ìˆ˜: {len(candidate_info)}")

        model, status, wide_df, build_model_logs = build_model(config, logger)
        
        if build_model_logs:
            log_messages.extend(build_model_logs)

        log_messages.append(f"Solver status: {status}")

        if status in ("OPTIMAL", "FEASIBLE") and wide_df is not None and not wide_df.empty:
            
            # wide_dfëŠ” ì‹¤ì œë¡œëŠ” long-formì´ë¯€ë¡œ, wide-to-long ë³€í™˜ì´ ë¶ˆí•„ìš”.
            # ì»¬ëŸ¼ëª… ë³€ê²½ë„ í•„ìš” ì—†ìŒ.
            try:
                long_df = wide_df.copy()
                long_df['interview_date'] = the_date
                
                # 'code' ì—´ì´ ì—†ìœ¼ë©´ 'job_code'ë¥¼ ì‚¬ìš©
                if 'code' not in long_df.columns and 'job_code' in long_df.columns:
                    long_df = long_df.rename(columns={'job_code': 'code'})

                # 'loc' ì—´ì´ ì—†ìœ¼ë©´ 'room'ì„ ì‚¬ìš©
                if 'loc' not in long_df.columns and 'room' in long_df.columns:
                    long_df = long_df.rename(columns={'room': 'loc'})
                
                # start_time, end_time -> start, endë¡œ ì •ê·œí™”
                if 'start_time' in long_df.columns:
                    long_df = long_df.rename(columns={'start_time': 'start'})
                if 'end_time' in long_df.columns:
                    long_df = long_df.rename(columns={'end_time': 'end'})


                scheduled_ids_today = set(long_df['id'].unique())
                all_scheduled_ids.update(scheduled_ids_today)
                
                all_scheduled_cands_long = pd.concat([all_scheduled_cands_long, long_df], ignore_index=True)
                log_messages.append(f"ì„±ê³µ: {len(scheduled_ids_today)}ëª… ë°°ì • ì™„ë£Œ.")
            except Exception as e:
                log_messages.append(f"ê²°ê³¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

        else:
            log_messages.append("ì‹¤íŒ¨ ë˜ëŠ” ë°°ì •ëœ ì§€ì›ì ì—†ìŒ.")
            if status == "ERROR":
                log_messages.append("\n>> ì˜¤ë¥˜ë¡œ ì¸í•´ ìŠ¤ì¼€ì¤„ë§ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìœ„ì˜ ìƒì„¸ ë¡œê·¸(Traceback)ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”. <<\n")
    
    else: # for-else: break ì—†ì´ ë£¨í”„ê°€ ëë‚˜ë©´ ì‹¤í–‰
        unscheduled_cands_final = candidates_df[~candidates_df['id'].isin(all_scheduled_ids)]
        if not unscheduled_cands_final.empty:
            log_messages.append(f"âš ï¸ {max_days}ì¼ ì•ˆì— {len(unscheduled_cands_final['id'].unique())}ëª…ì˜ ì§€ì›ìë¥¼ ëª¨ë‘ ë°°ì •í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            st.warning(f"ì‹œë®¬ë ˆì´ì…˜ ê¸°ê°„({max_days}ì¼)ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì¼ë¶€ ì§€ì›ìê°€ ë°°ì •ë˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    if all_scheduled_cands_long.empty:
        return "NO_SOLUTION", None, "\n".join(log_messages), daily_candidate_limit

    # ìµœì¢…ì ìœ¼ë¡œ long í¬ë§·ì„ wide í¬ë§·ìœ¼ë¡œ ë³€í™˜
    final_wide = all_scheduled_cands_long.pivot_table(
        index=['id', 'interview_date', 'code'],
        columns='activity',
        values=['start', 'end', 'loc'],
        aggfunc='first'
    ).reset_index()

    final_wide.columns = ['_'.join(col).strip() if isinstance(col, tuple) and col[1] else col[0] for col in final_wide.columns]
    final_wide = final_wide.rename(columns={'id_': 'id', 'interview_date_': 'interview_date', 'code_': 'code'})

    activity_cols = sorted(list(all_scheduled_cands_long['activity'].unique()))
    
    for act in activity_cols:
        for prefix in ['start_', 'end_']:
            col = f"{prefix}{act}"
            if col in final_wide.columns:
                final_wide[col] = pd.to_datetime(final_wide[col], errors='coerce').dt.strftime('%H:%M:%S')

    sorted_activity_cols = sort_activities_by_time(final_wide.copy(), activity_cols)

    base_cols = ['id', 'interview_date', 'code']
    ordered_cols = base_cols + [f'{prefix}{act}' for act in sorted_activity_cols for prefix in ['start_', 'end_', 'loc_']]
    
    final_ordered_cols = [c for c in ordered_cols if c in final_wide.columns]
    final_wide = final_wide[final_ordered_cols]

    return "OK", _drop_useless_cols(final_wide), "\n".join(log_messages), daily_candidate_limit

def _drop_useless_cols(df: pd.DataFrame) -> pd.DataFrame:
    """
    ê°’ì´ í•˜ë‚˜ë„ ì—†ê±°ë‚˜(ì „ë¶€ NaN/ë¹ˆì¹¸) ì •ë³´ëŸ‰ì´ 0ì¸ ì—´ì„ ì œê±°í•œë‹¤.
    (loc_/start_/end_ ê°™ì€ ì´ë¦„ì´ë¼ë„ ì „ë¶€ ë¹„ì–´ ìˆìœ¼ë©´ ì‚­ì œ)
    """
    def useless(s: pd.Series) -> bool:
        return s.replace('', pd.NA).nunique(dropna=True) == 0
    return df.drop(columns=[c for c in df.columns if useless(df[c])])

def sort_activities_by_time(df: pd.DataFrame, activity_cols: list) -> list:
    """í™œë™(activity) ì»¬ëŸ¼ë“¤ì„ í‰ê·  ì‹œì‘ ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬"""
    avg_start_times = {}
    for act in activity_cols:
        start_col = f'start_{act}'
        if start_col in df.columns:
            # SettingWithCopyWarningì„ í”¼í•˜ê¸° ìœ„í•´ .loc ì‚¬ìš© ë° íƒ€ì… ë³€í™˜
            times = pd.to_datetime(df[start_col], errors='coerce').dropna()
            if not times.empty:
                avg_start_times[act] = times.mean()

    sorted_activities = sorted(avg_start_times.keys(), key=lambda k: avg_start_times[k])
    time_missing_activities = sorted([act for act in activity_cols if act not in avg_start_times])
    return sorted_activities + time_missing_activities

def solve(cfg_ui: dict, params: dict | None = None, *, debug: bool = False):
    """
    cfg_ui : core.build_config()ê°€ ë„˜ê¸´ UI ë°ì´í„° ë¬¶ìŒ(dict)
    params : ìŠ¤ì¼€ì¤„ë§ íŒŒë¼ë¯¸í„° (dict)
    ë°˜í™˜   : (status:str, wide:pd.DataFrame|None, logs:str)
    """
    import io, contextlib, traceback, sys
    import pandas as pd
    import streamlit as st
    from interview_opt_test_v4 import build_model

    logger = st.logger.get_logger("solver")

    # 0) ì§€ì›ì ë°ì´í„° ìœ ë¬´ ì²´í¬
    if "candidates_exp" not in cfg_ui or cfg_ui["candidates_exp"].empty:
        st.error("â›” ì§€ì›ì ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 'Candidates' í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return "NO_DATA", None, ""

    # --- room_cap vs activity.max_cap í•˜ë“œ-ê²€ì¦ -----------------
    room_types_ui = cfg_ui["activities"]["room_type"].dropna().unique()
    room_max = {}
    for _, rp in cfg_ui["room_plan"].iterrows():
        for rt in room_types_ui:
            col = f"{rt}_cap"
            if col in rp and pd.notna(rp[col]):
                room_max[rt] = max(room_max.get(rt, 0), int(rp[col]))
    bad = [
        (row.activity, row.max_cap, room_max.get(row.room_type, 0))
        for _, row in cfg_ui["activities"].iterrows()
        if "max_cap" in row and "room_type" in row and pd.notna(row.max_cap) and pd.notna(row.room_type) and row.max_cap > room_max.get(row.room_type, 0)
    ]
    if bad:
        msg = ", ".join(f"{a}(max {mc}>{rc})" for a,mc,rc in bad)
        st.error(f"â›” room_plan cap ë¶€ì¡±: {msg}")
        return "ERR", None, ""
    # ----------------------------------------------------------

    # ë‚ ì§œ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ: ì§€ì›ì ë‚ ì§œì™€ Room Plan ë‚ ì§œì˜ êµì§‘í•©ë§Œ ì‚¬ìš©
    df_raw_all = cfg_ui["candidates_exp"].copy()
    df_raw_all["interview_date"] = pd.to_datetime(df_raw_all["interview_date"])
    candidate_dates = set(df_raw_all["interview_date"].dt.date)

    room_plan_df = cfg_ui["room_plan"].copy()
    if "date" not in room_plan_df.columns:
        st.error("â›” 'Room Plan'ì— 'date' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return "ERR_NO_ROOM_DATE", None, ""
    room_plan_df["date"] = pd.to_datetime(room_plan_df["date"])
    room_plan_dates = set(room_plan_df["date"].dt.date)

    date_list_obj = sorted(list(candidate_dates.intersection(room_plan_dates)))

    if not date_list_obj:
        st.error(
            "**ì„¤ì • ì˜¤ë¥˜:** ì§€ì›ìê°€ ë°°ì •ëœ ë‚ ì§œì™€ 'Room Plan'ì— ì„¤ì •ëœ ë‚ ì§œê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "
            f"ì§€ì›ì ë‚ ì§œ: `{sorted(list(candidate_dates))}`, "
            f"Room Plan ë‚ ì§œ: `{sorted(list(room_plan_dates))}`. "
            "ë‘ ì„¤ì •ì˜ ë‚ ì§œê°€ ì ì–´ë„ í•˜ë£¨ëŠ” ì¼ì¹˜í•´ì•¼ ìŠ¤ì¼€ì¤„ë§ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        )
        return "NO_VALID_DATE", None, ""

    date_list = [pd.to_datetime(d) for d in date_list_obj]

    all_wide = []
    all_logs = []
    for the_date in date_list:
        # (1) í•˜ë£¨ì¹˜ ì§€ì›ìë§Œ í•„í„°
        day_df_raw = df_raw_all[df_raw_all["interview_date"] == the_date]

        # (2) ë‚´ë¶€ í‘œ 4ê°œ ìƒì„± (ê¸°ì¡´ ë¡œì§ ì¬í™œìš©)
        internal = _derive_internal_tables(cfg_ui, the_date, debug=debug)
        
        # ----------------------------------------------------------
        # build_modelì— í•„ìš”í•œ ë°ì´í„° êµ¬ì¡° ìƒì„±
        # ----------------------------------------------------------
        activities_df = cfg_ui['activities']
        act_info = {
            row['activity']: {
                'duration': int(row['duration_min']),
                'min_ppl': int(row.get('min_cap', 1)),
                'max_ppl': int(row.get('max_cap', 1)),
                'required_rooms': [row['room_type']]
            }
            for _, row in activities_df.iterrows()
        }

        candidate_info = {
            cid: {
                'job_code': group['code'].iloc[0],
                'activities': group['activity'].tolist()
            }
            for cid, group in day_df_raw.groupby('id')
        }

        cfg_avail_day = internal['cfg_avail'][internal['cfg_avail']['date'] == the_date]
        room_info = {
            row['loc']: {'capacity': int(row['capacity_max'])}
            for _, row in cfg_avail_day.iterrows()
        }

        cfg_oper_day = internal['cfg_oper'][internal['cfg_oper']['date'] == the_date]
        oper_hours = {}
        base_time = pd.to_datetime(the_date.date().strftime('%Y-%m-%d') + ' 00:00:00')
        for _, row in cfg_oper_day.iterrows():
            start_dt = pd.to_datetime(f"{the_date.date()} {row['start_time']}")
            end_dt = pd.to_datetime(f"{the_date.date()} {row['end_time']}")
            start_minutes = int((start_dt - base_time).total_seconds() / 60)
            end_minutes = int((end_dt - base_time).total_seconds() / 60)
            oper_hours[row['code']] = (start_minutes, end_minutes)
        
        rules = [
            (row['predecessor'], row['successor'], int(row.get('gap_min', 0)), bool(row.get('adjacent', False)))
            for _, row in cfg_ui['precedence'].iterrows()
        ]
        
        config = {
            **(params or {}),
            'the_date': the_date,
            'debug_mode': debug,
            'num_cpus': 8,
            'act_info': act_info,
            'candidate_info': candidate_info,
            'room_info': room_info,
            'oper_hours': oper_hours,
            'rules': rules,
            'min_gap_min': params.get('min_gap_min', 5) if params else 5,
            'time_limit_sec': 60.0
        }
        
        log_buf = io.StringIO()
        try:
            with contextlib.redirect_stdout(log_buf):
                model, status_name, final_report_df, logs = build_model(config, logger)
                if logs:
                    all_logs.extend(logs)
                wide = final_report_df
        except Exception:
            tb_str = traceback.format_exc()
            st.error("âŒ Solver exception:")
            st.code(tb_str)
            st.code(log_buf.getvalue())
            return "ERR", None, log_buf.getvalue()

        all_logs.append(log_buf.getvalue())
        if status_name not in ["OPTIMAL", "FEASIBLE"]:
            st.error(f"âš ï¸ Solver status: {status_name} (date {the_date.date()})")
            st.code(log_buf.getvalue())
            return status_name, None, "\n".join(all_logs)

        all_wide.append(wide)

    if not all_wide:
        st.info("â„¹ï¸ í•´ë‹¹ ì¡°ê±´ìœ¼ë¡œ ë°°ì¹˜ ê°€ëŠ¥í•œ ì§€ì›ìê°€ ì—†ìŠµë‹ˆë‹¤.")
        return "NO_FEASIBLE_DATE", None, "\n".join(all_logs)

    all_long = []
    for df_w in all_wide:
        id_vars = [c for c in df_w.columns if not (c.startswith('start_') or c.startswith('end_') or c.startswith('loc_'))]
        # end_D -> end_ ë¡œ ë¯¸ë¦¬ ë³€ê²½
        df_w.columns = df_w.columns.str.replace("end_D", "end_")
        
        activities_in_df = set()
        for c in df_w.columns:
            if c.startswith('start_'): activities_in_df.add(c.replace('start_',''))
            elif c.startswith('end_'): activities_in_df.add(c.replace('end_',''))
            elif c.startswith('loc_'): activities_in_df.add(c.replace('loc_',''))

        if not activities_in_df:
            continue

        df_l = pd.wide_to_long(df_w,
                               stubnames=['start', 'end', 'loc'],
                               i=id_vars,
                               j='activity',
                               sep='_',
                               suffix='(' + '|'.join(activities_in_df) + ')').reset_index()
        all_long.append(df_l)

    if not all_long:
        st.info("â„¹ï¸ ì¡°ê±´ì— ë§ëŠ” ìŠ¤ì¼€ì¤„ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return "NO_FEASIBLE_SCHEDULE", None, "\n".join(all_logs)

    final_long = pd.concat(all_long, ignore_index=True)
    
    final_wide = final_long.pivot_table(
        index=[c for c in final_long.columns if c not in ['activity', 'start', 'end', 'loc']],
        columns='activity',
        values=['start', 'end', 'loc']
    ).reset_index()

    final_wide.columns = [f'{v}_{c}' if c else v for v,c in final_wide.columns]
    
    activity_cols = sorted(list(final_long['activity'].unique()))
    # copy()ë¥¼ ì‚¬ìš©í•˜ì—¬ SettingWithCopyWarning ë°©ì§€
    sorted_activity_cols = sort_activities_by_time(final_wide.copy(), activity_cols)

    base_cols = [c for c in ['id', 'interview_date', 'code'] if c in final_wide.columns]
    ordered_cols = base_cols + [f'{prefix}{act}' for act in sorted_activity_cols for prefix in ['start_', 'end_', 'loc_']]
    
    final_ordered_cols = [c for c in ordered_cols if c in final_wide.columns]
    final_wide = final_wide[final_ordered_cols]
    
    return "OK", _drop_useless_cols(final_wide), "\n".join(all_logs)
