# solver/solver.py  â€“  UI ë°ì´í„°ë§Œìœ¼ë¡œ OR-Tools ì‹¤í–‰
from datetime import timedelta
import pandas as pd
import traceback, sys, streamlit as st
from interview_opt_test_v4 import build_model   # â† ì›ë³¸ ê±°ëŒ€í•œ í•¨ìˆ˜ ì¬ì‚¬ìš©
import contextlib, io
import yaml
from interview_opt_test_v4 import YAML_FILE
def df_to_yaml_dict(df: pd.DataFrame) -> dict:
    rules = []
    for r in df.itertuples(index=False):
        rule = {
            "predecessor": r.predecessor,
            "successor": r.successor,
            "min_gap_min": int(r.gap_min),
            "adjacent": bool(getattr(r, "adjacent", False))
        }
        rules.append(rule)
    return {"common": rules, "by_code": {}}








# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 0. ì‹œë‚˜ë¦¬ì˜¤(íŒŒë¼ë¯¸í„°) ê·¸ë¦¬ë“œ ë¡œë”  â˜… RunScheduler í˜ì´ì§€ì—ì„œ ì‚¬ìš©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import pandas as pd   # <= solver/solver.py ìƒë‹¨ import ë¶€ë¶„ì— ì´ë¯¸ ìˆë‹¤ë©´ ìƒëµ

def load_param_grid(csv_path: str = "parameter_grid_test_v4.csv") -> pd.DataFrame:
    """
    parameter_grid_test_v4.csv ë¥¼ ì½ì–´ì„œ ë¹ˆì¹¸ì€ '' ë¡œ ì±„ìš´ DataFrame ë°˜í™˜.
    RunScheduler í˜ì´ì§€ ë“œë¡­ë‹¤ìš´/ì‹¤í–‰ìš© ê³µí†µ í—¬í¼.
    """
    return pd.read_csv(csv_path).fillna("")
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _derive_internal_tables(cfg_ui: dict, *, debug: bool = False) -> dict:
    """
    Streamlit UI ê°’ìœ¼ë¡œë¶€í„° build_model ì´ ë°”ë¡œ ì“¸ 4ê°œ í‘œë¥¼ ìƒì„±.
    debug=True ì´ë©´ ë¸Œë¼ìš°ì €ì— cfg_map / cfg_avail ë¯¸ë¦¬ë³´ê¸° ì¶œë ¥.
    """
    import pandas as pd
    import streamlit as st

    # â‘  í™œë™ â†” ì†Œìš”ì‹œê°„ ----------------------------
    cfg_duration = cfg_ui["activities"][["activity", "duration_min"]].copy()

    # â–¶ room_type ëª©ë¡ì„ Activities í‘œì—ì„œ ìë™ ì¶”ì¶œ
    room_types_ui = cfg_ui["activities"]["room_type"].dropna().unique()

    # â‘¡ í™œë™ â†” loc(room_type) ----------------------
    base_map = cfg_ui["activities"][["activity", "room_type"]]

    if "space_avail" in cfg_ui and not cfg_ui["space_avail"].empty:
        # ì™¸ë¶€ì—ì„œ loc Â· cap ì´ ì´ë¯¸ ì¤€ë¹„ë¼ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ í™œìš©
        sa = cfg_ui["space_avail"]
        rows = [
            {"activity": act, "loc": loc}
            for _, row in base_map.iterrows()
            for act, base in [(row["activity"], row["room_type"])]
            for loc in sa["loc"].unique()
            if str(loc).startswith(base)
        ]
        cfg_map = pd.DataFrame(rows)
    else:
        # room_plan â†’ loc í­ë°œ (room_type ë™ì )
        rp, rows = cfg_ui["room_plan"], []
        for _, r in rp.iterrows():
            for base in room_types_ui:
                n = int(r.get(f"{base}_count", 0))
                if n == 0:
                    continue
                for i in range(1, n + 1):
                    loc = f"{base}{chr(64+i)}" if n > 1 else base
                    rows.append({"room_type": base, "loc": loc})
        exploded = pd.DataFrame(rows).drop_duplicates("loc")
        cfg_map = (
            base_map.merge(exploded, on="room_type", how="left")
                    .drop(columns=["room_type"])
        )

    # â‘¢ ë‚ ì§œÂ·ë°©ë³„ capacity --------------------------
    if "space_avail" in cfg_ui and not cfg_ui["space_avail"].empty:
        cfg_avail = cfg_ui["space_avail"][["loc", "date", "capacity_max"]].copy()
        cfg_avail["capacity_override"] = pd.NA
    else:
        rp, rows = cfg_ui["room_plan"], []
        for _, r in rp.iterrows():
            date = pd.to_datetime(r["date"])
            for base in room_types_ui:
                n   = int(r.get(f"{base}_count", 0))
                if n == 0:
                    continue
                cap = int(r.get(f"{base}_cap", 0))
                for i in range(1, n + 1):
                    loc = f"{base}{chr(64+i)}" if n > 1 else base
                    rows.append(
                        {"loc": loc, "date": date,
                         "capacity_max": cap, "capacity_override": pd.NA}
                    )
        cfg_avail = pd.DataFrame(rows)

    # â‘£ ì „í˜•(code) Ã— ë‚ ì§œë³„ ìš´ì˜ì‹œê°„ -----------------
    raw_oper = cfg_ui["oper_window"].copy()
    for old, new in [("start", "start_time"), ("end", "end_time")]:
        if old in raw_oper.columns and new in raw_oper.columns:
            raw_oper = raw_oper.drop(columns=[old])
    cfg_oper = (
        raw_oper.dropna(subset=["code", "date",
                                "start" if "start" in raw_oper.columns else "start_time",
                                "end"   if "end"   in raw_oper.columns else "end_time"])
                .query("code != ''")
                .drop_duplicates(["code", "date"])
                .reset_index(drop=True)
                .rename(columns={"start": "start_time", "end": "end_time"})
    )
    cfg_oper["date"] = pd.to_datetime(cfg_oper["date"])
    cfg_oper["start_time"] = cfg_oper["start_time"].astype(str)
    cfg_oper["end_time"]   = cfg_oper["end_time"].astype(str)

    # â”€â”€â”€â”€â”€â”€ ğŸ”  ë””ë²„ê·¸ ë¯¸ë¦¬ë³´ê¸° (ë¸Œë¼ìš°ì €) â”€â”€â”€â”€â”€â”€
    if debug:
        st.markdown("#### ğŸ `cfg_map` (activity â†” loc) â€“ ìƒìœ„ 20í–‰")
        st.dataframe(cfg_map.sort_values(["activity", "loc"]).head(20),
                     use_container_width=True)

        first_date = cfg_avail["date"].min()
        st.markdown(f"#### ğŸ `cfg_avail` ({first_date.date()} ê¸°ì¤€) â€“ ìƒìœ„ 20í–‰")
        st.dataframe(cfg_avail.loc[cfg_avail["date"] == first_date]
                               .sort_values("loc").head(20),
                     use_container_width=True)
        st.markdown("---")

    # ê²°ê³¼ ë°˜í™˜ --------------------------------------
    return dict(
        cfg_duration=cfg_duration,
        cfg_map=cfg_map,
        cfg_avail=cfg_avail,
        cfg_oper=cfg_oper,
        group_meta=cfg_ui["activities"].copy(),   # ì¶”ê°€ í•„ë“œ
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â˜… ë¹ˆ ì¹¼ëŸ¼ ìë™ ì‚­ì œìš© í—¬í¼ â˜…
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _drop_useless_cols(df: pd.DataFrame) -> pd.DataFrame:
    """
    ê°’ì´ í•˜ë‚˜ë„ ì—†ê±°ë‚˜(ì „ë¶€ NaN/ë¹ˆì¹¸) ì •ë³´ëŸ‰ì´ 0ì¸ ì—´ì„ ì œê±°í•œë‹¤.
    (loc_/start_/end_ ê°™ì€ ì´ë¦„ì´ë¼ë„ ì „ë¶€ ë¹„ì–´ ìˆìœ¼ë©´ ì‚­ì œ)
    """
    def useless(s: pd.Series) -> bool:
        return s.replace('', pd.NA).nunique(dropna=True) == 0
    return df.drop(columns=[c for c in df.columns if useless(df[c])])
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) ìµœìƒìœ„ í˜¸ì¶œ í•¨ìˆ˜ â€“ Streamlitì—ì„œ ì—¬ê¸°ë§Œ ì‚¬ìš©
#    â˜… ì—¬ëŸ¬ ë‚ ì§œ(6/4â€¥6/7 ë“±)ë¥¼ ëª¨ë‘ ì²˜ë¦¬í•˜ë„ë¡ ìˆ˜ì • ë²„ì „ â˜…
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def solve(cfg_ui: dict, params: dict | None = None, *, debug: bool = False):
    """
    cfg_ui : core.build_config()ê°€ ë„˜ê¸´ UI ë°ì´í„° ë¬¶ìŒ(dict)
    params : wave_lenÂ·max_wave â€¦ ë“± ì‹œë‚˜ë¦¬ì˜¤ í•œ ì¤„(dict)
    ë°˜í™˜   : (status:str, wide:pd.DataFrame|None)
    """
    import io, contextlib, traceback, sys
    import pandas as pd
    import streamlit as st
    from interview_opt_test_v4 import build_model

    # 0) ì§€ì›ì ë°ì´í„° ìœ ë¬´ ì²´í¬
    if cfg_ui["candidates_exp"].empty:
        st.error("â›” ì§€ì›ì ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return "NO_DATA", None

    # --- room_cap vs activity.max_cap í•˜ë“œ-ê²€ì¦ -----------------
    room_types_ui = cfg_ui["activities"]["room_type"].dropna().unique()
    room_max = {}
    for _, rp in cfg_ui["room_plan"].iterrows():
        for rt in room_types_ui:
            col = f"{rt}_cap"
            if col in rp and pd.notna(rp[col]):
                room_max[rt] = max(room_max.get(rt, 0), int(rp[col]))
    bad = [
        (row.activity, row.max_cap, room_max.get(row.room_type, 0))
        for _, row in cfg_ui["activities"].iterrows()
        if row.max_cap > room_max.get(row.room_type, 0)
    ]
    if bad:
        msg = ", ".join(f"{a}(max {mc}>{rc})" for a,mc,rc in bad)
        st.error(f"â›” room_plan cap ë¶€ì¡±: {msg}")
        return "ERR", None
    # ----------------------------------------------------------

    # ë‚ ì§œ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ (ì—¬ëŸ¬ ë‚ ì§œ í•œêº¼ë²ˆì—)
    df_raw_all = cfg_ui["candidates_exp"].copy()
    df_raw_all["interview_date"] = pd.to_datetime(df_raw_all["interview_date"])
    date_list = sorted(df_raw_all["interview_date"].unique())

    all_wide = []
    for the_date in date_list:
        # (1) í•˜ë£¨ì¹˜ ì§€ì›ìë§Œ í•„í„°
        day_df_raw = df_raw_all[df_raw_all["interview_date"] == the_date]

        # (2) ë‚´ë¶€ í‘œ 4ê°œ ìƒì„± & df_raw ì£¼ì…
        internal = _derive_internal_tables(cfg_ui, debug=debug)
        internal["df_raw"] = day_df_raw
        
        # (3) precedence ë£°ì„ YAML í˜•ì‹ìœ¼ë¡œ (í† í° ë£°ì„ í™•ì¥í•œ ë’¤)
        prec_yaml_ui = df_to_yaml_dict(cfg_ui["precedence"])

        # (5) build_model í˜¸ì¶œìš© merged dict êµ¬ì„±
        merged = {**internal, **cfg_ui}
        merged["prec_yaml"] = prec_yaml_ui

        # ìº¡ì²˜ ì¤€ë¹„
        f = io.StringIO()

        # â”€â”€ (ë””ë²„ê·¸) build_model ì§ì „ í…Œì´ë¸” í™•ì¸
        if debug:
            st.markdown("##### ğŸ build_model í˜¸ì¶œ ì§ì „ ìŠ¤ëƒ…ìƒ·")
            st.dataframe(internal["cfg_map"].head(20), use_container_width=True)
            st.dataframe(
                internal["cfg_avail"].query("date == @the_date").head(20),
                use_container_width=True
            )
            st.dataframe(day_df_raw.head(30), use_container_width=True)
            st.markdown("---")

        # (6) ì‹¤ì œ OR-Tools ëª¨ë¸ ì‹¤í–‰
        try:
            with contextlib.redirect_stdout(f):
                status, wide = build_model(the_date, params or {}, merged)
        except Exception:
            tb_str = traceback.format_exc()
            st.error("âŒ Solver exception:")
            st.code(tb_str)
            st.code(f.getvalue())
            return "ERR", None

        # (7) í•˜ë£¨ì¹˜ ì‹¤íŒ¨ â†’ ì „ì²´ ì‹¤íŒ¨
        if status != "OK":
            st.error(f"âš ï¸ Solver status: {status} (date {the_date.date()})")
            st.code(f.getvalue())
            return status, None

        all_wide.append(wide)

    # â”€â”€ ëª¨ë“  ë‚ ì§œ ì„±ê³µ ì‹œ: í•˜ë‚˜ë¡œ í•©ì³ ë°˜í™˜
    full_wide = pd.concat(all_wide, ignore_index=True)
    full_wide = _drop_useless_cols(full_wide)

    if debug:
        print("[solver.solve] dates:", date_list, file=sys.stderr)

    return "OK", full_wide
