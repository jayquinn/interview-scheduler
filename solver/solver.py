# solver/solver.py  â€“  UI ë°ì´í„°ë§Œìœ¼ë¡œ OR-Tools ì‹¤í–‰
from datetime import timedelta, datetime
import pandas as pd
import traceback, sys, streamlit as st
from interview_opt_test_v4 import build_model
import contextlib, io
from pathlib import Path
import string
from .three_stage_optimizer import solve_with_three_stages



def _derive_internal_tables(cfg_ui: dict, the_date: pd.Timestamp, *, debug: bool = False) -> dict:
    """
    Streamlit UI ê°’ìœ¼ë¡œë¶€í„° build_model ì´ ë°”ë¡œ ì“¸ 4ê°œ í‘œë¥¼ ìƒì„±.
    debug=True ì´ë©´ ë¸Œë¼ìš°ì €ì— cfg_map / cfg_avail ë¯¸ë¦¬ë³´ê¸° ì¶œë ¥.
    """
    import pandas as pd
    import streamlit as st

    # â‘  í™œë™ â†” ì†Œìš”ì‹œê°„ ----------------------------
    cfg_duration = cfg_ui["activities"][["activity", "duration_min"]].copy()

    # â–¶ room_type ëª©ë¡ì„ Activities í‘œì—ì„œ ìë™ ì¶”ì¶œ
    room_types_ui = cfg_ui["activities"]["room_type"].dropna().unique()

    # â‘¡ í™œë™ â†” loc(room_type) ----------------------
    base_map = cfg_ui["activities"][["activity", "room_type"]]

    if "space_avail" in cfg_ui and not cfg_ui["space_avail"].empty:
        sa = cfg_ui["space_avail"]
        rows = [
            {"activity": act, "loc": loc}
            for _, row in base_map.iterrows()
            for act, base in [(row["activity"], row["room_type"])]
            for loc in sa["loc"].unique()
            if str(loc).startswith(base)
        ]
        cfg_map = pd.DataFrame(rows)
    else:
        rp, rows = cfg_ui["room_plan"], []
        for _, r in rp.iterrows():
            for base in room_types_ui:
                n = int(r.get(f"{base}_count", 0))
                if n == 0:
                    continue
                for i in range(1, n + 1):
                    if n > 1:
                        suffix = string.ascii_uppercase[i-1]
                        loc = f"{base}{suffix}"
                    else:
                        loc = base
                    rows.append({"room_type": base, "loc": loc})
        
        exploded = pd.DataFrame(rows, columns=['room_type', 'loc']).drop_duplicates("loc") if rows else pd.DataFrame(columns=['room_type', 'loc'])

        cfg_map = (
            base_map.merge(exploded, on="room_type", how="left")
                    .drop(columns=["room_type"])
        )
        if cfg_map['loc'].isnull().any():
            failed_acts = cfg_map[cfg_map['loc'].isnull()]['activity'].unique().tolist()
            st.error(f"**ì„¤ì • ì˜¤ë¥˜:** ë‹¤ìŒ í™œë™ì— í• ë‹¹ëœ ì¥ì†Œ(Room Type)ë¥¼ 'Room Plan'ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: **`{', '.join(failed_acts)}`**. 'Activities' í˜ì´ì§€ì™€ 'Room Plan' í˜ì´ì§€ì˜ Room Type ì´ë¦„ì´ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”. (ì˜ˆ: 'ì‹¬ì¸µë©´ì ‘ì‹¤'ì€ ë™ì¼í•´ì•¼ í•¨)")
            st.stop()

    # â‘¢ ë‚ ì§œÂ·ë°©ë³„ capacity --------------------------
    if "space_avail" in cfg_ui and not cfg_ui["space_avail"].empty:
        cfg_avail = cfg_ui["space_avail"][["loc", "date", "capacity_max"]].copy()
        cfg_avail["capacity_override"] = pd.NA
    else:
        rp, rows = cfg_ui["room_plan"], []
        for _, r in rp.iterrows():
            date = pd.to_datetime(r["date"])
            for base in room_types_ui:
                n   = int(r.get(f"{base}_count", 0))
                if n == 0:
                    continue
                cap = int(r.get(f"{base}_cap", 1))
                for i in range(1, n + 1):
                    if n > 1:
                        suffix = string.ascii_uppercase[i-1]
                        loc = f"{base}{suffix}"
                    else:
                        loc = base
                    rows.append(
                        {"loc": loc, "date": date,
                         "capacity_max": cap, "capacity_override": pd.NA}
                    )
        cfg_avail = pd.DataFrame(rows)

    # â‘£ ì „í˜•(code) Ã— ë‚ ì§œë³„ ìš´ì˜ì‹œê°„ -----------------
    raw_oper = cfg_ui["oper_window"].copy()
    for old, new in [("start", "start_time"), ("end", "end_time")]:
        if old in raw_oper.columns and new in raw_oper.columns:
            raw_oper = raw_oper.drop(columns=[old])
    cfg_oper = (
        raw_oper.dropna(subset=["code", "date",
                                "start" if "start" in raw_oper.columns else "start_time",
                                "end"   if "end"   in raw_oper.columns else "end_time"])
                .query("code != ''")
                .drop_duplicates(["code", "date"])
                .reset_index(drop=True)
                .rename(columns={"start": "start_time", "end": "end_time"})
    )
    cfg_oper["date"] = pd.to_datetime(cfg_oper["date"])
    cfg_oper["start_time"] = cfg_oper["start_time"].astype(str)
    cfg_oper["end_time"]   = cfg_oper["end_time"].astype(str)

    # â”€â”€â”€â”€â”€â”€ ğŸ”  ë””ë²„ê·¸ ë¯¸ë¦¬ë³´ê¸° (ë¸Œë¼ìš°ì €) â”€â”€â”€â”€â”€â”€
    if debug:
        st.markdown("---")
        st.markdown(f"### ğŸ ë””ë²„ê·¸ ì •ë³´ (ì²˜ë¦¬ ë‚ ì§œ: {the_date.date()})")
        st.markdown("#### `cfg_map` (activity â†” loc) â€“ ìƒìœ„ 20í–‰")
        st.dataframe(cfg_map.sort_values(["activity", "loc"]).head(20),
                     use_container_width=True)

        st.markdown("#### `cfg_avail` â€“ ìƒìœ„ 20í–‰")
        cfg_avail_today = cfg_avail[cfg_avail['date'] == the_date]
        
        if not cfg_avail_today.empty:
            st.dataframe(cfg_avail_today.sort_values("loc").head(20),
                     use_container_width=True)
        else:
            st.markdown(f"**ê²½ê³ :** `{the_date.date()}`ì— í•´ë‹¹í•˜ëŠ” ì¥ì†Œ(Room) ì •ë³´ê°€ 'Room Plan'ì— ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("---")

    # ê²°ê³¼ ë°˜í™˜ --------------------------------------
    return dict(
        cfg_duration=cfg_duration,
        cfg_map=cfg_map,
        cfg_avail=cfg_avail,
        cfg_oper=cfg_oper,
        group_meta=cfg_ui["activities"].copy(),
    )

def generate_virtual_candidates(job_acts_map: pd.DataFrame) -> pd.DataFrame:
    """'ì§ë¬´ë³„ ë©´ì ‘í™œë™' ì„¤ì •ìœ¼ë¡œë¶€í„° ê°€ìƒ ì§€ì›ì ëª©ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    all_candidates = []
    for _, row in job_acts_map.iterrows():
        code = row['code']
        count = int(row['count'])
        activities = [act for act, required in row.items() if act not in ['code', 'count'] and required]
        
        for i in range(1, count + 1):
            candidate_id = f"{code}_{str(i).zfill(3)}"
            for act in activities:
                all_candidates.append({'id': candidate_id, 'code': code, 'activity': act})
    
    if not all_candidates:
        return pd.DataFrame(columns=['id', 'code', 'activity'])

    return pd.DataFrame(all_candidates)

def _calculate_dynamic_daily_limit(
    room_plan_tpl: pd.DataFrame, 
    oper_window_tpl: pd.DataFrame, 
    activities_df: pd.DataFrame, 
    job_acts_map: pd.DataFrame,
    precedence_df: pd.DataFrame = None  # ì¶”ê°€: ì„ í›„í–‰ ì œì•½ ì •ë³´
) -> int:
    """ì‚¬ìš© ê°€ëŠ¥í•œ ìì›(ì‹œê°„, ê³µê°„)ê³¼ ì§€ì›ìë³„ í•„ìš” ìì›ì„ ê¸°ë°˜ìœ¼ë¡œ ì¼ì¼ ì²˜ë¦¬ ê°€ëŠ¥ ì¸ì›ì„ ë™ì ìœ¼ë¡œ ì¶”ì •í•©ë‹ˆë‹¤."""
    from datetime import date, datetime
    
    # 1. ì´ ê°€ìš© ì‹œê°„ ê³„ì‚°
    start_time_str = oper_window_tpl['start_time'].iloc[0]
    end_time_str = oper_window_tpl['end_time'].iloc[0]

    if isinstance(start_time_str, str):
        start_time = pd.to_datetime(start_time_str).time()
    else:
        start_time = start_time_str

    if isinstance(end_time_str, str):
        end_time = pd.to_datetime(end_time_str).time()
    else:
        end_time = end_time_str

    if not start_time or not end_time:
        return 20 # Fallback

    total_oper_minutes = (datetime.combine(date.min, end_time) - datetime.combine(date.min, start_time)).total_seconds() / 60
    
    room_types = activities_df.query("use==True")['room_type'].dropna().unique()
    total_room_minutes = 0
    for rt in room_types:
        count_col = f"{rt}_count"
        if count_col in room_plan_tpl:
            try:
                num_rooms = pd.to_numeric(room_plan_tpl[count_col].iloc[0], errors='coerce')
                if pd.notna(num_rooms):
                    total_room_minutes += num_rooms * total_oper_minutes
            except (ValueError, IndexError):
                pass
            
    if total_room_minutes <= 0:
        return 20

    # 2. ì§€ì›ì 1ëª…ë‹¹ í‰ê·  í•„ìš” ì‹œê°„ ê³„ì‚°
    job_acts_map_copy = job_acts_map.copy()
    
    if 'total_duration' not in job_acts_map_copy.columns:
        job_acts_map_copy['total_duration'] = 0
        for idx, row in job_acts_map_copy.iterrows():
            total_duration = 0
            activities = [act for act, required in row.items() if required and act not in ['code', 'count', 'total_duration']]
            
            for act_name in activities:
                act_info = activities_df[activities_df['activity'] == act_name]
                if not act_info.empty:
                    duration = act_info['duration_min'].iloc[0]
                    total_duration += duration
            job_acts_map_copy.loc[idx, 'total_duration'] = total_duration

    total_applicants = job_acts_map_copy['count'].sum()
    if total_applicants == 0:
        return 20
        
    weighted_avg_duration = (job_acts_map_copy['total_duration'] * job_acts_map_copy['count']).sum() / total_applicants
    
    if weighted_avg_duration <= 0:
        return 20

    # 3. ì¼ì¼ ì²˜ë¦¬ ê°€ëŠ¥ ì¸ì› ì¶”ì‚° (ì•ˆì „ ë§ˆì§„ 80% ì ìš©)
    daily_capacity = int((total_room_minutes / weighted_avg_duration) * 0.8)
    
    # 3-1. batched ëª¨ë“œê°€ ìˆì„ ë•Œ ì¶”ê°€ ì œì•½ ê³ ë ¤
    if 'mode' in activities_df.columns:
        batched_acts = activities_df[activities_df['mode'] == 'batched']
        if not batched_acts.empty:
            # batched í™œë™ì˜ ë³‘ëª© ê³„ì‚°
            group_size = int(batched_acts.iloc[0]['max_cap'])
            
            # Adjacent ì œì•½ì´ ìˆëŠ” batched â†’ parallel â†’ individual íë¦„ ê°ì§€
            has_complex_adjacent = False
            if precedence_df is not None and not precedence_df.empty and 'adjacent' in precedence_df.columns:
                # batched â†’ parallel/individual adjacent ì²´ì¸ í™•ì¸
                for _, rule in precedence_df.iterrows():
                    if rule.get('adjacent', False):
                        pred = rule['predecessor']
                        succ = rule['successor']
                        
                        pred_act = activities_df[activities_df['activity'] == pred]
                        succ_act = activities_df[activities_df['activity'] == succ]
                        
                        if not pred_act.empty and not succ_act.empty:
                            pred_mode = pred_act.iloc[0].get('mode', 'individual')
                            succ_mode = succ_act.iloc[0].get('mode', 'individual')
                            pred_cap = int(pred_act.iloc[0].get('max_cap', 1))
                            succ_cap = int(succ_act.iloc[0].get('max_cap', 1))
                            
                            # ì§„ì§œ ë¬¸ì œê°€ ë˜ëŠ” ê²½ìš°ë§Œ ê°ì§€
                            # 1. Batched â†’ Individual adjacent (ê·¸ë£¹ í¬ê¸° > individual ë°© ìˆ˜)
                            if pred_mode == 'batched' and succ_mode == 'individual':
                                succ_room_type = succ_act.iloc[0]['room_type']
                                count_col = f"{succ_room_type}_count"
                                if count_col in room_plan_tpl.columns:
                                    succ_room_count = int(room_plan_tpl[count_col].iloc[0])
                                    if group_size > succ_room_count:
                                        has_complex_adjacent = True
                                        break
                            # 2. Parallel â†’ Individual adjacent (parallel ìš©ëŸ‰ > individual ë°© ìˆ˜)
                            elif pred_mode == 'parallel' and succ_mode == 'individual':
                                succ_room_type = succ_act.iloc[0]['room_type']
                                count_col = f"{succ_room_type}_count"
                                if count_col in room_plan_tpl.columns:
                                    succ_room_count = int(room_plan_tpl[count_col].iloc[0])
                                    # ë°œí‘œì¤€ë¹„(2ëª…) â†’ ë°œí‘œë©´ì ‘(2ê°œ ë°©)ì€ OK
                                    if pred_cap > succ_room_count:
                                        has_complex_adjacent = True
                                        break
            
            bottlenecks = []
            for _, act in activities_df.iterrows():
                if not act['use']:
                    continue
                    
                room_type = act['room_type']
                duration = act['duration_min']
                mode = act.get('mode', 'individual')
                
                # ë°© ê°œìˆ˜ ê°€ì ¸ì˜¤ê¸°
                count_col = f"{room_type}_count"
                if count_col in room_plan_tpl.columns:
                    room_count = int(room_plan_tpl[count_col].iloc[0])
                    room_cap = int(room_plan_tpl.get(f"{room_type}_cap", 1).iloc[0])
                    
                    # í•˜ë£¨ ë™ì•ˆ ì²˜ë¦¬ ê°€ëŠ¥í•œ ìŠ¬ë¡¯ ìˆ˜
                    slots_per_day = int(total_oper_minutes // duration)
                    
                    if mode == 'batched':
                        # batched: ê·¸ë£¹ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
                        groups_per_slot = room_count  # ê° ë°©ì— 1ê·¸ë£¹ì”©
                        max_groups_per_day = slots_per_day * groups_per_slot
                        max_people_per_day = max_groups_per_day * group_size
                    elif mode == 'parallel':
                        # parallel: ë°© ìš©ëŸ‰ë§Œí¼ ë™ì‹œ ì²˜ë¦¬
                        max_people_per_day = slots_per_day * room_count * room_cap
                    else:  # individual
                        # individual: 1ëª…ì”© ì²˜ë¦¬
                        max_people_per_day = slots_per_day * room_count
                    
                    bottlenecks.append(max_people_per_day)
            
            # ê°€ì¥ ì‘ì€ ë³‘ëª©ì„ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì •
            if bottlenecks:
                batched_capacity = int(min(bottlenecks) * 0.8)
                
                # Adjacent ì œì•½ì´ ìˆëŠ” ë³µì¡í•œ íë¦„ì´ë©´ ì¶”ê°€ë¡œ 20% ê°ì†Œ (50%ëŠ” ë„ˆë¬´ ê³¼ë„í•¨)
                if has_complex_adjacent:
                    batched_capacity = int(batched_capacity * 0.8)
                    
                # ê·¸ë£¹ í¬ê¸°ì˜ ë°°ìˆ˜ë¡œ ì¡°ì • (batched â†’ parallel â†’ individual íë¦„ ìµœì í™”)
                # í•˜ë£¨ì— ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ì™„ì „í•œ ê·¸ë£¹ ìˆ˜ë§Œ í—ˆìš©
                if group_size > 0:
                    complete_groups = batched_capacity // group_size
                    # ìµœì†Œê°’ ì œí•œ ì—†ì´ ê³„ì‚°ëœ ê·¸ë£¹ ìˆ˜ ì‚¬ìš©
                    if complete_groups < 1:
                        complete_groups = 1  # ìµœì†Œ 1ê°œ ê·¸ë£¹ì€ ë³´ì¥
                    batched_capacity = complete_groups * group_size
                    
                daily_capacity = min(daily_capacity, batched_capacity)
    
    return max(10, daily_capacity)

def solve_for_days(cfg_ui: dict, params: dict, debug: bool):
    """
    ìµœì†Œ ìš´ì˜ì¼ì„ ì¶”ì •í•˜ê¸° ìœ„í•œ ë©”ì¸ ì†”ë²„ í•¨ìˆ˜.
    Day 1ë¶€í„° ì‹œì‘í•˜ì—¬ ëª¨ë“  ì§€ì›ìê°€ ë°°ì •ë  ë•Œê¹Œì§€ ë‚ ì§œë¥¼ ëŠ˜ë ¤ê°€ë©° ì‹œë„.
    batched ëª¨ë“œê°€ ìˆìœ¼ë©´ 3ë‹¨ê³„ ìµœì í™”ë¥¼ ìˆ˜í–‰.
    """
    logger = st.logger.get_logger("solver")
    
    # 1. ê°€ìƒ ì§€ì›ì ìƒì„±
    job_acts_map = cfg_ui.get("job_acts_map")
    if job_acts_map is None or job_acts_map.empty:
        st.error("â›” 'â‘¡ ì§ë¬´ë³„ ë©´ì ‘í™œë™'ì—ì„œ ì¸ì›ìˆ˜ ì„¤ì •ì„ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.")
        return "NO_JOB_DATA", None, "ì§ë¬´ë³„ ì¸ì› ì •ë³´ ì—†ìŒ", 0
        
    candidates_df = generate_virtual_candidates(job_acts_map)
    if candidates_df.empty:
        st.info("ì²˜ë¦¬í•  ì§€ì›ì ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return "NO_CANDIDATES", None, "ì§€ì›ì ì—†ìŒ", 0
    
    # ë””ë²„ê·¸ í—¬í¼ ì´ˆê¸°í™” (candidates_dfê°€ ìƒì„±ëœ í›„)
    debug_helper = None
    if debug:
        from utils.debug_helper import SchedulingDebugHelper
        debug_helper = SchedulingDebugHelper()
        debug_log_file = debug_helper.start_session(cfg_ui)
        logger.info(f"ë””ë²„ê·¸ ë¡œê·¸ íŒŒì¼: {debug_log_file}")
        debug_helper.log("INFO", "ìŠ¤ì¼€ì¤„ë§ ì‹œì‘", {"total_candidates": len(candidates_df)})

    # 2. ê³ ì • ì„¤ì •ê°’ ì¤€ë¹„ (í…œí”Œë¦¿)
    room_plan_tpl = cfg_ui.get("room_plan")
    oper_window_tpl = cfg_ui.get("oper_window")
    activities_df = cfg_ui.get("activities")
    rules = cfg_ui.get('precedence', pd.DataFrame())
    
    if room_plan_tpl is None or room_plan_tpl.empty:
        st.error("â›” 'â‘¢ ìš´ì˜ê³µê°„ì„¤ì •'ì—ì„œ ê³µê°„ í…œí”Œë¦¿ ì„¤ì •ì„ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.")
        return "NO_ROOM_PLAN", None, "ìš´ì˜ ê³µê°„ í…œí”Œë¦¿ ì—†ìŒ", 0
    if oper_window_tpl is None or oper_window_tpl.empty:
        st.error("â›” 'â‘£ ìš´ì˜ì‹œê°„ì„¤ì •'ì—ì„œ ì‹œê°„ í…œí”Œë¦¿ ì„¤ì •ì„ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.")
        return "NO_OPER_WINDOW", None, "ìš´ì˜ ì‹œê°„ í…œí”Œë¦¿ ì—†ìŒ", 0

    # +++ ë™ì  ì¼ì¼ ì²˜ë¦¬ëŸ‰ ê³„ì‚° +++
    daily_candidate_limit = 0
    try:
        daily_candidate_limit = _calculate_dynamic_daily_limit(
            room_plan_tpl=room_plan_tpl,
            oper_window_tpl=oper_window_tpl,
            activities_df=activities_df.query("use==True"),
            job_acts_map=job_acts_map,
            precedence_df=rules
        )
    except Exception as e:
        logger.warning(f"ë™ì  ì¼ì¼ ì²˜ë¦¬ëŸ‰ ê³„ì‚° ì‹¤íŒ¨: {e}. ê¸°ë³¸ê°’(70)ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        daily_candidate_limit = 70
    # ++++++++++++++++++++++++++++++
    
    # batched ëª¨ë“œ í™•ì¸
    has_batched = False
    if 'mode' in activities_df.columns:
        has_batched = any(activities_df['mode'] == 'batched')
    
    if has_batched:
        log_messages = ["ì§‘ë‹¨ë©´ì ‘(batched) ëª¨ë“œê°€ ê°ì§€ë˜ì–´ 3ë‹¨ê³„ ìµœì í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."]
    else:
        log_messages = []

    # 3. ë‚ ì§œë¥¼ ëŠ˜ë ¤ê°€ë©° ìŠ¤ì¼€ì¤„ë§ ì‹œë„
    all_scheduled_cands_long = pd.DataFrame()
    
    max_days = 30
    all_scheduled_ids = set()
    
    # ì „ì²´ ê·¸ë£¹ ì •ë³´ ëˆ„ì 
    all_group_info = {
        'member_to_group': {},
        'group_sizes': {}
    }
    
    for day_num in range(1, max_days + 1):
        the_date = pd.to_datetime("2025-01-01") + timedelta(days=day_num - 1)

        unscheduled_cands = candidates_df[~candidates_df['id'].isin(all_scheduled_ids)]
        if unscheduled_cands.empty:
            log_messages.append("âœ… ëª¨ë“  ì§€ì›ì ë°°ì • ì™„ë£Œ. ì‹œë®¬ë ˆì´ì…˜ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        candidate_ids_for_day = unscheduled_cands['id'].unique()[:daily_candidate_limit]
        cands_to_schedule_df = unscheduled_cands[unscheduled_cands['id'].isin(candidate_ids_for_day)]

        candidate_info = {
            cid: {'job_code': group['code'].iloc[0], 'activities': group['activity'].tolist()}
            for cid, group in cands_to_schedule_df.groupby('id')
        }

        room_types = activities_df.query("use==True")['room_type'].dropna().unique()
        room_info_list = []
        for rt in room_types:
            count = int(room_plan_tpl.get(f"{rt}_count", 0).iloc[0])
            cap = int(room_plan_tpl.get(f"{rt}_cap", 1).iloc[0])
            
            if count == 1:
                room_info_list.append({'loc': rt, 'capacity': cap})
            else:
                # ì—¬ëŸ¬ ê°œì¸ ê²½ìš° ì•ŒíŒŒë²³ ì ‘ë¯¸ì‚¬ ì‚¬ìš© (A, B, C...)
                for i in range(count):
                    suffix = string.ascii_uppercase[i]
                    loc = f"{rt}{suffix}"
                    room_info_list.append({'loc': loc, 'capacity': cap})
                    
        room_info = {row['loc']: {'capacity': row['capacity']} for row in room_info_list}

        act_info = {
            row['activity']: {
                'duration': int(row['duration_min']),
                'required_rooms': [row['room_type']]
            }
            for _, row in activities_df.iterrows() if row['use']
        }
        
        base_time = pd.to_datetime('00:00:00').time()
        start_time_str = oper_window_tpl['start_time'].iloc[0]
        end_time_str = oper_window_tpl['end_time'].iloc[0]
        
        start_dt = datetime.combine(the_date.date(), pd.to_datetime(start_time_str).time())
        end_dt = datetime.combine(the_date.date(), pd.to_datetime(end_time_str).time())
        start_minutes = int((start_dt - datetime.combine(the_date.date(), base_time)).total_seconds() / 60)
        end_minutes = int((end_dt - datetime.combine(the_date.date(), base_time)).total_seconds() / 60)
        
        oper_hours = {code: (start_minutes, end_minutes) for code in job_acts_map['code'].unique()}
        
        config = {
            'the_date': the_date,
            'min_gap_min': params.get('min_gap_min', 5),
            'act_info': act_info,
            'candidate_info': candidate_info,
            'room_info': room_info,
            'oper_hours': oper_hours,
            'rules': [tuple(x) for x in rules.to_records(index=False)],
            'debug_mode': debug,
            'num_cpus': params.get('num_cpus', 8),
            'optimize_for_max_scheduled': True,
            'time_limit_sec': 60.0
        }
        
        log_messages.append(f"--- Day {day_num} ({the_date.date()}) ---")
        log_messages.append(f"ì¼ì¼ ìµœëŒ€ ì²˜ë¦¬ ê°€ëŠ¥ ì¸ì›: {daily_candidate_limit}ëª…")
        log_messages.append(f"ì‹œë„ ëŒ€ìƒ ì§€ì›ì ìˆ˜: {len(candidate_info)}")

        # batched ëª¨ë“œê°€ ìˆìœ¼ë©´ 3ë‹¨ê³„ ìµœì í™” ì‚¬ìš©
        if has_batched:
            log_messages.append(f"Batched ëª¨ë“œ ê°ì§€ - 3ë‹¨ê³„ ìµœì í™” ì‚¬ìš©")
            # 3ë‹¨ê³„ ìµœì í™”ë¥¼ ìœ„í•œ ì¶”ê°€ íŒŒë¼ë¯¸í„° ì„¤ì •
            cfg_ui_day = cfg_ui.copy()
            cfg_ui_day['candidates_for_day'] = cands_to_schedule_df
            
            result = solve_with_three_stages(
                cfg_ui_day, params, the_date, cands_to_schedule_df, debug
            )
            
            log_messages.append(f"3ë‹¨ê³„ ìµœì í™” ê²°ê³¼ ê¸¸ì´: {len(result)}")
            
            # 3-stage optimizerê°€ 4ê°œì˜ ê°’ì„ ë°˜í™˜í•˜ëŠ” ê²½ìš°ì™€ 3ê°œë¥¼ ë°˜í™˜í•˜ëŠ” ê²½ìš° ëª¨ë‘ ì²˜ë¦¬
            if len(result) == 4:
                status, wide_df, stage_logs, group_info = result
                log_messages.append(f"ê·¸ë£¹ ì •ë³´ ë°˜í™˜ë¨: {group_info is not None}")
                if group_info is not None:
                    log_messages.append(f"  - member_to_group í¬ê¸°: {len(group_info.get('member_to_group', {}))}")
                    log_messages.append(f"  - group_sizes í¬ê¸°: {len(group_info.get('group_sizes', {}))}")
                
                # ì´ë²ˆ ë‚ ì§œì˜ ê·¸ë£¹ ì •ë³´ë¥¼ ì „ì²´ ê·¸ë£¹ ì •ë³´ì— ëˆ„ì 
                if group_info and group_info.get('member_to_group'):
                    # ê·¸ë£¹ ë²ˆí˜¸ ì˜¤í”„ì…‹ ê³„ì‚° (ê¸°ì¡´ ê·¸ë£¹ ìˆ˜ + 1ë¶€í„° ì‹œì‘)
                    existing_groups = max(all_group_info['group_sizes'].keys()) if all_group_info['group_sizes'] else 0
                    
                    # member_to_group ì—…ë°ì´íŠ¸ (ê·¸ë£¹ ë²ˆí˜¸ ì¡°ì •)
                    for member, group_num in group_info.get('member_to_group', {}).items():
                        all_group_info['member_to_group'][member] = group_num + existing_groups
                    
                    # group_sizes ì—…ë°ì´íŠ¸ (ê·¸ë£¹ ë²ˆí˜¸ ì¡°ì •)
                    for group_num, size in group_info.get('group_sizes', {}).items():
                        all_group_info['group_sizes'][group_num + existing_groups] = size
                        
                    log_messages.append(f"Day {day_num}: {len(group_info.get('member_to_group', {}))}ëª…ì˜ ê·¸ë£¹ ì •ë³´ ì¶”ê°€ë¨")
                else:
                    log_messages.append(f"Day {day_num}: ê·¸ë£¹ ì •ë³´ê°€ ë¹„ì–´ìˆê±°ë‚˜ None")
            else:
                status, wide_df, stage_logs = result
                log_messages.append(f"3ë‹¨ê³„ ìµœì í™”ê°€ ê·¸ë£¹ ì •ë³´ë¥¼ ë°˜í™˜í•˜ì§€ ì•ŠìŒ (3ê°œ ê°’ë§Œ ë°˜í™˜)")
            
            if isinstance(stage_logs, list):
                build_model_logs = stage_logs
            else:
                build_model_logs = [stage_logs]
                
            # 3ë‹¨ê³„ ìµœì í™”ê°€ ì‹¤íŒ¨í•œ ê²½ìš°
            if status not in ["OK", "OPTIMAL", "FEASIBLE"] or wide_df is None:
                log_messages.append(f"âš ï¸ 3ë‹¨ê³„ ìµœì í™” ì‹¤íŒ¨ (ìƒíƒœ: {status})")
                log_messages.append("âŒ Batched í™œë™ì´ ìˆì§€ë§Œ 3ë‹¨ê³„ ìµœì í™”ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                log_messages.append("   ì´ ê²½ìš° ì˜¬ë°”ë¥¸ ê·¸ë£¹ ìŠ¤ì¼€ì¤„ë§ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
                
                # Batched ëª¨ë“œì—ì„œëŠ” ë°˜ë“œì‹œ 3ë‹¨ê³„ ìµœì í™”ê°€ ì„±ê³µí•´ì•¼ í•¨
                # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±í•˜ì§€ ì•Šê³  ì‹¤íŒ¨ ì²˜ë¦¬
                log_messages.append("   â†’ ì´ ë‚ ì§œëŠ” ìŠ¤ì¼€ì¤„ë§ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                continue  # ë‹¤ìŒ ë‚ ì§œë¡œ
        else:
            # ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
            model, status, wide_df, build_model_logs = build_model(config, logger)
        
        if build_model_logs:
            log_messages.extend(build_model_logs)

        log_messages.append(f"Solver status: {status}")

        if status in ("OK", "OPTIMAL", "FEASIBLE") and wide_df is not None and not wide_df.empty:
            
            # wide_dfëŠ” ì‹¤ì œë¡œëŠ” long-formì´ë¯€ë¡œ, wide-to-long ë³€í™˜ì´ ë¶ˆí•„ìš”.
            # ì»¬ëŸ¼ëª… ë³€ê²½ë„ í•„ìš” ì—†ìŒ.
            try:
                long_df = wide_df.copy()
                long_df['interview_date'] = the_date
                
                # 'code' ì—´ì´ ì—†ìœ¼ë©´ 'job_code'ë¥¼ ì‚¬ìš©
                if 'code' not in long_df.columns and 'job_code' in long_df.columns:
                    long_df = long_df.rename(columns={'job_code': 'code'})

                # 'loc' ì—´ì´ ì—†ìœ¼ë©´ 'room'ì„ ì‚¬ìš©
                if 'loc' not in long_df.columns and 'room' in long_df.columns:
                    long_df = long_df.rename(columns={'room': 'loc'})
                
                # start_time, end_time -> start, endë¡œ ì •ê·œí™”
                if 'start_time' in long_df.columns:
                    long_df = long_df.rename(columns={'start_time': 'start'})
                if 'end_time' in long_df.columns:
                    long_df = long_df.rename(columns={'end_time': 'end'})


                scheduled_ids_today = set(long_df['id'].unique())
                all_scheduled_ids.update(scheduled_ids_today)
                
                all_scheduled_cands_long = pd.concat([all_scheduled_cands_long, long_df], ignore_index=True)
                log_messages.append(f"ì„±ê³µ: {len(scheduled_ids_today)}ëª… ë°°ì • ì™„ë£Œ.")
            except Exception as e:
                log_messages.append(f"ê²°ê³¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

        else:
            log_messages.append("ì‹¤íŒ¨ ë˜ëŠ” ë°°ì •ëœ ì§€ì›ì ì—†ìŒ.")
            if status == "ERROR":
                log_messages.append("\n>> ì˜¤ë¥˜ë¡œ ì¸í•´ ìŠ¤ì¼€ì¤„ë§ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìœ„ì˜ ìƒì„¸ ë¡œê·¸(Traceback)ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”. <<\n")
    
    else: # for-else: break ì—†ì´ ë£¨í”„ê°€ ëë‚˜ë©´ ì‹¤í–‰
        unscheduled_cands_final = candidates_df[~candidates_df['id'].isin(all_scheduled_ids)]
        if not unscheduled_cands_final.empty:
            log_messages.append(f"âš ï¸ {max_days}ì¼ ì•ˆì— {len(unscheduled_cands_final['id'].unique())}ëª…ì˜ ì§€ì›ìë¥¼ ëª¨ë‘ ë°°ì •í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            st.warning(f"ì‹œë®¬ë ˆì´ì…˜ ê¸°ê°„({max_days}ì¼)ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì¼ë¶€ ì§€ì›ìê°€ ë°°ì •ë˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    if all_scheduled_cands_long.empty:
        return "NO_SOLUTION", None, "\n".join(log_messages), daily_candidate_limit
    
    # ëˆ„ì ëœ ê·¸ë£¹ ì •ë³´ë¥¼ session_stateì— ì €ì¥
    if all_group_info['member_to_group']:
        st.session_state['last_group_info'] = all_group_info
        log_messages.append(f"ì´ {len(all_group_info['member_to_group'])}ëª…ì˜ ê·¸ë£¹ ì •ë³´ ì €ì¥ë¨")
    else:
        st.session_state['last_group_info'] = None

    # ìµœì¢…ì ìœ¼ë¡œ long í¬ë§·ì„ wide í¬ë§·ìœ¼ë¡œ ë³€í™˜
    final_wide = all_scheduled_cands_long.pivot_table(
        index=['id', 'interview_date', 'code'],
        columns='activity',
        values=['start', 'end', 'loc'],
        aggfunc='first'
    ).reset_index()

    final_wide.columns = ['_'.join(col).strip() if isinstance(col, tuple) and col[1] else col[0] for col in final_wide.columns]
    final_wide = final_wide.rename(columns={'id_': 'id', 'interview_date_': 'interview_date', 'code_': 'code'})

    activity_cols = sorted(list(all_scheduled_cands_long['activity'].unique()))
    
    for act in activity_cols:
        for prefix in ['start_', 'end_']:
            col = f"{prefix}{act}"
            if col in final_wide.columns:
                final_wide[col] = pd.to_datetime(final_wide[col], errors='coerce').dt.strftime('%H:%M:%S')

    sorted_activity_cols = sort_activities_by_time(final_wide.copy(), activity_cols)

    base_cols = ['id', 'interview_date', 'code']
    ordered_cols = base_cols + [f'{prefix}{act}' for act in sorted_activity_cols for prefix in ['start_', 'end_', 'loc_']]
    
    final_ordered_cols = [c for c in ordered_cols if c in final_wide.columns]
    final_wide = final_wide[final_ordered_cols]
    
    # ë”ë¯¸ ì§€ì›ì ìœ ì§€ (ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ì œê±°í•˜ì§€ ì•ŠìŒ)
    # if 'id' in final_wide.columns:
    #     before_count = len(final_wide)
    #     final_wide = final_wide[~final_wide['id'].str.startswith('DUMMY_')]
    #     dummy_count = before_count - len(final_wide)
    #     if dummy_count > 0:
    #         log_messages.append(f"ë”ë¯¸ ì§€ì›ì {dummy_count}ëª… ì œê±°ë¨")

    return "OK", _drop_useless_cols(final_wide), "\n".join(log_messages), daily_candidate_limit

def _drop_useless_cols(df: pd.DataFrame) -> pd.DataFrame:
    """
    ê°’ì´ í•˜ë‚˜ë„ ì—†ê±°ë‚˜(ì „ë¶€ NaN/ë¹ˆì¹¸) ì •ë³´ëŸ‰ì´ 0ì¸ ì—´ì„ ì œê±°í•œë‹¤.
    (loc_/start_/end_ ê°™ì€ ì´ë¦„ì´ë¼ë„ ì „ë¶€ ë¹„ì–´ ìˆìœ¼ë©´ ì‚­ì œ)
    """
    def useless(s: pd.Series) -> bool:
        return s.replace('', pd.NA).nunique(dropna=True) == 0
    return df.drop(columns=[c for c in df.columns if useless(df[c])])

def sort_activities_by_time(df: pd.DataFrame, activity_cols: list) -> list:
    """í™œë™(activity) ì»¬ëŸ¼ë“¤ì„ í‰ê·  ì‹œì‘ ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬"""
    avg_start_times = {}
    for act in activity_cols:
        start_col = f'start_{act}'
        if start_col in df.columns:
            # SettingWithCopyWarningì„ í”¼í•˜ê¸° ìœ„í•´ .loc ì‚¬ìš© ë° íƒ€ì… ë³€í™˜
            times = pd.to_datetime(df[start_col], errors='coerce').dropna()
            if not times.empty:
                avg_start_times[act] = times.mean()

    sorted_activities = sorted(avg_start_times.keys(), key=lambda k: avg_start_times[k])
    time_missing_activities = sorted([act for act in activity_cols if act not in avg_start_times])
    return sorted_activities + time_missing_activities

def solve(cfg_ui: dict, params: dict | None = None, *, debug: bool = False):
    """
    cfg_ui : core.build_config()ê°€ ë„˜ê¸´ UI ë°ì´í„° ë¬¶ìŒ(dict)
    params : ìŠ¤ì¼€ì¤„ë§ íŒŒë¼ë¯¸í„° (dict)
    ë°˜í™˜   : (status:str, wide:pd.DataFrame|None, logs:str)
    """
    import io, contextlib, traceback, sys
    import pandas as pd
    import streamlit as st
    from interview_opt_test_v4 import build_model

    logger = st.logger.get_logger("solver")

    # 0) ì§€ì›ì ë°ì´í„° ìœ ë¬´ ì²´í¬
    if "candidates_exp" not in cfg_ui or cfg_ui["candidates_exp"].empty:
        st.error("â›” ì§€ì›ì ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 'Candidates' í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return "NO_DATA", None, ""

    # --- room_cap vs activity.max_cap í•˜ë“œ-ê²€ì¦ -----------------
    room_types_ui = cfg_ui["activities"]["room_type"].dropna().unique()
    room_max = {}
    for _, rp in cfg_ui["room_plan"].iterrows():
        for rt in room_types_ui:
            col = f"{rt}_cap"
            if col in rp and pd.notna(rp[col]):
                room_max[rt] = max(room_max.get(rt, 0), int(rp[col]))
    bad = [
        (row.activity, row.max_cap, room_max.get(row.room_type, 0))
        for _, row in cfg_ui["activities"].iterrows()
        if "max_cap" in row and "room_type" in row and pd.notna(row.max_cap) and pd.notna(row.room_type) and row.max_cap > room_max.get(row.room_type, 0)
    ]
    if bad:
        msg = ", ".join(f"{a}(max {mc}>{rc})" for a,mc,rc in bad)
        st.error(f"â›” room_plan cap ë¶€ì¡±: {msg}")
        return "ERR", None, ""
    # ----------------------------------------------------------

    # ë‚ ì§œ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ: ì§€ì›ì ë‚ ì§œì™€ Room Plan ë‚ ì§œì˜ êµì§‘í•©ë§Œ ì‚¬ìš©
    df_raw_all = cfg_ui["candidates_exp"].copy()
    df_raw_all["interview_date"] = pd.to_datetime(df_raw_all["interview_date"])
    candidate_dates = set(df_raw_all["interview_date"].dt.date)

    room_plan_df = cfg_ui["room_plan"].copy()
    if "date" not in room_plan_df.columns:
        st.error("â›” 'Room Plan'ì— 'date' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return "ERR_NO_ROOM_DATE", None, ""
    room_plan_df["date"] = pd.to_datetime(room_plan_df["date"])
    room_plan_dates = set(room_plan_df["date"].dt.date)

    date_list_obj = sorted(list(candidate_dates.intersection(room_plan_dates)))

    if not date_list_obj:
        st.error(
            "**ì„¤ì • ì˜¤ë¥˜:** ì§€ì›ìê°€ ë°°ì •ëœ ë‚ ì§œì™€ 'Room Plan'ì— ì„¤ì •ëœ ë‚ ì§œê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "
            f"ì§€ì›ì ë‚ ì§œ: `{sorted(list(candidate_dates))}`, "
            f"Room Plan ë‚ ì§œ: `{sorted(list(room_plan_dates))}`. "
            "ë‘ ì„¤ì •ì˜ ë‚ ì§œê°€ ì ì–´ë„ í•˜ë£¨ëŠ” ì¼ì¹˜í•´ì•¼ ìŠ¤ì¼€ì¤„ë§ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        )
        return "NO_VALID_DATE", None, ""

    date_list = [pd.to_datetime(d) for d in date_list_obj]

    all_wide = []
    all_logs = []
    for the_date in date_list:
        # (1) í•˜ë£¨ì¹˜ ì§€ì›ìë§Œ í•„í„°
        day_df_raw = df_raw_all[df_raw_all["interview_date"] == the_date]

        # (2) ë‚´ë¶€ í‘œ 4ê°œ ìƒì„± (ê¸°ì¡´ ë¡œì§ ì¬í™œìš©)
        internal = _derive_internal_tables(cfg_ui, the_date, debug=debug)
        
        # ----------------------------------------------------------
        # build_modelì— í•„ìš”í•œ ë°ì´í„° êµ¬ì¡° ìƒì„±
        # ----------------------------------------------------------
        activities_df = cfg_ui['activities']
        act_info = {
            row['activity']: {
                'duration': int(row['duration_min']),
                'min_ppl': int(row.get('min_cap', 1)),
                'max_ppl': int(row.get('max_cap', 1)),
                'required_rooms': [row['room_type']]
            }
            for _, row in activities_df.iterrows()
        }

        candidate_info = {
            cid: {
                'job_code': group['code'].iloc[0],
                'activities': group['activity'].tolist()
            }
            for cid, group in day_df_raw.groupby('id')
        }

        cfg_avail_day = internal['cfg_avail'][internal['cfg_avail']['date'] == the_date]
        room_info = {
            row['loc']: {'capacity': int(row['capacity_max'])}
            for _, row in cfg_avail_day.iterrows()
        }

        cfg_oper_day = internal['cfg_oper'][internal['cfg_oper']['date'] == the_date]
        oper_hours = {}
        base_time = pd.to_datetime(the_date.date().strftime('%Y-%m-%d') + ' 00:00:00')
        for _, row in cfg_oper_day.iterrows():
            start_dt = pd.to_datetime(f"{the_date.date()} {row['start_time']}")
            end_dt = pd.to_datetime(f"{the_date.date()} {row['end_time']}")
            start_minutes = int((start_dt - base_time).total_seconds() / 60)
            end_minutes = int((end_dt - base_time).total_seconds() / 60)
            oper_hours[row['code']] = (start_minutes, end_minutes)
        
        rules = [
            (row['predecessor'], row['successor'], 'direct')
            for _, row in cfg_ui['precedence'].iterrows()
        ]
        
        config = {
            **(params or {}),
            'the_date': the_date,
            'debug_mode': debug,
            'num_cpus': 8,
            'act_info': act_info,
            'candidate_info': candidate_info,
            'room_info': room_info,
            'oper_hours': oper_hours,
            'rules': rules,
            'min_gap_min': params.get('min_gap_min', 5) if params else 5,
            'time_limit_sec': 60.0
        }
        
        log_buf = io.StringIO()
        try:
            with contextlib.redirect_stdout(log_buf):
                model, status_name, final_report_df, logs = build_model(config, logger)
                if logs:
                    all_logs.extend(logs)
                wide = final_report_df
        except Exception:
            tb_str = traceback.format_exc()
            st.error("âŒ Solver exception:")
            st.code(tb_str)
            st.code(log_buf.getvalue())
            return "ERR", None, log_buf.getvalue()

        all_logs.append(log_buf.getvalue())
        if status_name not in ["OPTIMAL", "FEASIBLE"]:
            st.error(f"âš ï¸ Solver status: {status_name} (date {the_date.date()})")
            st.code(log_buf.getvalue())
            return status_name, None, "\n".join(all_logs)

        all_wide.append(wide)

    if not all_wide:
        st.info("â„¹ï¸ í•´ë‹¹ ì¡°ê±´ìœ¼ë¡œ ë°°ì¹˜ ê°€ëŠ¥í•œ ì§€ì›ìê°€ ì—†ìŠµë‹ˆë‹¤.")
        return "NO_FEASIBLE_DATE", None, "\n".join(all_logs)

    all_long = []
    for df_w in all_wide:
        id_vars = [c for c in df_w.columns if not (c.startswith('start_') or c.startswith('end_') or c.startswith('loc_'))]
        # end_D -> end_ ë¡œ ë¯¸ë¦¬ ë³€ê²½
        df_w.columns = df_w.columns.str.replace("end_D", "end_")
        
        activities_in_df = set()
        for c in df_w.columns:
            if c.startswith('start_'): activities_in_df.add(c.replace('start_',''))
            elif c.startswith('end_'): activities_in_df.add(c.replace('end_',''))
            elif c.startswith('loc_'): activities_in_df.add(c.replace('loc_',''))

        if not activities_in_df:
            continue

        df_l = pd.wide_to_long(df_w,
                               stubnames=['start', 'end', 'loc'],
                               i=id_vars,
                               j='activity',
                               sep='_',
                               suffix='(' + '|'.join(activities_in_df) + ')').reset_index()
        all_long.append(df_l)

    if not all_long:
        st.info("â„¹ï¸ ì¡°ê±´ì— ë§ëŠ” ìŠ¤ì¼€ì¤„ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return "NO_FEASIBLE_SCHEDULE", None, "\n".join(all_logs)

    final_long = pd.concat(all_long, ignore_index=True)
    
    final_wide = final_long.pivot_table(
        index=[c for c in final_long.columns if c not in ['activity', 'start', 'end', 'loc']],
        columns='activity',
        values=['start', 'end', 'loc']
    ).reset_index()

    final_wide.columns = [f'{v}_{c}' if c else v for v,c in final_wide.columns]
    
    activity_cols = sorted(list(final_long['activity'].unique()))
    # copy()ë¥¼ ì‚¬ìš©í•˜ì—¬ SettingWithCopyWarning ë°©ì§€
    sorted_activity_cols = sort_activities_by_time(final_wide.copy(), activity_cols)

    base_cols = [c for c in ['id', 'interview_date', 'code'] if c in final_wide.columns]
    ordered_cols = base_cols + [f'{prefix}{act}' for act in sorted_activity_cols for prefix in ['start_', 'end_', 'loc_']]
    
    final_ordered_cols = [c for c in ordered_cols if c in final_wide.columns]
    final_wide = final_wide[final_ordered_cols]
    
    return "OK", _drop_useless_cols(final_wide), "\n".join(all_logs)
