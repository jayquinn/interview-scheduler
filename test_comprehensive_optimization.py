#!/usr/bin/env python3
"""
ì¢…í•©ì ì¸ ì²´ë¥˜ì‹œê°„ ìµœì í™” ì‹¤í—˜
- 4ì¼ê°„ ëª¨ë“  ë‚ ì§œ ë°ì´í„° ë¶„ì„
- ë‹¤ì–‘í•œ í† ë¡ ë©´ì ‘ ê·¸ë£¹ ì´ë™ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
- ìµœì  ì‹œê°„ ë°°ì¹˜ ì „ëµ íƒìƒ‰
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from itertools import combinations
import copy

def load_comprehensive_data():
    """ì „ì²´ ë°ì´í„° ë¡œë“œ ë° ë¶„ì„"""
    print("ğŸ§ª ì¢…í•©ì ì¸ ì²´ë¥˜ì‹œê°„ ìµœì í™” ì‹¤í—˜")
    print("=" * 80)
    
    df = pd.read_excel('complete_ui_defaults_test_result.xlsx')
    print(f"âœ… ìŠ¤ì¼€ì¤„ ë°ì´í„° ë¡œë“œ: {len(df)}ê°œ í•­ëª©")
    
    # ì‹œê°„ ë³€í™˜
    df['start_minutes'] = df['start_time'].apply(lambda x: int(x * 24 * 60))
    df['end_minutes'] = df['end_time'].apply(lambda x: int(x * 24 * 60))
    
    return df

def analyze_all_dates(df):
    """ëª¨ë“  ë‚ ì§œë³„ í˜„í™© ë¶„ì„"""
    print("\nğŸ” ì „ì²´ ë‚ ì§œë³„ ë¶„ì„")
    print("=" * 60)
    
    # ë‚ ì§œë³„ í†µê³„
    dates = sorted(df['interview_date'].unique())
    
    date_analysis = {}
    
    for date in dates:
        date_df = df[df['interview_date'] == date]
        
        # ì²´ë¥˜ì‹œê°„ ê³„ì‚°
        stay_times = {}
        for applicant_id in date_df['applicant_id'].unique():
            applicant_data = date_df[date_df['applicant_id'] == applicant_id]
            earliest_start = applicant_data['start_minutes'].min()
            latest_end = applicant_data['end_minutes'].max()
            stay_hours = (latest_end - earliest_start) / 60
            
            stay_times[applicant_id] = {
                'stay_hours': stay_hours,
                'earliest_start': earliest_start,
                'latest_end': latest_end,
                'job_code': applicant_data['job_code'].iloc[0]
            }
        
        # í† ë¡ ë©´ì ‘ ê·¸ë£¹ ë¶„ì„
        discussion_df = date_df[date_df['activity_name'] == 'í† ë¡ ë©´ì ‘']
        discussion_groups = discussion_df.groupby(['start_minutes', 'room_name'])
        
        groups_info = []
        for (start_time, room), group in discussion_groups:
            start_h, start_m = divmod(start_time, 60)
            groups_info.append({
                'start_time': start_time,
                'start_display': f"{start_h:02d}:{start_m:02d}",
                'room': room,
                'size': len(group),
                'members': group['applicant_id'].tolist(),
                'job_codes': group['job_code'].unique().tolist()
            })
        
        groups_info.sort(key=lambda x: x['start_time'])
        
        # í†µê³„
        all_stay_hours = [info['stay_hours'] for info in stay_times.values()]
        long_stay_count = sum(1 for h in all_stay_hours if h >= 4.0)
        
        date_analysis[date] = {
            'total_applicants': len(stay_times),
            'stay_times': stay_times,
            'discussion_groups': groups_info,
            'avg_stay': np.mean(all_stay_hours),
            'max_stay': np.max(all_stay_hours),
            'long_stay_count': long_stay_count,
            'long_stay_percent': long_stay_count / len(stay_times) * 100
        }
        
        print(f"\nğŸ“… {date.strftime('%m/%d')}:")
        print(f"   ì§€ì›ì: {len(stay_times)}ëª…")
        print(f"   í† ë¡ ë©´ì ‘ ê·¸ë£¹: {len(groups_info)}ê°œ")
        for group in groups_info:
            print(f"      {group['start_display']} {group['room']}: {group['size']}ëª… ({', '.join(group['job_codes'])})")
        print(f"   í‰ê·  ì²´ë¥˜ì‹œê°„: {np.mean(all_stay_hours):.1f}h")
        print(f"   ìµœëŒ€ ì²´ë¥˜ì‹œê°„: {np.max(all_stay_hours):.1f}h")
        print(f"   4ì‹œê°„+ ì²´ë¥˜ì: {long_stay_count}ëª… ({long_stay_count/len(stay_times)*100:.1f}%)")
    
    return date_analysis

def generate_optimization_scenarios():
    """ìµœì í™” ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±"""
    print(f"\nğŸ“‹ ìµœì í™” ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±")
    print("=" * 60)
    
    # ë‹¤ì–‘í•œ ì´ë™ ì‹œë‚˜ë¦¬ì˜¤ë“¤
    scenarios = [
        # ê¸°ë³¸ ì‹œë‚˜ë¦¬ì˜¤: ë§ˆì§€ë§‰ ê·¸ë£¹ì„ ë’·ì‹œê°„ìœ¼ë¡œ
        {
            'name': 'ë§ˆì§€ë§‰ ê·¸ë£¹ â†’ ì˜¤í›„ ì´ë™',
            'description': 'ê° ë‚ ì§œì˜ ë§ˆì§€ë§‰ í† ë¡ ë©´ì ‘ ê·¸ë£¹ì„ ì˜¤í›„ ì‹œê°„ëŒ€ë¡œ ì´ë™',
            'strategy': 'move_last_to_afternoon'
        },
        # ì¤‘ê°„ ê·¸ë£¹ ë¶„ì‚°
        {
            'name': 'ì¤‘ê°„ ê·¸ë£¹ ë¶„ì‚° ë°°ì¹˜',
            'description': 'ì¤‘ê°„ ì‹œê°„ëŒ€ ê·¸ë£¹ì„ ì˜¤í›„ë¡œ ë¶„ì‚° ë°°ì¹˜',
            'strategy': 'distribute_middle'
        },
        # ì•ì‹œê°„ ê·¸ë£¹ ë’¤ë¡œ
        {
            'name': 'ì•ì‹œê°„ ê·¸ë£¹ â†’ ë’·ì‹œê°„',
            'description': '09:00 ê·¸ë£¹ì„ ì ì‹¬ì‹œê°„ ì´í›„ë¡œ ì´ë™',
            'strategy': 'move_early_to_late'
        },
        # ìµœì  ê°„ê²© ë°°ì¹˜
        {
            'name': 'ìµœì  ê°„ê²© ë°°ì¹˜',
            'description': 'í† ë¡ ë©´ì ‘ì„ ê· ë“± ê°„ê²©ìœ¼ë¡œ ì¬ë°°ì¹˜',
            'strategy': 'optimal_spacing'
        }
    ]
    
    for scenario in scenarios:
        print(f"   ğŸ¯ {scenario['name']}: {scenario['description']}")
    
    return scenarios

def simulate_scenario(df, date_analysis, scenario_name, strategy):
    """ê°œë³„ ì‹œë‚˜ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜"""
    print(f"\nğŸš€ ì‹œë‚˜ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜: {scenario_name}")
    print("=" * 60)
    
    total_results = {
        'total_moved': 0,
        'total_reduction': 0,
        'improved_count': 0,
        'date_results': {}
    }
    
    for date, analysis in date_analysis.items():
        print(f"\nğŸ“… {date.strftime('%m/%d')} ì²˜ë¦¬...")
        
        date_df = df[df['interview_date'] == date]
        
        if strategy == 'move_last_to_afternoon':
            result = move_last_group_to_afternoon(date_df, analysis)
        elif strategy == 'distribute_middle':
            result = distribute_middle_groups(date_df, analysis)
        elif strategy == 'move_early_to_late':
            result = move_early_to_late(date_df, analysis)
        elif strategy == 'optimal_spacing':
            result = optimal_spacing_strategy(date_df, analysis)
        else:
            result = None
        
        if result:
            total_results['total_moved'] += result['moved_count']
            total_results['total_reduction'] += result['total_reduction']
            total_results['improved_count'] += result['improved_count']
            total_results['date_results'][date] = result
            
            print(f"   âœ… {result['moved_count']}ëª… ì´ë™, {result['total_reduction']:.1f}h ë‹¨ì¶•")
        else:
            print(f"   âŒ ì ìš© ë¶ˆê°€")
    
    return total_results

def move_last_group_to_afternoon(date_df, analysis):
    """ë§ˆì§€ë§‰ í† ë¡ ë©´ì ‘ ê·¸ë£¹ì„ ì˜¤í›„ë¡œ ì´ë™"""
    groups = analysis['discussion_groups']
    if not groups:
        return None
    
    # ê°€ì¥ ëŠ¦ì€ ì‹œê°„ëŒ€ ê·¸ë£¹ ì°¾ê¸°
    last_group = max(groups, key=lambda x: x['start_time'])
    
    # 14:00 ì´í›„ë¡œ ì´ë™ (840ë¶„ ì´í›„)
    if last_group['start_time'] >= 840:  # ì´ë¯¸ 14ì‹œ ì´í›„ë©´ íŒ¨ìŠ¤
        return None
    
    target_time = 840  # 14:00
    move_offset = target_time - last_group['start_time']
    
    # ì‹œë®¬ë ˆì´ì…˜
    modified_df = date_df.copy()
    moved_applicants = last_group['members']
    
    # í† ë¡ ë©´ì ‘ë§Œ ì´ë™
    mask = (modified_df['activity_name'] == 'í† ë¡ ë©´ì ‘') & (modified_df['start_minutes'] == last_group['start_time'])
    modified_df.loc[mask, 'start_minutes'] += move_offset
    modified_df.loc[mask, 'end_minutes'] += move_offset
    
    # íš¨ê³¼ ê³„ì‚°
    return calculate_improvement(date_df, modified_df, moved_applicants, analysis['stay_times'])

def distribute_middle_groups(date_df, analysis):
    """ì¤‘ê°„ ê·¸ë£¹ë“¤ì„ ë¶„ì‚° ë°°ì¹˜"""
    groups = analysis['discussion_groups']
    if len(groups) <= 2:
        return None
    
    # ì¤‘ê°„ ê·¸ë£¹ (ì²«ë²ˆì§¸, ë§ˆì§€ë§‰ ì œì™¸í•œ ê·¸ë£¹ë“¤)
    middle_groups = groups[1:-1] if len(groups) > 2 else []
    if not middle_groups:
        return None
    
    # 12:00, 13:00, 14:00 ë“±ìœ¼ë¡œ ë¶„ì‚°
    target_times = [720, 780, 840]  # 12:00, 13:00, 14:00
    
    modified_df = date_df.copy()
    all_moved_applicants = []
    
    for i, group in enumerate(middle_groups):
        if i < len(target_times):
            target_time = target_times[i]
            move_offset = target_time - group['start_time']
            
            # í† ë¡ ë©´ì ‘ë§Œ ì´ë™
            mask = (modified_df['activity_name'] == 'í† ë¡ ë©´ì ‘') & (modified_df['start_minutes'] == group['start_time'])
            modified_df.loc[mask, 'start_minutes'] += move_offset
            modified_df.loc[mask, 'end_minutes'] += move_offset
            
            all_moved_applicants.extend(group['members'])
    
    if not all_moved_applicants:
        return None
    
    return calculate_improvement(date_df, modified_df, all_moved_applicants, analysis['stay_times'])

def move_early_to_late(date_df, analysis):
    """09:00 ê·¸ë£¹ì„ 13:00ìœ¼ë¡œ ì´ë™"""
    groups = analysis['discussion_groups']
    
    # 09:00 ê·¸ë£¹ ì°¾ê¸°
    early_groups = [g for g in groups if g['start_time'] == 540]  # 09:00 = 540ë¶„
    if not early_groups:
        return None
    
    # 13:00ìœ¼ë¡œ ì´ë™
    target_time = 780  # 13:00
    move_offset = target_time - 540
    
    modified_df = date_df.copy()
    all_moved_applicants = []
    
    for group in early_groups:
        # í† ë¡ ë©´ì ‘ë§Œ ì´ë™
        mask = (modified_df['activity_name'] == 'í† ë¡ ë©´ì ‘') & (modified_df['start_minutes'] == 540)
        modified_df.loc[mask, 'start_minutes'] += move_offset
        modified_df.loc[mask, 'end_minutes'] += move_offset
        
        all_moved_applicants.extend(group['members'])
    
    return calculate_improvement(date_df, modified_df, all_moved_applicants, analysis['stay_times'])

def optimal_spacing_strategy(date_df, analysis):
    """ìµœì  ê°„ê²©ìœ¼ë¡œ í† ë¡ ë©´ì ‘ ì¬ë°°ì¹˜"""
    groups = analysis['discussion_groups']
    if len(groups) <= 1:
        return None
    
    # 09:00ë¶€í„° ì‹œì‘í•´ì„œ 2ì‹œê°„ ê°„ê²©ìœ¼ë¡œ ë°°ì¹˜
    optimal_times = [540, 660, 780, 900]  # 09:00, 11:00, 13:00, 15:00
    
    modified_df = date_df.copy()
    all_moved_applicants = []
    
    for i, group in enumerate(groups):
        if i < len(optimal_times):
            target_time = optimal_times[i]
            
            if group['start_time'] != target_time:
                move_offset = target_time - group['start_time']
                
                # í† ë¡ ë©´ì ‘ë§Œ ì´ë™
                mask = (modified_df['activity_name'] == 'í† ë¡ ë©´ì ‘') & (modified_df['start_minutes'] == group['start_time'])
                modified_df.loc[mask, 'start_minutes'] += move_offset
                modified_df.loc[mask, 'end_minutes'] += move_offset
                
                all_moved_applicants.extend(group['members'])
    
    if not all_moved_applicants:
        return None
    
    return calculate_improvement(date_df, modified_df, all_moved_applicants, analysis['stay_times'])

def calculate_improvement(original_df, modified_df, moved_applicants, original_stay_times):
    """ê°œì„  íš¨ê³¼ ê³„ì‚°"""
    if not moved_applicants:
        return None
    
    # ìƒˆë¡œìš´ ì²´ë¥˜ì‹œê°„ ê³„ì‚°
    new_stay_times = {}
    for applicant_id in moved_applicants:
        applicant_data = modified_df[modified_df['applicant_id'] == applicant_id]
        if len(applicant_data) > 0:
            earliest_start = applicant_data['start_minutes'].min()
            latest_end = applicant_data['end_minutes'].max()
            stay_hours = (latest_end - earliest_start) / 60
            
            new_stay_times[applicant_id] = stay_hours
    
    # ê°œì„  ê³„ì‚°
    total_reduction = 0
    improved_count = 0
    
    for applicant_id in moved_applicants:
        if applicant_id in original_stay_times and applicant_id in new_stay_times:
            original_hours = original_stay_times[applicant_id]['stay_hours']
            new_hours = new_stay_times[applicant_id]
            
            if new_hours < original_hours:
                improved_count += 1
                total_reduction += (original_hours - new_hours)
    
    return {
        'moved_count': len(moved_applicants),
        'improved_count': improved_count,
        'total_reduction': total_reduction,
        'avg_reduction': total_reduction / improved_count if improved_count > 0 else 0
    }

def find_best_strategy(df, date_analysis, scenarios):
    """ìµœì  ì „ëµ íƒìƒ‰"""
    print(f"\nğŸ† ìµœì  ì „ëµ íƒìƒ‰")
    print("=" * 60)
    
    best_results = []
    
    for scenario in scenarios:
        result = simulate_scenario(df, date_analysis, scenario['name'], scenario['strategy'])
        
        if result['total_reduction'] > 0:
            best_results.append({
                'scenario': scenario['name'],
                'total_moved': result['total_moved'],
                'total_reduction': result['total_reduction'],
                'improved_count': result['improved_count'],
                'avg_reduction_per_person': result['total_reduction'] / result['improved_count'] if result['improved_count'] > 0 else 0,
                'efficiency': result['total_reduction'] / result['total_moved'] if result['total_moved'] > 0 else 0
            })
    
    # íš¨ê³¼ ìˆœìœ¼ë¡œ ì •ë ¬
    best_results.sort(key=lambda x: x['total_reduction'], reverse=True)
    
    print(f"\nğŸ“Š ì „ëµë³„ íš¨ê³¼ ë¹„êµ:")
    print(f"{'ìˆœìœ„':<3} {'ì „ëµëª…':<20} {'ì´ë™ì¸ì›':<8} {'ë‹¨ì¶•ì‹œê°„':<10} {'ê°œì„ ì¸ì›':<8} {'í‰ê· ë‹¨ì¶•':<10} {'íš¨ìœ¨ì„±':<8}")
    print("-" * 70)
    
    for i, result in enumerate(best_results, 1):
        print(f"{i:<3} {result['scenario']:<20} {result['total_moved']:<8} {result['total_reduction']:<10.1f} {result['improved_count']:<8} {result['avg_reduction_per_person']:<10.1f} {result['efficiency']:<8.2f}")
    
    if best_results:
        best = best_results[0]
        print(f"\nğŸ¥‡ ìµœì  ì „ëµ: {best['scenario']}")
        print(f"   - ì´ {best['total_moved']}ëª… ì´ë™ìœ¼ë¡œ {best['total_reduction']:.1f}ì‹œê°„ ë‹¨ì¶•")
        print(f"   - ê°œì„  ì„±ê³µë¥ : {best['improved_count']}/{best['total_moved']}ëª… ({best['improved_count']/best['total_moved']*100:.1f}%)")
        print(f"   - í‰ê·  ê°œì„  íš¨ê³¼: {best['avg_reduction_per_person']:.1f}ì‹œê°„/ëª…")
    
    return best_results

def main():
    """ë©”ì¸ ì‹¤í—˜ í•¨ìˆ˜"""
    # 1. ë°ì´í„° ë¡œë“œ
    df = load_comprehensive_data()
    
    # 2. ëª¨ë“  ë‚ ì§œ ë¶„ì„
    date_analysis = analyze_all_dates(df)
    
    # 3. ìµœì í™” ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±
    scenarios = generate_optimization_scenarios()
    
    # 4. ìµœì  ì „ëµ íƒìƒ‰
    best_results = find_best_strategy(df, date_analysis, scenarios)
    
    # 5. ì „ì²´ ìš”ì•½
    print(f"\nğŸ‰ ì¢…í•© ì‹¤í—˜ ì™„ë£Œ!")
    print("=" * 60)
    
    if best_results:
        total_original_problems = sum(analysis['long_stay_count'] for analysis in date_analysis.values())
        best_reduction = best_results[0]['total_reduction']
        
        print(f"ğŸ“ˆ í•µì‹¬ ì„±ê³¼:")
        print(f"  - 4ì‹œê°„+ ì²´ë¥˜ ë¬¸ì œì: {total_original_problems}ëª…")
        print(f"  - ìµœëŒ€ ë‹¨ì¶• ê°€ëŠ¥ ì‹œê°„: {best_reduction:.1f}ì‹œê°„")
        print(f"  - ìµœì  ì „ëµ: {best_results[0]['scenario']}")
        
        print(f"\nğŸ’¡ ê²°ë¡ :")
        print(f"  âœ… ì‚¬ìš©ì ì•„ì´ë””ì–´ê°€ ëª¨ë“  ë‚ ì§œì—ì„œ íš¨ê³¼ì ì„ì„ í™•ì¸")
        print(f"  âœ… í† ë¡ ë©´ì ‘ ê·¸ë£¹ ì´ë™ì´ ì²´ë¥˜ì‹œê°„ ìµœì í™”ì˜ í•µì‹¬")
        print(f"  âœ… ì‹œìŠ¤í…œ í†µí•©ì„ ìœ„í•œ êµ¬ì²´ì  ì „ëµ ë„ì¶œ")

if __name__ == "__main__":
    main() 