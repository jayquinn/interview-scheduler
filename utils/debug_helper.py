"""
ë©´ì ‘ ìŠ¤ì¼€ì¤„ë§ ë””ë²„ê·¸ í—¬í¼
ì‹¤ì‹œê°„ ë¡œê·¸ í‘œì‹œ, íŒŒì¼ ì €ì¥, ì‹¤íŒ¨ ì›ì¸ ë¶„ì„ ê¸°ëŠ¥ ì œê³µ
"""
import os
import json
import logging
from datetime import datetime
from pathlib import Path
import streamlit as st
import pandas as pd
from typing import Dict, List, Optional, Any


class SchedulingDebugHelper:
    """ìŠ¤ì¼€ì¤„ë§ ë””ë²„ê·¸ë¥¼ ìœ„í•œ í—¬í¼ í´ë˜ìŠ¤"""
    
    def __init__(self, log_dir: str = "log"):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        self.current_log_file = None
        self.log_messages = []
        
    def start_session(self, config: Dict[str, Any]) -> str:
        """ìƒˆë¡œìš´ ë””ë²„ê·¸ ì„¸ì…˜ ì‹œì‘"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_filename = f"schedule_debug_{timestamp}.json"
        self.current_log_file = self.log_dir / log_filename
        
        # ì´ˆê¸° ë¡œê·¸ ì •ë³´
        session_info = {
            "timestamp": timestamp,
            "config": self._serialize_config(config),
            "logs": []
        }
        
        with open(self.current_log_file, 'w', encoding='utf-8') as f:
            json.dump(session_info, f, ensure_ascii=False, indent=2)
            
        return str(self.current_log_file)
    
    def _serialize_config(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """ì„¤ì •ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜"""
        serialized = {}
        for key, value in config.items():
            if isinstance(value, pd.DataFrame):
                serialized[key] = {
                    "type": "DataFrame",
                    "shape": value.shape,
                    "data": value.to_dict('records')
                }
            elif hasattr(value, '__dict__'):
                serialized[key] = str(value)
            else:
                serialized[key] = value
        return serialized
    
    def log(self, level: str, message: str, data: Optional[Dict] = None):
        """ë¡œê·¸ ë©”ì‹œì§€ ì¶”ê°€"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "level": level,
            "message": message,
            "data": data or {}
        }
        
        self.log_messages.append(log_entry)
        
        # íŒŒì¼ì— ì¦‰ì‹œ ê¸°ë¡
        if self.current_log_file and self.current_log_file.exists():
            with open(self.current_log_file, 'r+', encoding='utf-8') as f:
                session_data = json.load(f)
                session_data["logs"].append(log_entry)
                f.seek(0)
                json.dump(session_data, f, ensure_ascii=False, indent=2)
                f.truncate()
    
    def analyze_failure(self, status: str, logs: str):
        """ì‹¤íŒ¨ ì›ì¸ ë¶„ì„ ë° í•´ê²°ì±… ì œì‹œ"""
        st.error(f"âŒ ìŠ¤ì¼€ì¤„ë§ ì‹¤íŒ¨: {status}")
        
        # íŒ¨í„´ ê¸°ë°˜ ë¶„ì„
        patterns = {
            "NO_SOLUTION": {
                "keywords": ["ëª¨ë“  ì§€ì›ìë¥¼ ë°°ì •í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤"],
                "cause": "ì œì•½ ì¡°ê±´ì´ ë„ˆë¬´ ì—„ê²©í•˜ì—¬ ëª¨ë“  ì§€ì›ìë¥¼ ë°°ì •í•  ìˆ˜ ì—†ìŒ",
                "solutions": [
                    "ìš´ì˜ ì‹œê°„ì„ ëŠ˜ë¦¬ê¸° (ì˜ˆ: 9-18ì‹œ â†’ 9-19ì‹œ)",
                    "ìš´ì˜ ê³µê°„(ë°©) ê°œìˆ˜ ëŠ˜ë¦¬ê¸°",
                    "í™œë™ ì†Œìš”ì‹œê°„ ë‹¨ì¶•",
                    "ì„ í›„í–‰ ì œì•½ ì™„í™” (adjacent â†’ ì¼ë°˜ ìˆœì„œ)"
                ]
            },
            "INFEASIBLE": {
                "keywords": ["INFEASIBLE", "no feasible solution"],
                "cause": "í˜„ì¬ ì„¤ì •ìœ¼ë¡œëŠ” ìŠ¤ì¼€ì¤„ì„ ë§Œë“¤ ìˆ˜ ì—†ìŒ",
                "solutions": [
                    "ì²´ë¥˜ì‹œê°„ ì œí•œ ëŠ˜ë¦¬ê¸°",
                    "í™œë™ ê°„ ìµœì†Œ ê°„ê²©(gap) ì¤„ì´ê¸°",
                    "ë™ì‹œ ìˆ˜ìš© ì¸ì›(capacity) ëŠ˜ë¦¬ê¸°"
                ]
            },
            "ADJACENT_CONFLICT": {
                "keywords": ["adjacent", "batched", "parallel", "individual"],
                "cause": "Batched/Parallel â†’ Individual adjacent ì œì•½ì´ êµ¬ì¡°ì ìœ¼ë¡œ ë¶ˆê°€ëŠ¥",
                "solutions": [
                    "Adjacent ì œì•½ì„ ì¼ë°˜ ìˆœì„œ ì œì•½ìœ¼ë¡œ ë³€ê²½",
                    "Individual í™œë™ì˜ ë°© ê°œìˆ˜ë¥¼ ê·¸ë£¹ í¬ê¸°ë§Œí¼ ì¦ì„¤",
                    "ê·¸ë£¹ í¬ê¸°ë¥¼ Individual ë°© ê°œìˆ˜ì— ë§ì¶° ì¶•ì†Œ",
                    "Parallel í™œë™ì˜ ìˆ˜ìš© ì¸ì›ì„ Individual ë°© ê°œìˆ˜ì— ë§ì¶° ì¡°ì •"
                ]
            },
            "TIME_LIMIT": {
                "keywords": ["ì‹œê°„ ì´ˆê³¼", "time limit", "timeout"],
                "cause": "ê³„ì‚° ì‹œê°„ ì´ˆê³¼",
                "solutions": [
                    "ì¼ì¼ ì²˜ë¦¬ ì¸ì› ì¤„ì´ê¸°",
                    "ì‹œê°„ ì œí•œ ëŠ˜ë¦¬ê¸° (params['time_limit_sec'])",
                    "ì œì•½ ì¡°ê±´ ë‹¨ìˆœí™”"
                ]
            }
        }
        
        # Adjacent ì²´ì¸ ë¶„ì„ ì¶”ê°€
        if "adjacent" in logs.lower() and ("batched" in logs or "parallel" in logs):
            st.warning("âš ï¸ ë³µì¡í•œ Adjacent ì²´ì¸ ê°ì§€ë¨")
            st.markdown("""
            **Batched/Parallel â†’ Individual Adjacent ë¬¸ì œ**
            - ê·¸ë£¹ìœ¼ë¡œ í™œë™í•œ ì‚¬ëŒë“¤ì´ ê°œë³„ í™œë™ìœ¼ë¡œ ì¦‰ì‹œ ì „í™˜í•´ì•¼ í•˜ëŠ” êµ¬ì¡°
            - ì˜ˆ: 6ëª… ê·¸ë£¹ â†’ 2ëª…ì”© parallel â†’ 1ëª…ì”© individual
            - ì´ëŸ° ê²½ìš° ë³‘ëª© í˜„ìƒì´ ë°œìƒí•˜ì—¬ ìŠ¤ì¼€ì¤„ë§ì´ ë¶ˆê°€ëŠ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            """)
        
        # ë¡œê·¸ì—ì„œ íŒ¨í„´ ì°¾ê¸°
        detected_patterns = []
        for pattern_name, pattern_info in patterns.items():
            if any(keyword in logs for keyword in pattern_info["keywords"]):
                detected_patterns.append((pattern_name, pattern_info))
        
        if detected_patterns:
            st.markdown("### ğŸ” ì›ì¸ ë¶„ì„")
            for pattern_name, pattern_info in detected_patterns:
                st.info(f"**{pattern_info['cause']}**")
                
            st.markdown("### ğŸ’¡ í•´ê²° ë°©ì•ˆ")
            all_solutions = set()
            for _, pattern_info in detected_patterns:
                all_solutions.update(pattern_info['solutions'])
            
            for i, solution in enumerate(all_solutions, 1):
                st.markdown(f"{i}. {solution}")
        else:
            st.markdown("### ğŸ” ì¼ë°˜ì ì¸ í•´ê²° ë°©ì•ˆ")
            st.markdown("""
            1. ì œì•½ ì¡°ê±´ ê²€í†  ë° ì™„í™”
            2. ìš´ì˜ ìì›(ì‹œê°„, ê³µê°„) í™•ëŒ€
            3. í™œë™ êµ¬ì„± ë‹¨ìˆœí™”
            4. ì¼ì¼ ì²˜ë¦¬ ì¸ì› ì¡°ì •
            """)
    
    def display_realtime_logs(self, container=None):
        """ì‹¤ì‹œê°„ ë¡œê·¸ í‘œì‹œ (Streamlit)"""
        if container is None:
            container = st.container()
            
        with container:
            if self.log_messages:
                st.subheader("ğŸ“‹ ì‹¤ì‹œê°„ ë¡œê·¸")
                
                # ìµœê·¼ ë¡œê·¸ë¶€í„° í‘œì‹œ
                for log in reversed(self.log_messages[-50:]):  # ìµœê·¼ 50ê°œë§Œ
                    level = log["level"]
                    message = log["message"]
                    timestamp = log["timestamp"].split("T")[1].split(".")[0]  # ì‹œê°„ë§Œ í‘œì‹œ
                    
                    # ë ˆë²¨ë³„ ìƒ‰ìƒ
                    if level == "ERROR":
                        st.error(f"[{timestamp}] {message}")
                    elif level == "WARNING":
                        st.warning(f"[{timestamp}] {message}")
                    elif level == "INFO":
                        st.info(f"[{timestamp}] {message}")
                    else:
                        st.text(f"[{timestamp}] {message}")
                        
                    # ì¶”ê°€ ë°ì´í„°ê°€ ìˆìœ¼ë©´ í‘œì‹œ
                    if log.get("data"):
                        with st.expander("ìƒì„¸ ì •ë³´"):
                            st.json(log["data"])
    
    def save_failure_analysis(self, analysis: Dict[str, Any]):
        """ì‹¤íŒ¨ ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        if self.current_log_file and self.current_log_file.exists():
            with open(self.current_log_file, 'r+', encoding='utf-8') as f:
                session_data = json.load(f)
                session_data["failure_analysis"] = analysis
                f.seek(0)
                json.dump(session_data, f, ensure_ascii=False, indent=2)
                f.truncate()
    
    def get_log_files(self) -> List[Path]:
        """ì €ì¥ëœ ë¡œê·¸ íŒŒì¼ ëª©ë¡ ë°˜í™˜"""
        return sorted(self.log_dir.glob("schedule_debug_*.json"), reverse=True)
    
    def load_log_file(self, filename: str) -> Dict[str, Any]:
        """ë¡œê·¸ íŒŒì¼ ë¡œë“œ"""
        filepath = self.log_dir / filename
        if filepath.exists():
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}


def create_debug_summary(config: Dict[str, Any], status: str, logs: str) -> str:
    """ë””ë²„ê·¸ ìš”ì•½ ì •ë³´ ìƒì„±"""
    summary = []
    summary.append(f"ìƒíƒœ: {status}")
    summary.append(f"íƒ€ì„ìŠ¤íƒ¬í”„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # ì£¼ìš” ì„¤ì • ì •ë³´
    if "activities" in config:
        activities_df = config["activities"]
        if isinstance(activities_df, pd.DataFrame):
            summary.append(f"í™œë™ ìˆ˜: {len(activities_df[activities_df['use'] == True])}")
            
            # ëª¨ë“œë³„ í™œë™ ìˆ˜
            if 'mode' in activities_df.columns:
                mode_counts = activities_df[activities_df['use'] == True]['mode'].value_counts()
                for mode, count in mode_counts.items():
                    summary.append(f"  - {mode}: {count}ê°œ")
    
    if "job_acts_map" in config:
        job_df = config["job_acts_map"]
        if isinstance(job_df, pd.DataFrame):
            summary.append(f"ì§ë¬´ ìˆ˜: {len(job_df)}")
            summary.append(f"ì´ ì§€ì›ì: {job_df['count'].sum()}ëª…")
    
    if "precedence" in config:
        prec_df = config["precedence"]
        if isinstance(prec_df, pd.DataFrame):
            summary.append(f"ì„ í›„í–‰ ì œì•½: {len(prec_df)}ê°œ")
            if 'adjacent' in prec_df.columns:
                adj_count = len(prec_df[prec_df['adjacent'] == True])
                if adj_count > 0:
                    summary.append(f"  - ì—°ì† ë°°ì¹˜: {adj_count}ê°œ")
    
    # ë¡œê·¸ì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ
    if "INFEASIBLE" in logs:
        summary.append("\nâš ï¸ í•´ê²° ë¶ˆê°€ëŠ¥í•œ ì œì•½ ì¡°ê±´ì´ ìˆìŠµë‹ˆë‹¤.")
    elif "NO_SOLUTION" in logs:
        summary.append("\nâš ï¸ ì£¼ì–´ì§„ ê¸°ê°„ ë‚´ì— ëª¨ë“  ì§€ì›ìë¥¼ ë°°ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return "\n".join(summary)

def create_debug_ui():
    """ë””ë²„ê·¸ UI ì»´í¬ë„ŒíŠ¸ ìƒì„±"""
    with st.expander("ğŸ› ë””ë²„ê·¸ ì˜µì…˜", expanded=False):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            debug_mode = st.checkbox("ë””ë²„ê·¸ ëª¨ë“œ", key="debug_mode_checkbox")
            save_logs = st.checkbox("ë¡œê·¸ íŒŒì¼ ì €ì¥", key="save_logs_checkbox", value=True)
        
        with col2:
            show_realtime = st.checkbox("ì‹¤ì‹œê°„ ë¡œê·¸ í‘œì‹œ", key="show_realtime_checkbox")
            show_details = st.checkbox("ìƒì„¸ ì •ë³´ í‘œì‹œ", key="show_details_checkbox")
        
        with col3:
            log_level = st.selectbox(
                "ë¡œê·¸ ë ˆë²¨",
                ["INFO", "DEBUG", "WARNING", "ERROR"],
                key="log_level_select"
            )
        
        return {
            "debug_mode": debug_mode,
            "save_logs": save_logs,
            "show_realtime": show_realtime,
            "show_details": show_details,
            "log_level": log_level
        }

def display_failure_analysis(analysis: Dict[str, Any]):
    """ì‹¤íŒ¨ ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    st.error(f"âŒ ìŠ¤ì¼€ì¤„ë§ ì‹¤íŒ¨: {analysis['status']}")
    
    if analysis["possible_causes"]:
        st.markdown("### ğŸ” ê°€ëŠ¥í•œ ì›ì¸")
        for cause in analysis["possible_causes"]:
            st.markdown(f"- {cause}")
    
    if analysis["suggestions"]:
        st.markdown("### ğŸ’¡ í•´ê²° ë°©ì•ˆ")
        for suggestion in analysis["suggestions"]:
            st.markdown(f"- {suggestion}")
    
    # ë¡œê·¸ ë‹¤ìš´ë¡œë“œ ë§í¬
    if st.session_state.get("debug_helper"):
        helper = st.session_state["debug_helper"]
        log_content = "\n".join(helper.logs)
        st.download_button(
            "ğŸ“¥ ì „ì²´ ë¡œê·¸ ë‹¤ìš´ë¡œë“œ",
            log_content,
            file_name=f"debug_log_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
            mime="text/plain"
        ) 