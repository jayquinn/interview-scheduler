# %%
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import itertools, pandas as pd        # â† import ëŠ” ê·¸ëŒ€ë¡œ

def _build_param_grid() -> pd.DataFrame:       # â˜… ìƒˆ í•¨ìˆ˜
    seed_rows = [
        dict(priority=0, scenario_id="S_SAFE", wave_len=35, max_wave=18,
             br_offset_A=4, br_offset_B=3, min_gap_min=5, tl_sec=30)
    ]

    grid = []
    for wl, mw, brA, brB, mg in itertools.product(
            [35], [18], [-2,-1,0,1,2], [-2,-1,0,1,2], [5]):
        if wl==50 and mw==16 and brA==3 and brB==2 and mg==5:
            continue
        pr = 1
        if wl > 35: pr += 1
        if mw < 14: pr += 1
        if mg > 10: pr += 1
        grid.append(dict(priority=pr, wave_len=wl, max_wave=mw,
                         br_offset_A=brA, br_offset_B=brB,
                         min_gap_min=mg, tl_sec=30))

    df = (pd.DataFrame(seed_rows + grid)
            .sort_values(["priority","wave_len","min_gap_min","max_wave"])
            .reset_index(drop=True))

    if "scenario_id" not in df.columns:
        df.insert(0, "scenario_id",
                  [f"S{str(i+1).zfill(3)}" for i in range(len(df))])
    else:
        mask = df["scenario_id"].isna() | (df["scenario_id"]=="")
        df.loc[mask, "scenario_id"] = [
            f"S{str(i+1).zfill(3)}" for i in range(mask.sum())
        ]
    return df
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


# %%
# interview_opt_test_v4.py
# -*- coding: utf-8 -*-
"""
============================================================
Interview Schedule Optimiser â€“ multi-date / multi-grid
============================================================
* parameter_grid_test_v4.csv ì— ì •ì˜ëœ íŒŒë¼ë¯¸í„° ì„¸íŠ¸ Ã— ë‚ ì§œë¥¼ ìˆœì°¨ íƒìƒ‰
* ì²« SAT+í•˜ë“œë£° í†µê³¼ í•´ë¥¼ ì°¾ìœ¼ë©´ ê·¸ ë‚ ì§œëŠ” ì¢…ë£Œ
* ê²°ê³¼ëŠ” schedule_wide.csv ë¡œ ëˆ„ì  ì €ì¥, ì‹œë„ ë‚´ì—­ì€ run_log.csv ê¸°ë¡
"""
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 0. ê³µí†µ import & ìƒìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import sys, itertools, time
from datetime import timedelta
from pathlib import Path
from collections import defaultdict
import yaml
import pandas as pd, yaml
from pandas.api.types import is_integer_dtype
from ortools.sat.python import cp_model
from tqdm import tqdm

# ê³ ì • íŒŒì¼ ê²½ë¡œ
CAND_CSV = Path("candidate_activities_input_before_test_v4_HF.csv")
GRID_CSV = Path("parameter_grid_test_v4.csv")
YAML_FILE = Path("precedence_config_test_v4_HF.yaml")

OUT_WIDE = Path("schedule_wide_test_v4_HF.csv")
OUT_LOG  = Path("log/run_log_test_v4_HF.csv")
Path("log").mkdir(exist_ok=True)          # log í´ë” ë³´ì¥
from types import SimpleNamespace

def load_params(row):
    """grid CSV í•œ í–‰ â†’ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê°ì²´"""
    return SimpleNamespace(
        wave_len     = int(row.wave_len),
        max_wave     = int(row.max_wave),
        br_offset_A  = int(row.br_offset_A),
        br_offset_B  = int(row.br_offset_B),
        min_gap_min  = int(row.min_gap_min),
        tl_sec       = int(row.tl_sec),
    )
# â”€â”€ activities helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_all_activities(yaml_path: Path, df_candidates: pd.DataFrame) -> list[str]:
    """precedence YAML + CSVì—ì„œ í™œë™ëª… set ì¶”ì¶œ â†’ ì•ŒíŒŒë²³ìˆœ list"""
    prec = yaml.safe_load(open(yaml_path, encoding="utf-8"))

    acts = set(df_candidates["activity"].unique())          # â‘  CSVì— ì‹¤ì œ ë“±ì¥
    # â‘¡ YAML â€“ common
    for r in prec.get("common", []):
        acts.update([r["predecessor"], r["successor"]])
    # â‘¢ YAML â€“ by_code
    for branches in prec.get("by_code", {}).values():
        for rules in branches.values():
            for r in rules:
                acts.update([r["predecessor"], r["successor"]])
    return sorted(acts)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‚¬ì´í´ ê²€ì¦ í•¨ìˆ˜ ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def detect_cycle(edges):
    """
    edges: [(pred, succ), â€¦] ë¦¬ìŠ¤íŠ¸.
    ìˆœí™˜ì´ ìˆìœ¼ë©´ True ë°˜í™˜.
    """
    # 1) ê·¸ë˜í”„ ìƒì„±
    g = defaultdict(list)
    nodes = set()
    for u, v in edges:
        g[u].append(v)
        nodes.add(u)
        nodes.add(v)

    visited, onstack = set(), set()
    def dfs(u):
        visited.add(u)
        onstack.add(u)
        for w in g.get(u, []):
            if w not in visited:
                if dfs(w):
                    return True
            elif w in onstack:
                return True
        onstack.remove(u)
        return False

    # 2) ë¯¸ë¦¬ ì¶”ì¶œí•œ ë…¸ë“œ ì§‘í•©ìœ¼ë¡œ ìˆœí™˜ ê²€ì‚¬
    return any(dfs(node) for node in nodes if node not in visited)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def expand_availability(df_raw: pd.DataFrame) -> pd.DataFrame:
    """
    UI ì—ì„œ ë°›ì€ ì§‘ê³„í˜• space_availability
      (date Â· *_count Â· *_cap Â· ì‚¬ìš©ì—¬ë¶€ â€¦)
    â†’ solver ê°€ ìš”êµ¬í•˜ëŠ”
      (date Â· loc Â· capacity_max/override) í–‰ ë‹¨ìœ„ DF ë¡œ ë³€í™˜
    """
    rows = []
    ROOM_TYPES = [
        ("ë°œí‘œë©´ì ‘ì‹¤", "ë°œí‘œë©´ì ‘ì‹¤_cap",   "ë°œí‘œë©´ì ‘ì‹¤_count"),
        ("ì‹¬ì¸µë©´ì ‘ì‹¤", "ì‹¬ì¸µë©´ì ‘ì‹¤_cap",   "ì‹¬ì¸µë©´ì ‘ì‹¤_count"),
        ("ì»¤í”¼ì±—ì‹¤",   "ì»¤í”¼ì±—ì‹¤_cap",     "ì»¤í”¼ì±—ì‹¤_count"),
        ("ë°œí‘œì¤€ë¹„ì‹¤", "ë°œí‘œì¤€ë¹„ì‹¤_cap",   "ë°œí‘œì¤€ë¹„ì‹¤_count"),
    ]

    for _, r in df_raw.iterrows():
        if str(r.get("ì‚¬ìš©ì—¬ë¶€", "TRUE")).upper() == "FALSE":
            continue                      # ì‚¬ìš© ì•ˆ í•˜ëŠ” ë‚ ì§œë©´ skip
        date = pd.to_datetime(r["date"])
        for base, cap_col, cnt_col in ROOM_TYPES:
            n_room = int(r[cnt_col])
            cap    = int(r[cap_col])
            for i in range(1, n_room + 1):
                loc = f"{base}{chr(64+i)}"        # A,B,Câ€¦
                rows.append({
                    "date":           date,
                    "loc":            loc,
                    "capacity_max":   cap,        # capacity_override ë¡œ ì“°ì…”ë„ OK
                })
    return pd.DataFrame(rows)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. í•˜ë“œ-ë£° ê²€ì¦ í•¨ìˆ˜ (ìˆœì„œ + Wave ì •ë ¬)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# --- ê°„ê²°í•´ì§„ verify_rules ---
# â”€â”€â”€ PATCH-3 : ê¸°ì¡´ verify_rules() í•¨ìˆ˜ í†µì§¸ë¡œ ê°ˆì•„ë¼ìš°ê¸° â”€â”€â”€
def verify_rules(wide: pd.DataFrame,
                 yaml_rules: dict,
                 params: dict,                     # â† NEW
                 wave_len: int = 30,
                 company_end = pd.to_timedelta("17:45:00")) -> bool:
     # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ NEW: íŒŒë¼ë¯¸í„°ë¡œë¶€í„° ì˜¤í”„ì…‹ ì½ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # --- optional columns safeguard ---
    for a in ("ì¸ì„±ê²€ì‚¬", "í† ë¡ ë©´ì ‘"):
        for p in ("loc","start","end"):
            col = f"{p}_{a}"
            if col not in wide.columns:
                wide[col] = pd.NA
    br_offset_A = int(params.get("br_offset_A", 3))   # ë””í´íŠ¸ = 3
    br_offset_B = int(params.get("br_offset_B", 2))   # ë””í´íŠ¸ = 2
    default_codes = {
        c for c, b in yaml_rules.get("by_code", {}).items()
        if "default" in b and not ("A" in b or "B" in b)
    }
    """
    í•˜ë“œë£°: â‘  precedence â‘¡ í† ë¡ -ì¸ì„± Î´-ê²©ì(0-60, 5ë¶„) â‘¢ 17:30 ì´ì „ ì¢…ë£Œ
    ìœ„ë°˜ ì‹œ ë°”ë¡œ âŒ ë¡œê·¸ ì¶œë ¥ í›„ False
    """
    for _, r in wide.iterrows():
        cid = r["id"]
        arr_off = 0 if str(r["loc_ì¸ì„±ê²€ì‚¬"]).endswith("A") else 5
        code = r["code"]
        if code in default_codes:
            branch = "default"
        else:
            branch = "A" if arr_off == 0 else "B"
        # ---------- â‘  precedence ----------
        def viol(p, s, g):
            if pd.isna(r[f"start_{p}"]) or pd.isna(r[f"start_{s}"]):
                return False
            if r[f"end_{p}"] + pd.Timedelta(minutes=g) > r[f"start_{s}"]:
                print(f"âŒ precedence {cid}: {p}->{s}  "
                      f"end={r[f'end_{p}'].time()} "
                      f"start={r[f'start_{s}'].time()} gap={g}")
                return True
            return False

        for rule in yaml_rules.get("common", []):
            if viol(rule["predecessor"], rule["successor"], rule["min_gap_min"]):
                return False
        for code, branches in yaml_rules.get("by_code", {}).items():
            if r["code"] != code:
                continue
            if code in default_codes:
                rules_iter = branches.get("default", [])
            else:
                rules_iter = branches.get(branch, []) + branches.get("default", [])
            for rule in rules_iter:
                if viol(rule["predecessor"], rule["successor"], rule["min_gap_min"]):
                    return False

        # ---------- â‘¡ Î´-ê²©ì ----------
        if pd.notna(r["start_í† ë¡ ë©´ì ‘"]):
            raw = (r["start_í† ë¡ ë©´ì ‘"] - r["start_ì¸ì„±ê²€ì‚¬"]).total_seconds() / 60

            if branch == "A" or branch == "default":        # ì¸ì„± â†’ í† ë¡ 
                base = raw - br_offset_A * wave_len         #   Î´ = slide (0â€¥60)
            else:                                           # branch == "B"  í† ë¡  â†’ ì¸ì„±
                base = raw + br_offset_B * wave_len         #   (rawê°€ ìŒìˆ˜ â‡’ + ë¡œ ë³´ì •)

            if base % 5 or not (0 <= base <= 60):
                print(f"âŒ Î´-grid  {cid}: rawÎ”={raw}  base={base}")
                return False
        # ---------- â‘¢ 17:30 ì´ˆê³¼ ----------
        # wide DF ì•ˆì— ì‹¤ì œë¡œ ìˆëŠ” end_ ì»¬ëŸ¼ë§Œ ê²€ì‚¬
        for col in [c for c in wide.columns if c.startswith("end_")]:
            if pd.isna(r[col]):
                continue
            if (r[col] - r[col].normalize()) > company_end:
                print(f"âŒ overtime {cid}: {col}={r[col].time()}")
                return False


    return True

       # â† lit ë„ ê°™ì´
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. build_model() â€“  **ì—”ì§„**  (ê¸°ì¡´ ì½”ë“œë¥¼ í•¨ìˆ˜í™”Â·ê²½ëŸ‰í™”)
#    â†’  SAT & ê·œì¹™í†µê³¼ : ('OK', wide_df)
#       ê·œì¹™ìœ„ë°˜      : ('RULE', None)
#       UNSAT/íƒ€ì„ì•„ì›ƒ : ('UNSAT', None)
#       ì˜ˆì™¸          : ('ERR',  None)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_model(the_date: pd.Timestamp,
                params: dict,
                cfg: dict      # â† CSV ë¬¶ìŒ
               ) -> tuple[str, pd.DataFrame | None]:
    """
    ë°˜í™˜ ('OK'|'RULE_VIOL'|'UNSAT'|'ERR', wide_df or None)
    """



    try:
        # â”€â”€ 2-1. ë‚ ì§œ í•„í„° â”€â”€
        df_cand = cfg["df_raw"][cfg["df_raw"]["interview_date"] == the_date].copy()
        if df_cand.empty:
            return "NO_DATA", None
        ALL_ACTS = get_all_activities(YAML_FILE, df_cand)  
        # â”€â”€ 2-2. ì§§ì€ ë³„ì¹­ â”€â”€
        cfg_duration = cfg["cfg_duration"].copy()
        cfg_avail    = cfg["cfg_avail"].copy()
        # ì§‘ê³„í˜• í…Œì´ë¸”(date Â· *_count â€¦)ì´ë©´ í–‰ ë‹¨ìœ„(loc) í˜•íƒœë¡œ í¼ì¹œë‹¤
        if "loc" not in cfg_avail.columns:
            cfg_avail = expand_availability(cfg_avail)
        cfg_map      = cfg["cfg_map"]
        cfg_oper     = cfg["cfg_oper"]
        prec_yaml = cfg["prec_yaml"]
        # â–¶ï¸ NEW â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        group_meta      = cfg.get("group_meta", pd.DataFrame()).copy()
        MODE            = group_meta.set_index("activity")["mode"].to_dict()
        MIN_CAP_ACT     = group_meta.set_index("activity")["min_cap"].to_dict()
        MAX_CAP_ACT     = group_meta.set_index("activity")["max_cap"].to_dict()
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # â–¶ï¸ NEW: invalid config â†’ ì¦‰ì‹œ ì˜ˆì™¸
        for act, md in MODE.items():
            if md != "batched" and MAX_CAP_ACT.get(act, 1) > 1:
                raise ValueError(f"[CONFIG] '{act}' ëŠ” individual ì¸ë° max_cap > 1")
            if MIN_CAP_ACT.get(act, 1) > MAX_CAP_ACT.get(act, 1):
                raise ValueError(f"[CONFIG] '{act}'  min_cap > max_cap")
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ëª¨ë¸ íŒŒë¼ë¯¸í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        WAVE_LEN = int(params["wave_len"])
        MAX_WAVE = int(params["max_wave"])
        tl_sec   = int(params["tl_sec"])
        MIN_GAP  = int(params["min_gap_min"])
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 0. ìƒìˆ˜ ë° ì„¤ì • â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        INPUT_CSV    = CAND_CSV

        DEBUG = True

        TALK_GMIN, TALK_GMAX = 3, 5
        W_MAKESPAN, W_GAP_AB, W_WAIT, W_SOFT, W_OT = 1000, 300, 200, 200, 1
        W_SLIDE = 80

        ENABLE_CAPACITY  = True
        COMPANY_END_CAL  = 17*60 + 45



        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 2. ì „ì²˜ë¦¬ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 2-1 duration & act_space
        cfg_duration["duration_min"] = pd.to_numeric(
            cfg_duration["duration_min"], errors="coerce"
        ).fillna(0).astype(int)
        DUR = cfg_duration.set_index("activity")["duration_min"].to_dict()

        df_cand = df_cand.merge(
            cfg_duration[["activity","duration_min"]],
            on="activity", how="left"
        )
        if df_cand["duration_min"].isna().any():
            miss = df_cand.loc[df_cand["duration_min"].isna(), "activity"].unique()
            raise ValueError(f"[CONFIG] duration ê°’ì´ ì—†ëŠ” í™œë™: {miss}")

        df_cand["duration_min"] = df_cand["duration_min"].astype(int)

        ACT_SPACE = cfg_map.groupby("activity")["loc"].apply(list).to_dict()
        DEBATE_ROOMS = ACT_SPACE.get("í† ë¡ ë©´ì ‘", [])

        if DEBUG:                        # ğŸ ìƒˆ ë””ë²„ê·¸ ì¶œë ¥
            print("[bm] ACT_SPACE keys:", list(ACT_SPACE.keys())[:5])

        for a in ACT_SPACE:
            ACT_SPACE[a].sort()
        def get_space(act: str):
            """ACT_SPACE ì•ˆì „ ë˜í¼ â€“ ì •ì˜ë¼ ìˆì§€ ì•Šìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
            return ACT_SPACE.get(act, [])
        # 2-2 capacity
        cfg_avail["capacity_effective"] = pd.to_numeric(
            cfg_avail["capacity_override"], errors="coerce"
        ).fillna(cfg_avail["capacity_max"]).astype(int)
        CAP = cfg_avail.set_index(["loc","date"])["capacity_effective"].to_dict()
        if DEBUG:
            print("[bm] CAP sample   :", list(CAP.items())[:5])
        # 2-3 operating window
        cfg_oper["start_dt"] = pd.to_datetime(
            cfg_oper["date"].dt.strftime("%Y-%m-%d") + " " + cfg_oper["start_time"]
        )
        cfg_oper["end_dt"] = pd.to_datetime(
            cfg_oper["date"].dt.strftime("%Y-%m-%d") + " " + cfg_oper["end_time"]
        )
        # â‘  ìš´ì˜ì°½ dict
        OPER = cfg_oper.set_index(["code", "date"])[["start_dt", "end_dt"]].to_dict("index")

        # â‘¡ ê° ì „í˜•ë³„ ìš´ì˜ ê¸¸ì´Â·ìˆ˜í‰ì„ 
        OPER_LEN = {
            (c, d): int((v["end_dt"] - v["start_dt"]).total_seconds() // 60)
            for (c, d), v in OPER.items()
        }
        HORIZON = max(OPER_LEN.values())
        # # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ YAML ë¡œë“œ: ê¸°ë³¸ branch ì½”ë“œ íŒŒì•… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # prec_yaml = yaml.safe_load(open(YAML_FILE, encoding="utf-8"))
        # default_codes = {
        #     c for c, b in prec_yaml.get("by_code", {}).items()
        #     if "default" in b and not ("A" in b or "B" in b)
        # }
        default_codes = {
        c for c, b in prec_yaml.get("by_code", {}).items()
        if "default" in b and not ("A" in b or "B" in b)
        }
        # 2-4 lookup dicts
        CIDS     = sorted(df_cand["id"].unique())
        CODE_MAP = df_cand.set_index("id")["code"].to_dict()

        # â•â•â•â•â• 2-5 íŒ€ & ë™ì„  ì´ˆê¸° ë°°ì • â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        isA         = {cid: (i % 2 == 0) for i,cid in enumerate(CIDS)}
        init_Tfirst = {cid: (i % 2 == 1) for i,cid in enumerate(CIDS)}

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 3. ëª¨ë¸ êµ¬ì¶• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€ helper (ëª¨ë¸ ë‚´ë¶€ ì „ìš©) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        def _apply_prec_constraint(cid, pred, succ, min_gap, extra_lits=None):
            """
            cid      : ì§€ì›ì id
            pred,succ: activity ì´ë¦„
            min_gap  : ë¶„
            extra_lits (list[BoolVar]) : ì¡°ê±´ë¶€ í™œì„±í™”ìš© ì¶”ê°€ ë¦¬í„°ëŸ´
            """
            if extra_lits is None:
                extra_lits = []

            for loc_p in ACT_SPACE.get(pred, []):
                if (cid, pred, loc_p) not in sel:
                    continue
                for loc_s in ACT_SPACE.get(succ, []):
                    if (cid, succ, loc_s) not in sel:
                        continue

                    lit = model.NewBoolVar(f"PRE_{cid}_{pred}->{succ}")
                    model.AddAssumption(lit)
                    ASSUMPTIONS.append(lit)
                    ASSUME_IDX[lit.Index()] = lit
                    conds = [sel[cid, pred, loc_p],
                            sel[cid, succ, loc_s],
                            lit] + extra_lits

                    model.Add(
                        start[cid, succ, loc_s] + ARR_OFF[cid] >=
                        end[cid,   pred, loc_p] + ARR_OFF[cid] + min_gap
                    ).OnlyEnforceIf(conds)
        ASSUMPTIONS = []
        ASSUME_IDX = {}
        model = cp_model.CpModel()
        start,end,sel,iv = {},{},{},{}
        cid_iv, loc_iv = defaultdict(list), defaultdict(list)

        # ----------  Branch ì„ íƒ BoolVar + Offset IntVar  ----------
        isA_lit, ARR_OFF, BR_OFFSET = {}, {}, {}

        OFFSET_A = params['br_offset_A']     # e.g. 4
        OFFSET_B = params['br_offset_B']     # e.g. 3

        for cid in CIDS:
            # 1) A-branch?  BoolVar
            lit = model.NewBoolVar(f"isA_{cid}")
            model.AddHint(lit, 1 if isA[cid] else 0)   # ì˜ˆì „ isA[] ê°’ì€ íŒíŠ¸ë¡œë§Œ
            isA_lit[cid] = lit

            # 2) ARR_OFF   0 (A) / 5 (B)
            arr = model.NewIntVar(0, 5, f"arrOff_{cid}")
            ARR_OFF[cid] = arr
            model.Add(arr == 0).OnlyEnforceIf(lit)
            model.Add(arr == 5).OnlyEnforceIf(lit.Not())

            # 3) BR_OFFSET  offset_A / offset_B
            # br = model.NewIntVar(min(OFFSET_A, OFFSET_B),
            #                     max(OFFSET_A, OFFSET_B),
            #                     f"brOff_{cid}")
            # BR_OFFSET[cid] = br
            # model.Add(br == OFFSET_A).OnlyEnforceIf(lit)
            # model.Add(br == OFFSET_B).OnlyEnforceIf(lit.Not())
            BR_OFFSET[cid] = (isA_lit[cid]       *  OFFSET_A +
                            isA_lit[cid].Not() * (-OFFSET_B))
        # -----------------------------------------------------------
        # IntervalVar ìƒì„±
        for _, row in df_cand.iterrows():
            cid, act, dur = row["id"], row["activity"], row["duration_min"]
            for loc in ACT_SPACE[act]:
                if act in ("ì¸ì„±ê²€ì‚¬", "ë°œí‘œë©´ì ‘"):
                    pass
                if CAP.get((loc, the_date), 0) == 0:
                    continue

                # ---- Interval & decision var ----
                s = model.NewIntVar(0, HORIZON, f"s_{cid}_{act}_{loc}")
                e = model.NewIntVar(0, HORIZON, f"e_{cid}_{act}_{loc}")
                x = model.NewBoolVar(f"x_{cid}_{act}_{loc}")
                ivar = model.NewOptionalIntervalVar(s, dur, e, x,
                                                    f"iv_{cid}_{act}_{loc}")
                start[cid, act, loc], end[cid, act, loc], sel[cid, act, loc], iv[cid, act, loc] = (
                    s, e, x, ivar
                )
                if MODE.get(act, "individual") != "parallel":   # parallel ì€ NoOverlap ëŒ€ìƒ ì œì™¸
                    cid_iv[cid].append(ivar)
                if dur > 0:
                    loc_iv[loc, the_date].append(ivar)

                # ---- â‘  5ë¶„ ê²©ì ê°•ì œ (ë°œí‘œ ì¤€ë¹„Â·ë©´ì ‘) ----
                if act in ("ë°œí‘œì¤€ë¹„", "ë°œí‘œë©´ì ‘"):
                    k = model.NewIntVar(0, HORIZON // 5,
                                        f"k_{cid}_{act}_{loc}")  # 5-ë¶„ ê·¸ë¦¬ë“œ ì¸ë±ìŠ¤

                    # start + ARR_OFF ê°€ 5 ì˜ ë°°ìˆ˜ â‡’ 5 ë¶„ ê²©ì
                    model.Add(s + ARR_OFF[cid] == k * 5).OnlyEnforceIf(x)

            # ---- â‘¡ exactly-1 loc per activity (loc loop ë°”ê¹¥) ----
            model.Add(
                sum(sel[cid, act, l]                       # â† sel dict ëŠ” ìœ„ì—ì„œ ì±„ì›€
                    for l in ACT_SPACE[act]
                    if (cid, act, l) in sel) == 1
            )

        # 3-1b T_FIRST
        T_FIRST = {cid: model.NewBoolVar(f"Tfirst_{cid}") for cid in CIDS}
        for cid in CIDS:
            if init_Tfirst[cid]:
                model.AddHint(T_FIRST[cid],1)
        # 3-2 (ì„ íƒì ) ê·¸ë£¹ í™œë™ Wave / Î´-slide ë¡œì§ â”€â”€â”€â”€â”€â”€â”€â”€
        SLIDE_UNIT = 5            # 5ë¶„ ë‹¨ìœ„
        SLIDE_MAX  = 12           # 0â€¥60ë¶„
        # HAS_GROUP = bool(get_space("ì¸ì„±ê²€ì‚¬")) and bool(get_space("í† ë¡ ë©´ì ‘"))
        # ë‚ ì§œë³„ ì§€ì›ì ëª©ë¡ì— í† ë¡ ë©´ì ‘ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ë¡œ íŒë‹¨
        # AFTER  â”€â”€ (build_model() ìƒë‹¨, MODEÂ·MIN_CAP_ACTÂ·MAX_CAP_ACT ë§Œë“  ë°”ë¡œ ì•„ë˜) â”€â”€
        BATCH_ACTS = [a for a, m in MODE.items() if m == "batched"]
        HAS_GROUP  = df_cand["activity"].isin(BATCH_ACTS).any()

        # ëª¨ë“  batched í™œë™ì— ëŒ€í•´ {act: cap} dict ë¡œ ë³´ê´€
        GROUP_MIN = {a: MIN_CAP_ACT.get(a, 1) for a in BATCH_ACTS}
        GROUP_MAX = {a: MAX_CAP_ACT.get(a, 999) for a in BATCH_ACTS}
        # HAS_GROUPì„ ê³„ì‚°í•œ **ë’¤**ì— ê°€ì¤‘ì¹˜ ê²°ì •
        gap_ab_wt = 0 if not HAS_GROUP else W_GAP_AB
        slide_wt  = 0 if not HAS_GROUP else W_SLIDE
        # ---------- (1) ê³µí†µ ë”ë¯¸ ë³€ìˆ˜ ë¨¼ì € ë§Œë“¤ê¸° ----------
        # â†’ HAS_GROUP ì´ False ì—¬ë„ ì•„ë˜ìª½ ì½”ë“œê°€ ì•ˆì „í•˜ê²Œ ì°¸ì¡° ê°€ëŠ¥
        y = {}                                          # wave ë°°ì • BoolVar
        delta_unit = []                                # ì „ì²´ Î´-unit(IntVar) ë¦¬ìŠ¤íŠ¸
        delta_unit_cid = {cid: model.NewIntVar(0, 0, f"dSel_{cid}") for cid in CIDS}
        I_wave =      {cid: model.NewIntVar(0, 0, f"Iwave_{cid}")   for cid in CIDS}
        slide_penalty = 0                              # ëª©ì í•¨ìˆ˜ìš© ê¸°ë³¸ê°’
        if HAS_GROUP:
            print("=== Wave capacity debug ===")
            y = {}
            for cid in CIDS:
                for room in ("ì¸ì„±ê²€ì‚¬ì‹¤A","ì¸ì„±ê²€ì‚¬ì‹¤B","ì¸ì„±ê²€ì‚¬ì‹¤C"):
                    if (cid,"ì¸ì„±ê²€ì‚¬",room) not in sel: continue
                    for w in range(MAX_WAVE):
                        y[cid,room,w] = model.NewBoolVar(f"y_{cid}_{room}_{w}")
                        model.Add(sel[cid,"ì¸ì„±ê²€ì‚¬",room] == 1).OnlyEnforceIf(y[cid,room,w])
                        model.Add(start[cid,"ì¸ì„±ê²€ì‚¬",room] == w*WAVE_LEN).OnlyEnforceIf(y[cid,room,w])
                    model.Add(sum(y[cid,room,w] for w in range(MAX_WAVE)) == sel[cid,"ì¸ì„±ê²€ì‚¬",room])

            # wave ë™ì‹œì…ì‹¤(3â€“5)
            for room in ("ì¸ì„±ê²€ì‚¬ì‹¤A","ì¸ì„±ê²€ì‚¬ì‹¤B","ì¸ì„±ê²€ì‚¬ì‹¤C"):
                for w in range(MAX_WAVE):
                    members = [y[c,room,w] for c in CIDS if (c,room,w) in y]
                    if not members: continue
                    non_empty = model.NewBoolVar(f"nonEmpty_{room}_{w}")
                    model.Add(sum(members)>0).OnlyEnforceIf(non_empty)
                    model.Add(sum(members)==0).OnlyEnforceIf(non_empty.Not())
                    # model.Add(sum(members)>=3).OnlyEnforceIf(non_empty)
                    # model.Add(sum(members)<=5).OnlyEnforceIf(non_empty)
                    # model.Add(sum(members) >= GROUP_MIN).OnlyEnforceIf(non_empty)
                    # model.Add(sum(members) <= GROUP_MAX).OnlyEnforceIf(non_empty)
                    act = "ì¸ì„±ê²€ì‚¬"      # â† ì´ë¯¸ ê·¸ ë¸”ë¡ì´ ì¸ì„±ê²€ì‚¬ìš©ì´ë©´ í•˜ë“œì½”ë”© ê·¸ëŒ€ë¡œ ë‘¬ë„ ë¬´ë°©
                    model.Add(sum(members) >= GROUP_MIN[act]).OnlyEnforceIf(non_empty)
                    model.Add(sum(members) <= GROUP_MAX[act]).OnlyEnforceIf(non_empty)
            # ì¸ì„±ê²€ì‚¬ ì¢…ë£Œ ì‹œê° ì €ì¥
            # I_END = {}
            # for cid in CIDS:
            #     lst = [end[cid, "ì¸ì„±ê²€ì‚¬", l]
            #         for l in ACT_SPACE.get("ì¸ì„±ê²€ì‚¬", [])
            #         if (cid, "ì¸ì„±ê²€ì‚¬", l) in end]
            #     if lst:                      # ì¸ì„±ê²€ì‚¬ ìˆëŠ” ê²½ìš°ì—ë§Œ ì €ì¥
            #         I_END[cid] = lst[0]

            # I_wave ì •ì˜
            I_wave = {}
            for cid in CIDS:
                wvar = model.NewIntVar(0, MAX_WAVE-1, f"Iwave_{cid}")
                I_wave[cid] = wvar
                for room in ("ì¸ì„±ê²€ì‚¬ì‹¤A","ì¸ì„±ê²€ì‚¬ì‹¤B",'ì¸ì„±ê²€ì‚¬ì‹¤C'):
                    key = (cid,"ì¸ì„±ê²€ì‚¬",room)
                    if key in start:
                        model.Add(wvar*WAVE_LEN == start[key]).OnlyEnforceIf(sel[key])
            # --- B-ë¸Œëœì¹˜(í† ë¡ â†’ì¸ì„±) ìµœì†Œ wave í•˜í•œ ---  â† ìƒˆ ì½”ë“œ
            if OFFSET_B > 0:                                         # ì•ˆì „ê°€ë“œ
                for cid in CIDS:
                    model.Add(I_wave[cid] >= OFFSET_B).OnlyEnforceIf(isA_lit[cid].Not())
            # â”€â”€â”€ Î´-slideìš© z ë³€ìˆ˜ ë° â€œexactly-oneâ€ ì œì•½ (â˜… ë°©ë³„ë¡œ ê³„ì‚°) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            deb_z = {}                               # (cid, loc, abs_t) â†’ BoolVar

            # 0) í† ë¡  ë°© ëª©ë¡ & ë°©ë³„ ì¢Œì„ ìˆ˜
            DEBATE_ROOMS = ACT_SPACE.get("í† ë¡ ë©´ì ‘", [])
            ROOM_CAP = {loc: CAP[(loc, the_date)] for loc in DEBATE_ROOMS}  # ex) 5

            for cid in CIDS:
                # ì´ ì§€ì›ìê°€ ì‹¤ì œë¡œ ê°–ê³  ìˆëŠ” í† ë¡  interval í‚¤ ëª¨ìœ¼ê¸°
                debate_keys = [
                    (cid, "í† ë¡ ë©´ì ‘", loc)
                    for loc in DEBATE_ROOMS
                    if (cid, "í† ë¡ ë©´ì ‘", loc) in sel
                ]
                if not debate_keys:            # í† ë¡ ì´ ì—†ëŠ” ì§€ì›ì
                    continue

                for loc in DEBATE_ROOMS:
                    if (cid, "í† ë¡ ë©´ì ‘", loc) not in sel:
                        continue
                    for w in range(MAX_WAVE):
                        for du in range(SLIDE_MAX + 1):      # Î´-unit 0â€¥12
                            for offset, lit_ok in [(OFFSET_A,  isA_lit[cid]),   # A-branch
                                                ( -OFFSET_B, isA_lit[cid].Not() )]:  # B
                                abs_t = (w + offset) * WAVE_LEN + du * SLIDE_UNIT
                                if abs_t < 0 or abs_t > HORIZON + 60:   # ì•ˆì „ê°€ë“œ
                                    continue

                                z = model.NewBoolVar(f"deb_{cid}_{loc}_{abs_t}")
                                deb_z[cid, loc, abs_t] = z

                                model.Add(sel[cid,"í† ë¡ ë©´ì ‘",loc] == 1).OnlyEnforceIf([z, lit_ok])
                                model.Add(start[cid,"í† ë¡ ë©´ì ‘",loc] + ARR_OFF[cid] == abs_t).OnlyEnforceIf([z, lit_ok])
                # í•œ ì§€ì›ìë‹¹ z í•˜ë‚˜ë§Œ 1
                model.Add(
                    sum(deb_z[cid, loc, t]
                        for loc in DEBATE_ROOMS
                        for t in range(0, HORIZON + 60, SLIDE_UNIT)
                        if (cid, loc, t) in deb_z) == 1
                )

            # â˜… ë°©Â·ì‹œê°ë³„ ì¸ì› 3â€¥ë°©ìˆ˜ìš©ëŸ‰(cap) ì œì•½
            for loc in DEBATE_ROOMS:
                cap = ROOM_CAP[loc]              # ëŒ€ë¶€ë¶„ 5
                for abs_t in range(0, HORIZON + 60, SLIDE_UNIT):
                    members = [deb_z[cid, loc, abs_t]
                            for cid in CIDS if (cid, loc, abs_t) in deb_z]
                    if not members:
                        continue
                    non_empty = model.NewBoolVar(f"deb_nonEmpty_{loc}_{abs_t}")
                    # model.Add(sum(members) >= 3).OnlyEnforceIf(non_empty)     # ì¼œì¡Œìœ¼ë©´ â‰¥3
                    # model.Add(sum(members) <= 2).OnlyEnforceIf(non_empty.Not())   # êº¼ì¡Œìœ¼ë©´ â‰¤2
                    # model.Add(sum(members) <= cap).OnlyEnforceIf(non_empty)\
                    act = "í† ë¡ ë©´ì ‘"
                    model.Add(sum(members) >= GROUP_MIN[act]).OnlyEnforceIf(non_empty)
                    model.Add(sum(members) <= 2).OnlyEnforceIf(non_empty.Not())       # (ì´ ì¤„ì€ ê·¸ëŒ€ë¡œ)
                    model.Add(sum(members) <= cap).OnlyEnforceIf(non_empty)
            # â”€â”€ Î´-unit(IntVar) â€“ waveë‹¹ í•˜ë‚˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            delta_unit = [
                model.NewIntVar(0, SLIDE_MAX, f"deltaUnit_{w:02d}")
                for w in range(MAX_WAVE)
            ]

            # â”€â”€ í›„ë³´ë³„ Î´ ì„ íƒ ë³€ìˆ˜ & Element ì œì•½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            delta_unit_cid = {}
            for cid in CIDS:
                delta_unit_cid[cid] = model.NewIntVar(
                    0, SLIDE_MAX, f"deltaSel_{cid}")
                model.AddElement(I_wave[cid],
                                delta_unit,
                                delta_unit_cid[cid])

            # â”€â”€ ëª©ì í•¨ìˆ˜ìš© í˜ë„í‹° ê³„ì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            slide_penalty = sum(delta_unit) * SLIDE_UNIT
        else:
            I_wave = {cid: model.NewIntVar(0, 0, f"Iwave_{cid}") for cid in CIDS}
            delta_unit      = []
            delta_unit_cid  = {cid: model.NewIntVar(0, 0, f"deltaSel_{cid}") for cid in CIDS}
            slide_penalty   = 0
        # â”€â”€â”€â”€â”€ í† ë¡ ë©´ì ‘ start ì‹ ìˆ˜ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# === Î´-slide ì„ íƒ ë³€ìˆ˜ëŠ” ì´ë¯¸ ì •ì˜ ===
# delta : list[IntVar]   delta_cid : dict[cid -> IntVar]
# â”€â”€â”€ í† ë¡ ë©´ì ‘ start ë“±ì‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # â”€â”€â”€ í† ë¡ ë©´ì ‘ start ë“±ì‹ (ARR_OFF ì œê±°â€§ì¬ë°°ì¹˜) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # for cid in CIDS:
        #     for loc in DEBATE_ROOMS:
        #         key_T = (cid, "í† ë¡ ë©´ì ‘", loc)
        #         if key_T not in sel: continue

        #         model.Add(
        #             start[key_T]
        #             ==
        #             (I_wave[cid] + BR_OFFSET[cid]) * WAVE_LEN
        #             + delta_unit_cid[cid] * SLIDE_UNIT
        #         ).OnlyEnforceIf(sel[key_T])
        for cid in CIDS:
            for loc in DEBATE_ROOMS:
                key = (cid, "í† ë¡ ë©´ì ‘", loc)
                if key not in sel: continue

                # A-branch: í† ë¡  = ì¸ì„± + OFFSET_A
                model.Add(
                    start[key] ==
                    (I_wave[cid] + OFFSET_A) * WAVE_LEN +
                    delta_unit_cid[cid] * SLIDE_UNIT
                ).OnlyEnforceIf(isA_lit[cid])

                # B-branch: í† ë¡  = ì¸ì„± â€“ OFFSET_B
                model.Add(
                    start[key] ==
                    (I_wave[cid] - OFFSET_B) * WAVE_LEN +
                    delta_unit_cid[cid] * SLIDE_UNIT
                ).OnlyEnforceIf(isA_lit[cid].Not())


        # â”€â”€â”€â”€â”€â”€â”€â”€â”€ í† ë¡ ì‹¤ capacity â”€â”€â”€â”€â”€â”€â”€â”€â”€
        for loc in DEBATE_ROOMS:
            iv_list = [ iv[cid, "í† ë¡ ë©´ì ‘", loc]
                        for cid in CIDS if (cid, "í† ë¡ ë©´ì ‘", loc) in iv ]
            if iv_list:
                max_cap = CAP[(loc, the_date)]                  # CSV ê°’ (5)
                model.AddCumulative(iv_list, [1]*len(iv_list), max_cap)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ YAML ë¡œë“œ (prec ì •ì˜) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        prec = prec_yaml

                # â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3-2b Debug: precedence ì ìš© ì „ ê°€ëŠ¥ ì˜µì…˜ í™•ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€
        print("=== PRECEDENCE OPTIONS DEBUG ===")
        for cid in CIDS:
            code = CODE_MAP[cid]
            branch = "default" if code in default_codes else ("A" if isA[cid] else "B")
            # ê³µí†µ(common)
            for rule in prec.get("common", []):
                p,s = rule["predecessor"], rule["successor"]
                preds = [loc for loc in ACT_SPACE.get(p,[])     if (cid,p,loc) in sel]
                succs = [loc for loc in ACT_SPACE.get(s,[])     if (cid,s,loc) in sel]
                if not preds or not succs:
                    print(f"CID={cid}  common {p}->{s}: preds={preds}  succs={succs}")
            # by_code
            for rules in prec.get("by_code", {}).get(code, {}).get(branch, []):
                p,s = rules["predecessor"], rules["successor"]
                preds = [loc for loc in ACT_SPACE.get(p,[])     if (cid,p,loc) in sel]
                succs = [loc for loc in ACT_SPACE.get(s,[])     if (cid,s,loc) in sel]
                if not preds or not succs:
                    print(f"CID={cid}  {code}-{branch} {p}->{s}: preds={preds}  succs={succs}")
        print("=== END DEBUG ===\n")
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3-3 precedence from YAML â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # prec = yaml.safe_load(open(YAML_FILE, encoding="utf-8"))
        prec = prec_yaml
        # --- ì‚¬ì´í´ ê²€ì¦ ì‹¤í–‰ ---
        # 1) ê³µí†µ ì œì•½ ìŒ ìˆ˜ì§‘
        common_edges = [
            (c["predecessor"], c["successor"])
            for c in prec.get("common", [])
        ]
        # 2) ì½”ë“œÂ·ë¸Œëœì¹˜ë³„ë¡œ ê²€ì‚¬
        for code, branches in prec.get("by_code", {}).items():
            for branch, rules in branches.items():
                edges = common_edges + [
                    (r["predecessor"], r["successor"])
                    for r in rules
                ]
                if detect_cycle(edges):
                    print("[UNSAT] precedence cycle detected")
                    return 'UNSAT', None
        # 3-3a) ëª¨ë“  ì§€ì›ìì—ê²Œ ê³µí†µìœ¼ë¡œ ì ìš©í•  ìˆœì„œ ì œì•½
        for c in prec.get("common", []):
            for cid in CIDS:
                _apply_prec_constraint(cid,
                                    c["predecessor"],
                                    c["successor"],
                                    c["min_gap_min"])

        # 3-3b) ì½”ë“œë³„Â·branchë³„ íŠ¹ë³„ ì œì•½  â† ì „ì²´ êµì²´
        # â”€â”€â”€ 3-3b) ì½”ë“œë³„Â·branchë³„ íŠ¹ë³„ ì œì•½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        for cid in CIDS:
            code = CODE_MAP[cid]
            lit = isA_lit[cid]
            # â‘ -a ì¸ì„±ê²€ì‚¬ ë°©ê³¼ lit ì—°ê²°
            for loc in ("ì¸ì„±ê²€ì‚¬ì‹¤A","ì¸ì„±ê²€ì‚¬ì‹¤B","ì¸ì„±ê²€ì‚¬ì‹¤C"):
                key = (cid, "ì¸ì„±ê²€ì‚¬", loc)
                if key in sel:
                    if loc.endswith("A"):
                        model.Add(lit == 1).OnlyEnforceIf(sel[key])
                    else:
                        model.Add(lit == 0).OnlyEnforceIf(sel[key])



            # â‘ -b  ì¸ì„±ê²€ì‚¬ê°€ **ì•„ì˜ˆ ì—†ëŠ”** ì§€ì›ìëŠ” ììœ  ë³€ìˆ˜
            #       (íŒíŠ¸ë¥¼ ì£¼ê³  ì‹¶ìœ¼ë©´ ì—¬ê¸°ì„œ model.AddHint(isA_lit, â€¦) ê°€ëŠ¥)
            #       ë³„ë„ ì œì•½ì€ ì£¼ì§€ ì•ŠëŠ”ë‹¤.

            # â”€â”€â”€â”€â”€ branch ê°€ë ¤ë‚´ì„œ precedence ë„£ê¸° â”€â”€â”€â”€â”€
            br_A_rules = prec.get("by_code", {}).get(code, {}).get("A", [])
            br_B_rules = prec.get("by_code", {}).get(code, {}).get("B", [])
            def_rules  = prec.get("by_code", {}).get(code, {}).get("default", [])

            # A-branch rules
            for r in br_A_rules:
                _apply_prec_constraint(cid,
                                    r["predecessor"], r["successor"],
                                    r["min_gap_min"],
                                    extra_lits=[lit])

            # B-branch rules
            for r in br_B_rules:
                _apply_prec_constraint(cid,
                                    r["predecessor"], r["successor"],
                                    r["min_gap_min"],
                                    extra_lits=[lit.Not()])

            # default rules (branch ë¬´ê´€)
            for r in def_rules:
                _apply_prec_constraint(cid,
                                    r["predecessor"], r["successor"],
                                    r["min_gap_min"])
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 3-4 NoOverlap & Capacity
        for ivs in cid_iv.values():
            model.AddNoOverlap(ivs)
        if ENABLE_CAPACITY:
            for (loc,date), ivs in loc_iv.items():
                model.AddCumulative(ivs, [1]*len(ivs), CAP[loc,date])

        # 3-5  íšŒì‚¬ ì¢…ë£Œì‹œê°„ ì œí•œ  (ê¸°ì¡´ ì½”ë“œ ëŒ€ì²´)
        for (cid, act, loc), x in sel.items():
            oper_len = OPER_LEN[(CODE_MAP[cid], the_date)]      # â† ì „í˜•ë³„ ê¸¸ì´
            model.Add(end[cid, act, loc] + ARR_OFF[cid] <= oper_len).OnlyEnforceIf(x)

        # 3-7 Soft same-code wave
        codes = set(CODE_MAP.values())
        M_wave = {code: model.NewIntVar(0,MAX_WAVE-1,f"Mwave_{code}") for code in codes}
        diff_vars = []
        for cid in CIDS:
            d = model.NewIntVar(0,MAX_WAVE,f"diff_{cid}")
            model.AddAbsEquality(d, I_wave[cid] - M_wave[CODE_MAP[cid]])
            diff_vars.append(d)
        soft_penalty = sum(diff_vars)



        # ëª©ì í•¨ìˆ˜
        real_end = []
        for (cid,act,loc),x in sel.items():
            rend = model.NewIntVar(0,COMPANY_END_CAL+10,f"rend_{cid}_{act}")
            model.Add(rend == end[cid,act,loc] + ARR_OFF[cid]).OnlyEnforceIf(x)
            real_end.append(rend)
        makespan = model.NewIntVar(0,COMPANY_END_CAL+10,"makespan")
        model.AddMaxEquality(makespan, real_end)

        cntA = sum(x for (cid,a,l),x in sel.items() if a=="ë°œí‘œë©´ì ‘" and l.endswith("A"))
        cntB = sum(x for (cid,a,l),x in sel.items() if a=="ë°œí‘œë©´ì ‘" and l.endswith("B"))
        gapAB = model.NewIntVar(0,len(CIDS),"gapAB")
        model.AddAbsEquality(gapAB, cntA-cntB)
        model.Add(gapAB <= 2)
        OBJ = (W_MAKESPAN * makespan +
            gap_ab_wt   * gapAB +
            W_SOFT      * soft_penalty +
            slide_wt    * slide_penalty)
        model.Minimize(OBJ)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 4. Solver â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        solver = cp_model.CpSolver()
        solver.parameters.max_time_in_seconds = tl_sec        # 30 ì´ˆ ì œí•œ
        solver.parameters.num_search_workers  = 1
        solver.parameters.max_memory_in_mb    = 0
        solver.parameters.stop_after_first_solution = True
        solver.parameters.log_search_progress = True

        status = solver.Solve(model)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ precedence GAP ìƒ˜í”Œ ì²´í¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if status == cp_model.INFEASIBLE:        # UNSAT ì¸ ê²½ìš°ì—ë§Œ ì°ì–´ ë³´ì
            try:
                sample = []
                for cid in CIDS[:15]:            # ì• 15ëª…ë§Œ ìƒ˜í”Œ
                    for lp in ACT_SPACE['ë°œí‘œì¤€ë¹„']:
                        for ls in ACT_SPACE['ë°œí‘œë©´ì ‘']:
                            if (cid,'ë°œí‘œì¤€ë¹„',lp) in start and (cid,'ë°œí‘œë©´ì ‘',ls) in start:
                                # ì•„ì§ ê°’ì´ ì—†ì–´ë„ Var ëŠ” ì¡´ì¬ â†’ ìµœì ê°’ ëŒ€ì‹  lower/upper bound ì´ìš©
                                gap_lb = start[cid,'ë°œí‘œë©´ì ‘',ls].Proto().domain[0] - \
                                        end  [cid,'ë°œí‘œì¤€ë¹„',lp].Proto().domain[-1]
                                sample.append((cid, gap_lb))
                print("[bm] GAP lower-bounds (cid, min_gap_min í›„ë³´):", sample)
            except Exception as e:
                print("[bm] gap-debug failed:", e)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

        ARR_OFF_VAL = {cid: solver.Value(ARR_OFF[cid]) for cid in CIDS}
        BR_OFFSET_VAL = {cid: solver.Value(BR_OFFSET[cid]) for cid in CIDS}
        # â”€â”€ INFEASIBLE ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if status == cp_model.INFEASIBLE:
            if DEBUG and tl_sec >= 5:
                try:
                    core = solver.SufficientAssumptionsForInfeasibility()
                    print("âŒ UNSAT core size:", len(core))
                    for lit in core[:20]:
                        lv   = int(lit)                         # â† â‘  int() ë¡œ ìºìŠ¤íŒ…
                        sign = "Â¬" if lv < 0 else ""            # â† â‘¡ ì´ì œ int ë¡œ ë¹„êµ
                        var  = ASSUME_IDX.get(abs(lv))
                        name = var.Name() if var is not None else f"lit#{lv}"
                        print("   âŠ ", f"{sign}{name}")



                except Exception as e:
                    print("[WARN] UNSAT-core fetch failed:", e)
            else:
                print("[INFO] UNSAT (core skipped)")
            return "UNSAT", None

        # SAT í•´ê°€ ì•„ë‹ˆë©´ ë°”ë¡œ ì¢…ë£Œ
        if status not in (cp_model.OPTIMAL, cp_model.FEASIBLE):
            return "UNSAT", None

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë””ë²„ê·¸ ì¶œë ¥ (SAT í•´ì¼ ë•Œë§Œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if DEBUG:
            # 4-1 Wave capacity (ì¸ì„±ê²€ì‚¬ ê·¸ë£¹)
            if HAS_GROUP:
                print("=== Wave capacity debug ===")
                for w in range(MAX_WAVE):
                    a = sum(solver.Value(v)
                            for (cid, room, ww), v in y.items()
                            if room == "ì¸ì„±ê²€ì‚¬ì‹¤A" and ww == w)
                    b = sum(solver.Value(v)
                            for (cid, room, ww), v in y.items()
                            if room == "ì¸ì„±ê²€ì‚¬ì‹¤B" and ww == w)
                    c = sum(solver.Value(v)
                            for (cid, room, ww), v in y.items()
                            if room == "ì¸ì„±ê²€ì‚¬ì‹¤C" and ww == w)
                    print(f"Wave{w:02d}: A={a}, B={b}, C={c}")
                print("=== End wave debug ===")

            # 4-2 í† ë¡ ë©´ì ‘ í™•ì • start ì‹œê°
            print("=== Debug: ì‹¤ì œ í• ë‹¹ëœ í† ë¡ ë©´ì ‘ start times (minutes) ===")
            for cid in CIDS:
                for loc in DEBATE_ROOMS:
                    key = (cid, "í† ë¡ ë©´ì ‘", loc)
                    if key in sel and solver.Value(sel[key]):
                        real_start = solver.Value(start[key]) + ARR_OFF_VAL[cid]
                        print(f"{cid}({loc}): start+ARR_OFF = {real_start}")
            print("=============================================")

            # 4-3 raw í† ë¡ ë©´ì ‘ start ì‹œê°
            print("=== Debug: raw í† ë¡ ë©´ì ‘ start times (minutes) ===")
            for cid in CIDS:
                for loc in DEBATE_ROOMS:
                    key = (cid, "í† ë¡ ë©´ì ‘", loc)
                    if key in start:
                        val = solver.Value(start[key])
                        print(f"{cid}({loc}): start={val} (+ARR_OFF {ARR_OFF_VAL[cid]})")
            print("=============================================")

            # 4-4 precedence gap í™•ì¸ (ìƒ˜í”Œ 5ëª…)
            for cid in CIDS[:5]:
                print(f"--- Debug for {cid} ---")
                # â‘  common rules
                for idx, rule in enumerate(prec.get("common", [])):
                    pred, succ, gap = rule["predecessor"], rule["successor"], rule["min_gap_min"]
                    for loc_p in ACT_SPACE.get(pred, []):
                        if (cid, pred, loc_p) not in sel: continue
                        for loc_s in ACT_SPACE.get(succ, []):
                            if (cid, succ, loc_s) not in sel: continue
                            pe = solver.Value(end[cid, pred, loc_p])
                            ss = solver.Value(start[cid, succ, loc_s])
                            print(f"  [common#{idx}] {pred}->{succ}: end={pe}, start={ss}, gap={gap}")
                # â‘¡ by_code rules
                for code, branches in prec.get("by_code", {}).items():
                    if CODE_MAP[cid] != code: continue
                    branch = "default" if code in default_codes else ("A" if isA[cid] else "B")
                    for idx, rule in enumerate(branches.get(branch, [])):
                        pred, succ, gap = rule["predecessor"], rule["successor"], rule["min_gap_min"]
                        for loc_p in ACT_SPACE.get(pred, []):
                            if (cid, pred, loc_p) not in sel: continue
                            for loc_s in ACT_SPACE.get(succ, []):
                                if (cid, succ, loc_s) not in sel: continue
                                pe = solver.Value(end[cid, pred, loc_p])
                                ss = solver.Value(start[cid, succ, loc_s])
                                print(f"  [{code}-{branch}#{idx}] {pred}->{succ}: end={pe}, start={ss}, gap={gap}")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 5. ê²°ê³¼ ì¶œë ¥ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        rows = []
        for (cid,act,loc),x in sel.items():
            if solver.Value(x)==0: continue
            st = solver.Value(start[cid,act,loc]) + ARR_OFF_VAL[cid]
            ed = solver.Value(end  [cid,act,loc]) + ARR_OFF_VAL[cid]
            base = OPER[CODE_MAP[cid],the_date]["start_dt"]
            rows.append({
                "id":cid,
                "code":CODE_MAP[cid],
                "interview_date":the_date,
                "wave":solver.Value(I_wave[cid]),
                "activity":act,
                "loc":loc,
                "start":base + timedelta(minutes=st),
                "end":base   + timedelta(minutes=ed)
            })

        df_long = pd.DataFrame(rows)
        CORE_ACTS = ALL_ACTS      # pivot ì— ì“¸ ìµœì¢… í™œë™ ë¦¬ìŠ¤íŠ¸
        wide = (
            df_long[df_long["activity"].isin(CORE_ACTS)]
            .pivot_table(
                index=["id","code","interview_date"],
                columns="activity",
                values=["loc","start","end"],
                aggfunc="first"
            )
        )
        for a in ("ì¸ì„±ê²€ì‚¬", "í† ë¡ ë©´ì ‘"):
            for p in ("loc", "start", "end"):
                col = f"{p}_{a}"
                if col not in wide.columns:
                    wide[col] = pd.NA
        wide.columns = [f"{t}_{a}" for t,a in wide.columns]
        wide = wide.reset_index()
        order_cols = (
            ["id","code","interview_date"]
        + list(itertools.chain.from_iterable([[f"loc_{a}",f"start_{a}",f"end_{a}"] for a in CORE_ACTS]))
        )
        wide = wide.reindex(columns=order_cols, fill_value=pd.NA)
        # â”€â”€â”€â”€â”€â”€ wide DF ë§Œë“¤ê³  ë‚œ ë’¤ â”€â”€â”€â”€â”€â”€
        wide["wave"] = wide["id"].map({cid: solver.Value(I_wave[cid]) for cid in CIDS})

        # === ğŸ”½ ì¤‘ë³µ ì—†ëŠ” ì¹´ìš´íŠ¸ ì»¬ëŸ¼ ì¶”ê°€ ===============
        # 1) ì¹´ìš´íŠ¸ ê³„ì‚°
        # 1) wave cnt (ì¸ì„±ê²€ì‚¬ ì—†ìœ¼ë©´ ê±´ë„ˆëœ€)
        if "loc_ì¸ì„±ê²€ì‚¬" in wide.columns and "start_ì¸ì„±ê²€ì‚¬" in wide.columns:
            cnt_wave = (wide.groupby(["interview_date","wave","loc_ì¸ì„±ê²€ì‚¬"])["id"]
                            .transform("size"))
        else:
            cnt_wave = pd.NA

        # 2) debate cnt (í† ë¡ ë©´ì ‘ ì—†ìœ¼ë©´ ê±´ë„ˆëœ€)
        if "start_í† ë¡ ë©´ì ‘" in wide.columns:
            cnt_debate = (wide.groupby(["interview_date","start_í† ë¡ ë©´ì ‘"])["id"]
                            .transform("size"))
        else:
            cnt_debate = pd.NA
        # 2) ì´ë¯¸ ìˆë‹¤ë©´ ì œê±°
        for col in ("wave_in_cnt", "debate_in_cnt"):
            if col in wide.columns:
                wide.drop(columns=[col], inplace=True)

        # 3) ì›í•˜ëŠ” ìœ„ì¹˜ì— ì‚½ì…
        wave_pos = wide.columns.get_loc("wave") + 1   # wave ë°”ë¡œ ë’¤
        wide.insert(wave_pos, "wave_in_cnt", cnt_wave)
        wide["debate_in_cnt"] = cnt_debate            # ë§¨ ëì— ë‘ (í•„ìš”í•˜ë©´ insert ì‚¬ìš©)

        # =================================================

        wave_map = {cid: solver.Value(I_wave[cid]) for cid in CIDS}
        rule_ok = verify_rules(wide, prec_yaml, params, wave_len=WAVE_LEN)
                
        if rule_ok:
            return 'OK', wide
        else:
            print("â— RULE FAIL at", cid)
            print("[RULE_VIOL] order / grid mis-match")
            return 'RULE_VIOL', None



    except Exception as e:
        import traceback, sys
        traceback.print_exc()      # ì „ì²´ ì½œìŠ¤íƒì„ ì½˜ì†”ì— ì¶œë ¥
        raise                      # ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ì˜¬ë ¤ solve() â†’ Streamlit ê¹Œì§€ ì „ë‹¬


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. main â€“  ë‚ ì§œ Ã— íŒŒë¼ë¯¸í„° ë£¨í”„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    # â”€â”€ 0) ì§€ì›ì CSV í•œ ë²ˆë§Œ ì½ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    df_raw = (
        pd.read_csv(CAND_CSV, encoding="utf-8-sig")      # í•„ìš”í•˜ë©´ utf-8-sig, cp949
          .assign(activity=lambda d: d["activity"].str.split(","))
          .explode("activity")
          .assign(activity=lambda d: d["activity"].str.strip())
          .assign(
              interview_date=lambda d:
                  pd.to_datetime(d["interview_date"], errors="coerce")
          )
    )

    # â”€â”€ 1) ë‚ ì§œ ë¦¬ìŠ¤íŠ¸ ìë™ ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    date_list = (
        pd.to_datetime(df_raw["interview_date"].dropna().unique())
    )
    date_list = pd.DatetimeIndex(date_list).sort_values()

    # â”€â”€ 2) ê³µí†µ cfg ëª¨ìŒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    cfg = {
        "df_raw"       : df_raw,                              # â† ì¬í™œìš©
        "cfg_duration" : pd.read_csv("duration_config_test_v4_HF.csv"),
        "cfg_avail"    : pd.read_csv("space_availability_test_v4_HF.csv",
                                     parse_dates=["date"]),
        "cfg_map"      : pd.read_csv("activity_space_map_test_v4_HF.csv"),
        "cfg_oper"     : pd.read_csv("operating_config_test_v4_HF.csv",
                                     parse_dates=["date"]),
    }

    # (3) íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ
    grid = pd.read_csv(GRID_CSV, dtype=str).fillna('')
    if 'scenario_id' not in grid.columns:
        grid.insert(0, 'scenario_id', range(1, len(grid)+1))
    if 'tl_sec' not in grid.columns:
        grid['tl_sec'] = '30'
    for col, default in [("br_offset_A", "2"), ("br_offset_B", "1")]:
        if col not in grid.columns:
            grid[col] = default

    # (4) ì‹¤í–‰
    all_wides, log_rows = [], []
    for d in tqdm(date_list, desc="Dates"):

        ok_found = False
        for _, p in grid.iterrows():
            params = {k: (int(v) if str(v).lstrip('-').isdigit() else v) for k,v in p.items()}
            status, wide = build_model(d, params, cfg)
            if status == "NO_DATA":
                continue      # í•´ë‹¹ ë‚ ì§œì— ì§€ì›ì ì—†ìŒ
            log_rows.append({
                "date"    : d.date(),
                "scenario": p["scenario_id"],
                "status"  : status,
                "success" : 1 if status == "OK" else 0
            })


            if status == "OK":
                all_wides.append(wide)
                ok_found = True
                break   # ë‹¤ìŒ ë‚ ì§œ

        if not ok_found:
            print(f"[WARN] {d.date()} â€“ feasible í•´ ì—†ìŒ")

    # (5) ì €ì¥
    pd.DataFrame(log_rows).to_csv(OUT_LOG, mode='w', index=False,
                              encoding="utf-8-sig")

    if all_wides:
        pd.concat(all_wides).to_csv(OUT_WIDE, index=False, encoding="utf-8-sig")
        print(f"[SAVE] {OUT_WIDE}")
    print("[SAVE] run_log_test_v4.csv")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. ì‹¤í–‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    # (1) íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ csv ì €ì¥ â€“ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì§ì ‘ ì‹¤í–‰í•  ë•Œë§Œ
    _build_param_grid().to_csv(
        "parameter_grid_test_v4.csv",
        index=False, encoding="utf-8-sig")
    print("ğŸ“ parameter_grid_test_v4.csv ìƒì„± ì™„ë£Œ")

    # (2) ê¸°ì¡´ main() í˜¸ì¶œ
    main()
# %%
# interview_opt_test_v4.py
# 0. import & ìƒìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import re, itertools, yaml
from collections import Counter, defaultdict, deque
from pathlib import Path
import pandas as pd
from openpyxl import Workbook
from openpyxl.utils.dataframe import dataframe_to_rows
from openpyxl.styles import PatternFill, numbers

CSV  = Path('schedule_wide_test_v4_HF.csv')     # â† ì…ë ¥
XLSX = Path('schedule_view_test_v4_HF.xlsx')    # â† ê²°ê³¼
YAML = Path('precedence_config_test_v4.yaml')

META        = ['id', 'code', 'interview_date']
GROUP_ACTS  = ('ì¸ì„±ê²€ì‚¬', 'í† ë¡ ë©´ì ‘')
PALETTE     = ['E3F2FD','FFF3E0','E8F5E9','FCE4EC','E1F5FE',
               'F3E5F5','FFFDE7','E0F2F1','EFEBE9','ECEFF1']


#1. ì…ë ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_csv(path: Path) -> pd.DataFrame:
    cols_dt = [c for c in pd.read_csv(path, nrows=0)
               if re.match(r'(start|end)_', c)]
    df = pd.read_csv(path, parse_dates=cols_dt, keep_default_na=False)
    def is_useless(col: str, s: pd.Series) -> bool:
        """
        ì—´ ì „ì²´ê°€ ë¹„ì–´ ìˆê±°ë‚˜(ê°’ì´ í•˜ë‚˜ë„ ì—†ìŒ) ì •ë³´ëŸ‰ì´ 1 ì´í•˜ì´ë©´ Trueë¥¼ ë°˜í™˜.
        loc_/start_/end_ ë¡œ ì‹œì‘í•˜ë”ë¼ë„ ì˜ˆì™¸ ì—†ì´ ê²€ì‚¬í•œë‹¤.
        """
        nunique = s.replace('', pd.NA).nunique(dropna=True)   # '' â†’ NaN ì²˜ë¦¬ í›„ ê³ ìœ ê°’ ê°œìˆ˜
        return nunique == 0 if re.match(r'^(loc|start|end)_', col) else nunique <= 1

    # def is_useless(col: str, s: pd.Series) -> bool:
    #     # (1) ë©”íƒ€(id/code/â€¦) ëŠ” ë†”ë‘”ë‹¤
    #     if not re.match(r'^(loc|start|end)_', col):
    #         return s.replace('', pd.NA).nunique(dropna=True) <= 1
    #     # (2) í™œë™ ì»¬ëŸ¼ì€ ì ˆëŒ€ ì§€ìš°ì§€ ì•ŠëŠ”ë‹¤
    #     return False
    df.drop(columns=[c for c in df if is_useless(c, df[c])], inplace=True)
    return df

#2. í™œë™ ìˆœì„œ(ìœ„ìƒì •ë ¬ â€“ ì‹œê° ê¸°ë°˜) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

PREFIXES = ('loc_', 'start_', 'end_')          # 3-ê´€ì ˆ
IS_ACT = lambda c: any(c.startswith(p) for p in PREFIXES)
JOINT_RANK = {'loc': 0, 'start': 1, 'end': 2}  # loc<start<end
def detect_variants(df: pd.DataFrame,
                    order: dict[tuple[str, str], int]) -> None:

    # â”€â”€ 0) ê¸°ë³¸ ìˆœìœ„ë§Œ ì¶”ë ¤ ë‘ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    base_rank = {act: r for (act, var), r in order.items() if var == ''}
    base_acts = set(base_rank)

    # â”€â”€ â˜… ë³´ì¡° í•¨ìˆ˜ ì •ì˜ â˜… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _is_okay(act: str,
                 times: dict[str, str],
                 rank: dict[str, int]) -> bool:
        """
        í•´ë‹¹ í™œë™(act)ì˜ ì‹œì‘ì‹œê°„ì´ â€˜ì •ìƒ ìˆœì„œâ€™ ì•ˆì— ë“¤ì–´ìˆìœ¼ë©´ True.
        times  : {í™œë™: "HH:MM"}
        rank   : {í™œë™: ì˜ˆìƒìˆœìœ„}
        """
        t_act = pd.to_datetime(times[act])
        # act ì•ë’¤ë¡œ ì™€ì•¼ í•  í™œë™ë“¤ì˜ ì‹œê°„
        for other, t_other in times.items():
            if other == act:
                continue
            t_other = pd.to_datetime(t_other)
            if rank[other] < rank[act] and t_other > t_act:   # ì•ì— ì™€ì•¼ í•  ë†ˆì´ ë’¤ì— ìˆë‹¤
                return False
            if rank[other] > rank[act] and t_other < t_act:   # ë’¤ì— ì™€ì•¼ í•  ë†ˆì´ ì•ì— ìˆë‹¤
                return False
        return True

    # â”€â”€ 1) í–‰ ë‹¨ìœ„ ìŠ¤ìº” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for idx, row in df.iterrows():
        # 1-A) ì‹œì‘ì‹œê°„ ëª¨ìœ¼ê¸° (NA ì•ˆì „)
        times = {act: row[f'start_{act}']
                 for act in base_acts
                 if f'start_{act}' in df.columns
                 and pd.notna(row[f'start_{act}'])
                 and row[f'start_{act}'] != ''}
        if not times:
            continue

        # 2) ì˜ˆìƒÂ·ì‹¤ì œ ìˆœì„œ
        expect = sorted(times, key=lambda a: base_rank[a])
        actual = sorted(times, key=lambda a: pd.to_datetime(times[a]))
        if actual == expect:
            continue            # ì´ìƒ ì—†ìŒ

        # 3) ìˆœì„œë¥¼ ê¹¨ëœ¨ë¦° í™œë™ë§Œ ë³€ì¢…ìœ¼ë¡œ ì´ë™
        for act in actual:
            if _is_okay(act, times, base_rank):
                continue        # ì •ìƒ ìœ„ì¹˜ë©´ skip

            # 3-A) ë¹„ì–´ ìˆëŠ” v2/v3â€¦ ì—´ ì°¾ê¸°
            ver = 2
            while f'start_{act}_v{ver}' in df.columns and df.at[idx, f'start_{act}_v{ver}'] != '':
                ver += 1

            # 3-B) ì´ë™ (loc/start/end ì„¸íŠ¸)
            for joint in ('loc', 'start', 'end'):
                base_col = f'{joint}_{act}'
                var_col  = f'{joint}_{act}_v{ver}'
                if var_col not in df.columns:
                    df[var_col] = ''      # ìƒˆ ì—´ ì¶”ê°€ (ë¹ˆ ê°’)
                df.at[idx, var_col], df.at[idx, base_col] = df.at[idx, base_col], ''

            break   # í•œ í–‰ë‹¹ í•œ í™œë™ë§Œ ë³€ì¢… ì²˜ë¦¬ (ì›ë˜ ë¡œì§ ìœ ì§€)



def split_col(col: str):
    """loc_í† ë¡ ë©´ì ‘_v2 â†’ ('loc','í† ë¡ ë©´ì ‘','_v2')"""
    joint, body = col.split('_', 1)
    m = re.match(r'(.+?)(_v\d+)?$', body)
    return joint, m.group(1), m.group(2) or ''
def build_graph(df: pd.DataFrame):
    from collections import Counter, defaultdict, deque

    nodes  = set()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # â‘  start_* ì¹¼ëŸ¼ â†’ (act, '') ë˜ëŠ” (act, 'v2') â€¦
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for c in df.columns:
        if not c.startswith('start_'):
            continue
        m = re.match(r'start_(.+?)(?:_v(\d+))?$', c)
        if m:
            act, ver = m.groups()
            nodes.add((act, f'v{ver}' if ver else ''))

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # â‘¡ í–‰ ë‹¨ìœ„ ë‹¤ìˆ˜ê²° íˆ¬í‘œ
    #    **ì—¬ê¸°ë„ íŠœí”Œ í‚¤ë§Œ ì‚¬ìš©**
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    votes = defaultdict(Counter)      # {(a,b): Counter({'AB':n,'BA':m})}

    for _, row in df.iterrows():
        times = {}
        for col in df.columns:
            if not col.startswith('start_'):
                continue
            val = row[col]
            if val == '' or pd.isna(val):
                continue

            act = re.match(r'start_(.+?)(?:_v\d+)?$', col).group(1)
            key = (act, '')                          # â˜…â˜… í•­ìƒ íŠœí”Œë¡œ â˜…â˜…
            t   = pd.to_datetime(val)

            # ë™ì¼ í™œë™ì´ ì—¬ëŸ¬ ë²ˆ ë“±ì¥í•˜ë©´ ê°€ì¥ ì´ë¥¸ ì‹œê°„ë§Œ
            times[key] = min(times.get(key, t), t)

        # íˆ¬í‘œ
        for a, b in itertools.permutations(times, 2):
            votes[(a, b)]['AB' if times[a] < times[b] else 'BA'] += 1
            nodes.update([a, b])       # í˜¹ì‹œ ë¹ ì§„ ë…¸ë“œ ìˆì„ê¹Œ ë´ ë³´ê°•

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # â‘¢ ê°„ì„ â€§ìœ„ìƒì •ë ¬ ë¶€ë¶„ì€ ê·¸ëŒ€ë¡œ,
    #    a, b ê°€ ì´ì œ ëª¨ë‘ íŠœí”Œì´ë¯€ë¡œ ì¶”ê°€ ìˆ˜ì • í•„ìš” ì—†ìŒ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


    # ---------------------------------------------
    # 2) ìš°ì„¸ ë°©í–¥ë§Œ ê°„ì„ ìœ¼ë¡œ â€” ê°€ì¤‘ì¹˜ = ë“í‘œì°¨
    # ---------------------------------------------
    G, weight = defaultdict(set), {}
    for (a, b), cnt in votes.items():
        if cnt['AB'] > cnt['BA']:
            G[a].add(b); weight[(a, b)] = cnt['AB'] - cnt['BA']
        elif cnt['BA'] > cnt['AB']:
            G[b].add(a); weight[(b, a)] = cnt['BA'] - cnt['AB']
        # ì™„ì „ ë™ì ì´ë©´ ê°„ì„  ì—†ìŒ

    # ---------------------------------------------
    # 3) Condorcet ìˆœí™˜ ê¹¨ê¸° (ê°€ì¥ ì•½í•œ ê°„ì„ ë¶€í„° ì œê±°)
    # ---------------------------------------------
    while True:
        indeg = defaultdict(int)
        for u in G:
            for v in G[u]:
                indeg[v] += 1
                indeg.setdefault(u, 0)

        # Kahn ìœ„ìƒì •ë ¬ ì‹œë„
        q      = deque([n for n in nodes if indeg.get(n, 0) == 0])
        seen   = set()
        while q:
            u = q.popleft(); seen.add(u)
            for v in G[u]:
                indeg[v] -= 1
                if indeg[v] == 0:
                    q.append(v)

        if len(seen) == len(nodes):          # âœ… DAG ì™„ì„±
            break

        # ìˆœí™˜ì— ë‚¨ì€ ë…¸ë“œ & ê°€ì¥ ì•½í•œ ê°„ì„  ì°¾ê¸°
        cyclic_nodes   = nodes - seen
        cyclic_edges   = [(u, v) for u in cyclic_nodes for v in G[u] if v in cyclic_nodes]
        weakest_edge   = min(cyclic_edges, key=lambda e: weight.get(e, 1))
        G[weakest_edge[0]].remove(weakest_edge[1])
        # ë£¨í”„ê°€ ë¬´í•œíˆ ëŒ ì¼ì€ ì—†ìŠµë‹ˆë‹¤: ê°„ì„ ì€ ìœ í•œ, ë§¤ íšŒ í•˜ë‚˜ì”© ì œê±°

    return nodes, G

def topo_sort(nodes, G):
    indeg = {n: 0 for n in nodes}
    for u in G:
        for v in G[u]:
            indeg[v] += 1
    q = deque([n for n,d in indeg.items() if d == 0])
    order = []
    while q:
        u = q.popleft()
        order.append(u)
        for v in G[u]:
            indeg[v] -= 1
            if indeg[v] == 0:
                q.append(v)
    if len(order) != len(nodes):
        raise ValueError('âš ï¸  cycle detected in activity order!')
    return {n:i for i,n in enumerate(order)}
# ë³€ì¢…ì´ ê¸°ë³¸ë³´ë‹¤ ì–¼ë§ˆë‚˜ â€˜ë‹¹ê²¨/ë¯¸ë£°â€™ì§€
SHIFT = {
    '':      0,     # ê¸°ë³¸
    '_v2': -0.4,    # ì œì¼ ë¨¼ì €
    '_v3': -0.3,
    '_v4': -0.2,
    # ê·¸ ì´í›„ëŠ” 0.01ì”© ë’¤ë¡œ ë¯¸ë£¬ë‹¤ â†’ ì˜ˆ: _v5 = +0.01
}
def order_key_factory(order_map):
    def key(col: str):
        # 0) ë©”íƒ€Â·ì¹´ìš´íŠ¸ ì—´ ë¹ ë¥¸ ë¦¬í„´ ----------------------------
        if col in META or '_' not in col:
            return (-1, 1, 0, col)   # (ê°€ì¤‘ì¹˜ ë§ì¶”ê¸°ìš© dummy)

        joint, base, var = split_col(col)

        if (base, '') not in order_map:     # in_cnt ê°™ì€ ì—´
            return (-1, 1, 0, col)

        base_rank = order_map[(base, '')]

        # â”€â”€ 1) ë³€ì¢… rank ê³„ì‚° ----------------------------------
        if var:                               # ex) _v2
            n = int(var[2:])                  # 2
            act_rank = base_rank - n          # 5-2=3
            variant_flag = 0                  # â˜… ë³€ì¢…ì€ 0 (ìš°ì„ )
        else:
            act_rank = base_rank
            variant_flag = 1                  # ë³¸íŒì€ 1 (ë’¤)

        # â”€â”€ 2) ìµœì¢… key ---------------------------------------
        # (rank, variant_flag, joint_rank, col)
        return (act_rank,
                variant_flag,
                JOINT_RANK[joint],
                col)
    return key


def reorder_columns(df: pd.DataFrame) -> pd.DataFrame:
    nodes, G   = build_graph(df)
    order_map  = topo_sort(nodes, G)
    new_cols   = sorted(df.columns, key=order_key_factory(order_map))
    return df.loc[:, new_cols]

# ------------------------------------------------------------
def prepare_schedule(df_raw: pd.DataFrame) -> pd.DataFrame:
    """
    solver ê°€ ë±‰ì€ wide-DFë¥¼
    (1) ë³€ì¢…(_v2 â€¦) ì •ë¦¬ â†’ (2) ì—´ ì¬ë°°ì—´ â†’ (3) wave ì»¬ëŸ¼/ì •ë ¬ê¹Œì§€
    ë§ˆì¹œ ìµœì¢… í…Œì´ë¸”ë¡œ ë³€í™˜í•œë‹¤.
    """
    df = df_raw.copy()

    # A. ê¸°ë³¸ ì„ í›„ê´€ê³„ â†’ order_map
    nodes, G = build_graph(df)
    order_map = topo_sort(nodes, G)

    # B. ë³€ì¢… ì—´ ì´ë™
    detect_variants(df, order_map)

    # C. wave ë“± ê·¸ë£¹ ë³´ì¡° ì»¬ëŸ¼
    add_group_cols(df)

    # E. ì—´ ìˆœì„œ ì •ë¦¬
    new_cols = sorted(df.columns, key=order_key_factory(order_map))
    df = df.loc[:, META + [c for c in new_cols if c not in META]]

    # F. í–‰ ì •ë ¬ (ì²« start â†’ date â†’ wave â†’ code)
    start_cols = [c for c in df if c.startswith('start_')]
    df['_sort_key'] = (df[start_cols]
                       .apply(pd.to_datetime, errors='coerce')
                       .min(axis=1))
    sort_cols = ['_sort_key', 'interview_date']
    if 'wave' in df.columns:
        sort_cols.append('wave')
    sort_cols.append('code')
    return (df
            .sort_values(sort_cols)
            .drop(columns='_sort_key')
            .reset_index(drop=True))
# ------------------------------------------------------------


#3. ì§‘ë‹¨í™œë™/wave ë³´ì¡° ì¹¼ëŸ¼ â”€â”€â”€â”€â”€fâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def add_group_cols(df: pd.DataFrame) -> bool:
    has_group = any(f'start_{a}' in df for a in GROUP_ACTS)
    if not has_group: return False
    if 'wave' not in df:
        df.insert(df.columns.get_loc('id') + 1, 'wave', pd.NA)
    df['wave_in_cnt'] = (df.groupby(['interview_date', 'wave'])['id']
                           .transform('size'))
    if 'start_í† ë¡ ë©´ì ‘' in df:
        df['debate_in_cnt'] = (df.groupby(['interview_date', 'start_í† ë¡ ë©´ì ‘'])['id']
                                 .transform('size'))
    return True


#4. ì—‘ì…€ë¡œ ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def df_to_excel(df: pd.DataFrame, by_wave: bool, stream=None) -> None:
    wb = Workbook()
    ws = wb.active
    ws.title = 'Schedule'
    df = df.copy()

    # â”€â”€ wave ì»¬ëŸ¼: dtype ìƒê´€ì—†ì´ ìˆ«ìë¡œ ë§ì¶¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if 'wave' in df.columns:
        df['wave'] = (pd.to_numeric(df['wave'], errors='coerce')  # ìˆ«ì ì•„ë‹Œ ê±´ NaN
                        .fillna(-1)                               # NaN â†’ -1
                        .astype(int))                             # int ë¡œ í†µì¼
    # â”€â”€ â¬‡ï¸ ì´ ì¤„ì„ ë°”ë¡œ **ì•„ë˜**ì— ì‚½ì… â¬‡ï¸
    use_wave_color = (by_wave                      # ì™¸ë¶€ì—ì„œ ì¼œì¡Œê³ 
                    and 'wave' in df.columns     # wave ì»¬ëŸ¼ì´ ìˆìœ¼ë©°
                    and (df['wave'] >= 0).any()) # ì‹¤ì œë¡œ â‰¥0 ê°’ì´ í•˜ë‚˜ë¼ë„

    # ë‚˜ë¨¸ì§€ëŠ” ì „ë¶€ None ìœ¼ë¡œ
    df = df.astype(object).where(pd.notna(df), None)
    for r in dataframe_to_rows(df, index=False, header=True):
        ws.append(r)

    act_color = {}
    time_cols = [c for c in df if c.startswith(('start_', 'end_'))]
    wave_col_idx = (df.columns.get_loc('wave') + 1               # 1-based
                    if 'wave' in df.columns else None)
    for j, col in enumerate(df.columns, 1):
        m = re.match(r'(loc|start|end)_(.+?)', col)
        if m:
            act = m.group(2)
            act_color.setdefault(act, PALETTE[len(act_color) % len(PALETTE)])
            hdr = act_color[act]
            ws.cell(1, j).fill = PatternFill('solid', fgColor=hdr)
            for i in range(2, ws.max_row + 1):
                w = ws.cell(i, wave_col_idx).value if wave_col_idx else None
                color = (PALETTE[int(w) % len(PALETTE)]
                        if (use_wave_color and w is not None) else hdr)
                ws.cell(i, j).fill = PatternFill('solid', fgColor=color)
        if col in time_cols:
            for i in range(2, ws.max_row + 1):
                ws.cell(i, j).number_format = 'hh:mm'

    wb.save(stream or XLSX)
    print('âœ… saved:', XLSX)


#5. ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def export_schedule_view() -> None:
    df = load_csv(CSV)

    # (A) ê¸°ë³¸ í™œë™ ì„ í›„ê´€ê³„ êµ¬í•˜ê¸°
    nodes, G  = build_graph(df)
    order_map = topo_sort(nodes, G)

    # (B) ë³€ì¢…(_v2 â€¦) ì´ë™
    detect_variants(df, order_map)

    # (C) ê·¸ë£¹(ì‹œíŠ¸)ìš© ì»¬ëŸ¼ í™•ë³´ â€• wave ê°€ ì—†ìœ¼ë©´ ì—¬ê¸°ì„œ ë§Œë“¤ì–´ ë‘ 
    by_wave = add_group_cols(df)

    # (D) ì¹¼ëŸ¼ ì¬ì •ë ¬
    new_cols = sorted(df.columns, key=order_key_factory(order_map))
    df = df.loc[:, META + [c for c in new_cols if c not in META]]

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # (E) â˜… ì²« ì‹œì‘ì‹œê° â†’ interview_date â†’ wave â†’ code ìˆœ ì •ë ¬ â˜…
    start_cols = [c for c in df.columns if c.startswith('start_')]   # â† ëª¨ë“  start_ ì»¬ëŸ¼

    df['_sort_key'] = (
        df[start_cols]
        .apply(pd.to_datetime, errors='coerce')   # '' â†’ NaT
        .min(axis=1)                              # í–‰ë³„ ê°€ì¥ ë¹ ë¥¸ ì‹œê°
    )

    sort_cols = ['_sort_key', 'interview_date']
    if 'wave' in df.columns:
        sort_cols.append('wave')
    sort_cols.append('code')

    df = (df
        .sort_values(sort_cols)
        .drop(columns='_sort_key')
        .reset_index(drop=True))
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    # (F) ì—‘ì…€ ì¶œë ¥
    df_to_excel(df, by_wave)

#6. ì‹¤í–‰ ìŠ¤ìœ„ì¹˜
if __name__ == '__main__':
    export_schedule_view()
