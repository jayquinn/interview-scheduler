# pages/1_ë©´ì ‘ìš´ì˜ìŠ¤ì¼€ì¤„ë§.py
import streamlit as st
import pandas as pd
import re
import json
from datetime import time, datetime, timedelta
from st_aggrid import (
    AgGrid,
    GridOptionsBuilder,
    GridUpdateMode,
    DataReturnMode,
)
from io import BytesIO
from openpyxl import Workbook
from openpyxl.utils.dataframe import dataframe_to_rows
from openpyxl.styles import PatternFill, Alignment, Font
from openpyxl.utils import get_column_letter
import core
from solver.solver import solve_for_days

st.set_page_config(
    page_title="ë©´ì ‘ìš´ì˜ìŠ¤ì¼€ì¤„ë§",
    layout="wide"
)

# ì‚¬ì´ë“œë°”ì—ì„œ app í˜ì´ì§€ ìˆ¨ê¸°ê¸°
st.markdown("""
<style>
    /* ì‚¬ì´ë“œë°”ì—ì„œ ì²« ë²ˆì§¸ í•­ëª©(app) ìˆ¨ê¸°ê¸° */
    .css-1d391kg .css-1rs6os .css-17eq0hr:first-child {
        display: none !important;
    }
    
    /* ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ app í•­ëª© ìˆ¨ê¸°ê¸° */
    [data-testid="stSidebar"] [data-testid="stSidebarNav"] ul li:first-child {
        display: none !important;
    }
    
    /* ë˜ ë‹¤ë¥¸ ë°©ë²• */
    .css-1rs6os .css-17eq0hr:first-child {
        display: none !important;
    }
    
    /* ì‚¬ì´ë“œë°” ë„¤ë¹„ê²Œì´ì…˜ì—ì„œ ì²« ë²ˆì§¸ ë§í¬ ìˆ¨ê¸°ê¸° */
    .css-1rs6os a[href="/"]:first-child {
        display: none !important;
    }
    
    /* ìµœì‹  Streamlit ë²„ì „ìš© */
    [data-testid="stSidebarNav"] > ul > li:first-child {
        display: none !important;
    }
</style>
""", unsafe_allow_html=True)

# í˜ì´ì§€ ìƒë‹¨ ì•µì»¤ í¬ì¸íŠ¸
st.markdown('<div id="top"></div>', unsafe_allow_html=True)

st.title("ğŸ¯ ë©´ì ‘ìš´ì˜ìŠ¤ì¼€ì¤„ë§")
st.markdown("""
**ì˜¬ì¸ì› ë©´ì ‘ ìŠ¤ì¼€ì¤„ë§ ì†”ë£¨ì…˜**  
ì´ í˜ì´ì§€ì—ì„œ ë©´ì ‘ ìŠ¤ì¼€ì¤„ë§ì— í•„ìš”í•œ ëª¨ë“  ì„¤ì •ê³¼ ì¼ì • ìƒì„±ì„ í•œ ë²ˆì— ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ìš´ì˜ì¼ì • ì¶”ì •ì„ ë¨¼ì € í™•ì¸í•œ í›„, í•„ìš”í•œ ì„¤ì •ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì§„í–‰í•´ë³´ì„¸ìš”.
""")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
def init_session_states():
    # ê¸°ë³¸ í™œë™ í…œí”Œë¦¿
    default_activities = pd.DataFrame({
        "use": [True, True, True],
        "activity": ["í† ë¡ ë©´ì ‘", "ë°œí‘œì¤€ë¹„", "ë°œí‘œë©´ì ‘"],
        "mode": ["batched", "parallel", "individual"],
        "duration_min": [30, 5, 15],
        "room_type": ["í† ë¡ ë©´ì ‘ì‹¤", "ë°œí‘œì¤€ë¹„ì‹¤", "ë°œí‘œë©´ì ‘ì‹¤"],
        "min_cap": [4, 1, 1],
        "max_cap": [6, 2, 1],
    })
    st.session_state.setdefault("activities", default_activities)
    
    # ìŠ¤ë§ˆíŠ¸ ì§ë¬´ ë§¤í•‘ (ëª¨ë“  ê¸°ë³¸ í™œë™ í™œì„±í™” + ì‹¤ì œ ì¸ì›ìˆ˜)
    if "job_acts_map" not in st.session_state:
        act_list = default_activities.query("use == True")["activity"].tolist()
        job_codes = ["JOB01", "JOB02", "JOB03", "JOB04", "JOB05", "JOB06", "JOB07", "JOB08", "JOB09", "JOB10", "JOB11"]
        job_counts = [23, 23, 20, 20, 12, 15, 6, 6, 6, 3, 3]
        
        job_data = {"code": job_codes, "count": job_counts}
        for act in act_list:
            job_data[act] = [True] * len(job_codes)
        st.session_state["job_acts_map"] = pd.DataFrame(job_data)
    
    # ê¸°ë³¸ ì„ í›„í–‰ ì œì•½ (ë°œí‘œì¤€ë¹„ â†’ ë°œí‘œë©´ì ‘)
    default_precedence = pd.DataFrame([
        {"predecessor": "ë°œí‘œì¤€ë¹„", "successor": "ë°œí‘œë©´ì ‘", "gap_min": 0, "adjacent": True}  # ë°œí‘œì¤€ë¹„ â†’ ë°œí‘œë©´ì ‘ ì—°ì†
    ])
    st.session_state.setdefault("precedence", default_precedence)
    
    # ê¸°ë³¸ ìš´ì˜ ì‹œê°„
    st.session_state.setdefault("oper_start_time", time(9, 0))
    st.session_state.setdefault("oper_end_time", time(18, 0))
    
    # ìŠ¤ë§ˆíŠ¸ ë°© í…œí”Œë¦¿ (ê¸°ë³¸ í™œë™ì— ë§ì¶° ìë™ ìƒì„±)
    if "room_template" not in st.session_state:
        room_template = {
            "í† ë¡ ë©´ì ‘ì‹¤": {"count": 2, "cap": 6},
            "ë°œí‘œì¤€ë¹„ì‹¤": {"count": 1, "cap": 2},
            "ë°œí‘œë©´ì ‘ì‹¤": {"count": 2, "cap": 1}
        }
        st.session_state["room_template"] = room_template
    
    # ìŠ¤ë§ˆíŠ¸ ìš´ì˜ ê³µê°„ ê³„íš (room_template ê¸°ë°˜ìœ¼ë¡œ ìë™ ìƒì„±)
    if "room_plan" not in st.session_state:
        room_template = st.session_state.get("room_template", {})
        if room_template:
            final_plan_dict = {}
            for rt, values in room_template.items():
                final_plan_dict[f"{rt}_count"] = values['count']
                final_plan_dict[f"{rt}_cap"] = values['cap']
            st.session_state["room_plan"] = pd.DataFrame([final_plan_dict])
        else:
            st.session_state["room_plan"] = pd.DataFrame()
    
    # ìŠ¤ë§ˆíŠ¸ ìš´ì˜ ì‹œê°„ (ìë™ ìƒì„±)
    if "oper_window" not in st.session_state:
        t_start = st.session_state["oper_start_time"]
        t_end = st.session_state["oper_end_time"]
        oper_window_dict = {
            "start_time": t_start.strftime("%H:%M"),
            "end_time": t_end.strftime("%H:%M")
        }
        st.session_state["oper_window"] = pd.DataFrame([oper_window_dict])
    
    # ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼
    st.session_state.setdefault('final_schedule', None)
    st.session_state.setdefault('last_solve_logs', "")
    st.session_state.setdefault('solver_status', "ë¯¸ì‹¤í–‰")
    st.session_state.setdefault('daily_limit', 0)
    
    # ì§‘ë‹¨ë©´ì ‘ ì„¤ì • ì´ˆê¸°í™” (í† ë¡ ë©´ì ‘ì— ë§ì¶° ì„¤ì •)
    st.session_state.setdefault('group_min_size', 4)
    st.session_state.setdefault('group_max_size', 6)
    st.session_state.setdefault('global_gap_min', 5)
    st.session_state.setdefault('max_stay_hours', 5)  # 5ì‹œê°„ìœ¼ë¡œ ë‹¨ì¶•

init_session_states()

# =============================================================================
# ì„¹ì…˜ 0: ìš´ì˜ì¼ì • ì¶”ì • (ë©”ì¸ ì„¹ì…˜)
# =============================================================================
st.header("ğŸš€ ìš´ì˜ì¼ì • ì¶”ì •")
st.markdown("í˜„ì¬ ì„¤ì •ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì ì˜ ìš´ì˜ì¼ì •ì„ ì¶”ì •í•©ë‹ˆë‹¤.")

# ì²« ë°©ë¬¸ìë¥¼ ìœ„í•œ ì•ˆë‚´
if st.session_state.get('solver_status', 'ë¯¸ì‹¤í–‰') == 'ë¯¸ì‹¤í–‰':
    st.info("ğŸ‘‹ **ì²˜ìŒ ë°©ë¬¸í•˜ì…¨ë‚˜ìš”?** ë°”ë¡œ ì•„ë˜ 'ìš´ì˜ì¼ì •ì¶”ì • ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ë³´ì„¸ìš”! ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ë°ëª¨ë¥¼ ì²´í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    st.markdown("ğŸ’¡ **íŒ:** ì¶”ì • í›„ ì•„ë˜ ì„¹ì…˜ë“¤ì—ì„œ ì„¸ë¶€ ì„¤ì •ì„ ì¡°ì •í•˜ì—¬ ë” ì •í™•í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# Excel ì¶œë ¥ í•¨ìˆ˜ (íƒ€ì„ìŠ¬ë¡¯ ê¸°ëŠ¥ í†µí•©)
def df_to_excel(df: pd.DataFrame, stream=None, group_info: dict = None) -> None:
    wb = Workbook()
    
    # ê¸°ë³¸ íŒ”ë ˆíŠ¸
    PALETTE = ['E3F2FD', 'FFF3E0', 'E8F5E9', 'FCE4EC', 'E1F5FE', 'F3E5F5', 'FFFDE7', 'E0F2F1', 'EFEBE9', 'ECEFF1']
    
    # í™œë™ë³„ ëª¨ë“œ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (batched í™œë™ í™•ì¸ìš©)
    activities_df = st.session_state.get("activities", pd.DataFrame())
    activity_modes = {}
    if not activities_df.empty:
        for _, act in activities_df.iterrows():
            if act["use"]:
                activity_modes[act["activity"]] = act.get("mode", "individual")
    
    # ===== 1) ê¸°ë³¸ ìŠ¤ì¼€ì¤„ ì‹œíŠ¸ =====
    ws1 = wb.active
    ws1.title = 'Schedule'
    df_copy = df.copy()
    
    # ì²´ë¥˜ì‹œê°„ ê³„ì‚° í•¨ìˆ˜
    def calculate_stay_time(row):
        """ê° ì§€ì›ìì˜ ì²´ë¥˜ì‹œê°„ì„ ê³„ì‚° (ë¶„ ë‹¨ìœ„)"""
        start_times = []
        end_times = []
        
        for col in row.index:
            if col.startswith('start_') and pd.notna(row[col]):
                try:
                    time_val = pd.to_datetime(row[col])
                    start_times.append(time_val)
                except:
                    pass
            elif col.startswith('end_') and pd.notna(row[col]):
                try:
                    time_val = pd.to_datetime(row[col])
                    end_times.append(time_val)
                except:
                    pass
        
        if start_times and end_times:
            first_start = min(start_times)
            last_end = max(end_times)
            stay_minutes = (last_end - first_start).total_seconds() / 60
            return int(stay_minutes)
        return 0
    
    # ì²´ë¥˜ì‹œê°„ ì¹¼ëŸ¼ ì¶”ê°€
    df_copy['ì²´ë¥˜ì‹œê°„(ë¶„)'] = df_copy.apply(calculate_stay_time, axis=1)
    df_copy['ì²´ë¥˜ì‹œê°„(ì‹œ:ë¶„)'] = df_copy['ì²´ë¥˜ì‹œê°„(ë¶„)'].apply(
        lambda x: f"{int(x//60)}:{int(x%60):02d}" if x > 0 else ""
    )
    
    # ê·¸ë£¹ ì •ë³´ ì¶”ê°€ (group_infoê°€ ì œê³µëœ ê²½ìš°)
    if group_info:
        df_copy['ê·¸ë£¹ë²ˆí˜¸'] = df_copy['id'].map(group_info.get('member_to_group', {}))
        df_copy['ê·¸ë£¹í¬ê¸°'] = df_copy['ê·¸ë£¹ë²ˆí˜¸'].map(group_info.get('group_sizes', {}))
    else:
        df_copy['ê·¸ë£¹ë²ˆí˜¸'] = ''
        df_copy['ê·¸ë£¹í¬ê¸°'] = ''
    
    # ì¹¼ëŸ¼ ìˆœì„œ ì¬ì •ë ¬ - ê¸°ë³¸ ì •ë³´ ë‹¤ìŒì— ì²´ë¥˜ì‹œê°„ê³¼ ê·¸ë£¹ ì •ë³´ë¥¼ ë°°ì¹˜
    base_cols = ['id', 'interview_date', 'code']
    extra_cols = ['ê·¸ë£¹ë²ˆí˜¸', 'ê·¸ë£¹í¬ê¸°', 'ì²´ë¥˜ì‹œê°„(ë¶„)', 'ì²´ë¥˜ì‹œê°„(ì‹œ:ë¶„)']
    activity_cols = [col for col in df_copy.columns if col not in base_cols + extra_cols]
    
    # ìƒˆë¡œìš´ ì¹¼ëŸ¼ ìˆœì„œ: ê¸°ë³¸ ì •ë³´ â†’ ê·¸ë£¹ ì •ë³´ â†’ ì²´ë¥˜ì‹œê°„ â†’ í™œë™ ì •ë³´
    new_column_order = base_cols + [col for col in ['ê·¸ë£¹ë²ˆí˜¸', 'ê·¸ë£¹í¬ê¸°'] if col in df_copy.columns] + \
                      [col for col in ['ì²´ë¥˜ì‹œê°„(ë¶„)', 'ì²´ë¥˜ì‹œê°„(ì‹œ:ë¶„)'] if col in df_copy.columns] + \
                      activity_cols
    df_copy = df_copy[new_column_order]
    
    # ë‚ ì§œë³„ë¡œ ìƒ‰ìƒ ì§€ì •
    unique_dates = df_copy['interview_date'].dt.date.unique()
    date_color_map = {date: PALETTE[i % len(PALETTE)] for i, date in enumerate(unique_dates)}
    
    df_copy = df_copy.astype(object).where(pd.notna(df_copy), None)
    for r in dataframe_to_rows(df_copy, index=False, header=True):
        ws1.append(r)
    
    header_fill = PatternFill('solid', fgColor='D9D9D9')
    special_header_fill = PatternFill('solid', fgColor='B8B8B8')  # ì²´ë¥˜ì‹œê°„/ê·¸ë£¹ ì •ë³´ëŠ” ì§„í•œ íšŒìƒ‰
    
    for cell in ws1[1]:
        if cell.value in ['ì²´ë¥˜ì‹œê°„(ë¶„)', 'ì²´ë¥˜ì‹œê°„(ì‹œ:ë¶„)', 'ê·¸ë£¹ë²ˆí˜¸', 'ê·¸ë£¹í¬ê¸°']:
            cell.fill = special_header_fill
            cell.font = Font(bold=True)
        else:
            cell.fill = header_fill
    
    # ë‚ ì§œ ì—´ ì°¾ê¸°
    date_col_idx = -1
    for j, col_name in enumerate(df_copy.columns, 1):
        if col_name == 'interview_date':
            date_col_idx = j
            break
    
    for i, row in enumerate(ws1.iter_rows(min_row=2, max_row=ws1.max_row), 2):
        if date_col_idx != -1:
            date_val = row[date_col_idx - 1].value
            if date_val and hasattr(date_val, 'date'):
                row_color = date_color_map.get(date_val.date())
                if row_color:
                    row_fill = PatternFill('solid', fgColor=row_color)
                    for cell in row:
                        cell.fill = row_fill
    
    # ì‹œê°„ í˜•ì‹ ì§€ì •
    for j, col_name in enumerate(df_copy.columns, 1):
        if 'start' in col_name or 'end' in col_name:
            for i in range(2, ws1.max_row + 1):
                ws1.cell(i, j).number_format = 'hh:mm'
    
    # ===== 2) íƒ€ì„ìŠ¬ë¡¯ ì‹œíŠ¸ë“¤ ì¶”ê°€ =====
    def _color_picker():
        """í™œë™ëª… â†’ ê³ ì • ìƒ‰ìƒ ë§¤í•‘"""
        mapping = {}
        def _pick(act: str) -> str:
            if act not in mapping:
                mapping[act] = PALETTE[len(mapping) % len(PALETTE)]
            return mapping[act]
        return _pick
    
    def _build_timeslot_sheet(ws, df_day: pd.DataFrame, pick_color, group_info_param=None, activity_modes_param=None):
        """ë‹¨ì¼ ë‚ ì§œ ìŠ¤ì¼€ì¤„ â†’ íƒ€ì„ìŠ¬ë¡¯ ë§¤íŠ¸ë¦­ìŠ¤"""
        loc_cols = [c for c in df_day.columns if c.startswith("loc_")]
        start_cols = [c for c in df_day.columns if c.startswith("start_")]
        end_cols = [c for c in df_day.columns if c.startswith("end_")]
        
        # group_info íŒŒë¼ë¯¸í„° ì‚¬ìš©
        group_info = group_info_param
        
        # í™œë™ë³„ ëª¨ë“œ ì •ë³´ëŠ” íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬ë°›ìŒ
        activity_modes = activity_modes_param if activity_modes_param is not None else {}
        
        # ê³µê°„ ëª©ë¡
        locs = sorted(set(df_day[loc_cols].stack().dropna().unique()))
        if not locs:
            return
        
        # ì‹œê°„ ë²”ìœ„ ê³„ì‚°
        t_min = t_max = None
        for col in start_cols + end_cols:
            ts = pd.to_datetime(df_day[col], errors="coerce").dropna()
            if ts.empty:
                continue
            t_min = ts.min() if t_min is None else min(t_min, ts.min())
            t_max = ts.max() if t_max is None else max(t_max, ts.max())
        if t_min is None or t_max is None:
            return
        
        TIME_STEP_MIN = 5
        t_min = t_min.floor(f"{TIME_STEP_MIN}min")
        t_max = (t_max.ceil(f"{TIME_STEP_MIN}min") + timedelta(minutes=TIME_STEP_MIN))
        times = pd.date_range(t_min, t_max, freq=f"{TIME_STEP_MIN}min")
        
        # í—¤ë” ì‘ì„±
        ws.cell(1, 1, "Time")
        for j, loc in enumerate(locs, start=2):
            cell = ws.cell(1, j, loc)
            cell.alignment = Alignment(horizontal="center")
        
        for i, t in enumerate(times, start=2):
            ws.cell(i, 1, t.strftime("%H:%M"))
            ws.cell(i, 1).alignment = Alignment(horizontal="right")
        
        # ì…€ ì±„ìš°ê¸°
        for _, row in df_day.iterrows():
            for st_col in start_cols:
                suffix = st_col[len("start_"):]
                end_col = f"end_{suffix}"
                loc_col = f"loc_{suffix}"
                if end_col not in df_day.columns or loc_col not in df_day.columns:
                    continue
                st = row[st_col]
                ed = row[end_col]
                loc = row[loc_col]
                if pd.isna(st) or pd.isna(ed) or loc in ("", None):
                    continue
                st_dt = pd.to_datetime(st, errors="coerce")
                ed_dt = pd.to_datetime(ed, errors="coerce")
                if pd.isna(st_dt) or pd.isna(ed_dt):
                    continue
                base_act = suffix
                color = pick_color(base_act)
                if loc not in locs:
                    continue
                col_idx = locs.index(loc) + 2
                
                # í‘œì‹œí•  ë‚´ìš© ê²°ì •: batched í™œë™ì´ë©´ ê·¸ë£¹ ë²ˆí˜¸, ì•„ë‹ˆë©´ ID
                display_value = str(row["id"])
                if group_info and base_act in activity_modes and activity_modes[base_act] == "batched":
                    # batched í™œë™ì¸ ê²½ìš° ê·¸ë£¹ ë²ˆí˜¸ í‘œì‹œ
                    member_id = row["id"]
                    if member_id in group_info.get('member_to_group', {}):
                        group_num = group_info['member_to_group'][member_id]
                        display_value = f"G{group_num}"
                
                cur = st_dt.floor(f"{TIME_STEP_MIN}min")
                while cur < ed_dt:
                    if cur < t_min or cur > t_max:
                        cur += timedelta(minutes=TIME_STEP_MIN)
                        continue
                    row_idx = times.get_loc(cur) + 2
                    cell = ws.cell(row_idx, col_idx)
                    if cell.value in (None, ""):
                        cell.value = display_value
                        cell.fill = PatternFill("solid", fgColor=color)
                    else:
                        existing = str(cell.value)
                        if display_value not in existing.split("\n"):
                            cell.value = existing + "\n" + display_value
                    cell.alignment = Alignment(horizontal="center", vertical="center", wrap_text=True)
                    cur += timedelta(minutes=TIME_STEP_MIN)
        
        # ì—´ ë„ˆë¹„Â·í–‰ ë†’ì´ ìë™ ì¡°ì •
        for j, loc in enumerate(locs, start=2):
            max_len = len(str(loc))
            for i in range(2, ws.max_row + 1):
                val = ws.cell(i, j).value
                if val is None:
                    continue
                for part in str(val).split("\n"):
                    max_len = max(max_len, len(part))
            col_letter = get_column_letter(j)
            ws.column_dimensions[col_letter].width = max(10, min(1.2 * max_len, 30))
        
        default_ht = 15
        for i in range(2, ws.max_row + 1):
            max_lines = 1
            for j in range(2, ws.max_column + 1):
                val = ws.cell(i, j).value
                if val is None:
                    continue
                lines = str(val).count("\n") + 1
                max_lines = max(max_lines, lines)
            ws.row_dimensions[i].height = default_ht * max_lines
    
    # ë‚ ì§œë³„ íƒ€ì„ìŠ¬ë¡¯ ì‹œíŠ¸ ìƒì„±
    pick_color = _color_picker()
    for the_date, df_day in df.groupby("interview_date"):
        ws_name = f"TS_{pd.to_datetime(the_date).strftime('%m%d')}"
        ws_ts = wb.create_sheet(ws_name)
        _build_timeslot_sheet(ws_ts, df_day.copy(), pick_color, group_info, activity_modes)
    
    wb.save(stream or "interview_schedule.xlsx")

def reset_run_state():
    st.session_state['final_schedule'] = None
    st.session_state['last_solve_logs'] = ""
    st.session_state['solver_status'] = "ë¯¸ì‹¤í–‰"
    st.session_state['daily_limit'] = 0

# ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì„¤ì • (í•˜ë“œì½”ë”©)
params = {
    "min_gap_min": st.session_state.get('global_gap_min', 5),
    "time_limit_sec": 120,
    "max_stay_hours": st.session_state.get('max_stay_hours', 8)
}

# batched ëª¨ë“œê°€ ìˆëŠ”ì§€ í™•ì¸
acts_df = st.session_state.get("activities", pd.DataFrame())
has_batched = any(acts_df["mode"] == "batched") if not acts_df.empty and "mode" in acts_df.columns else False

# ì§‘ë‹¨ë©´ì ‘ ì„¤ì •ì´ ìˆìœ¼ë©´ paramsì— ì¶”ê°€
if has_batched:
    params["group_min_size"] = st.session_state.get('group_min_size', 4)
    params["group_max_size"] = st.session_state.get('group_max_size', 6)

# ë°ì´í„° ê²€ì¦
job_df = st.session_state.get("job_acts_map", pd.DataFrame())
room_plan = st.session_state.get("room_plan", pd.DataFrame())
oper_df = st.session_state.get("oper_window", pd.DataFrame())
prec_df = st.session_state.get("precedence", pd.DataFrame())

# ê²€ì¦ ê²°ê³¼ í‘œì‹œ
validation_errors = []

if acts_df.empty or not (acts_df["use"] == True).any():
    validation_errors.append("í™œë™ì„ í•˜ë‚˜ ì´ìƒ ì •ì˜í•˜ê³  'use=True'ë¡œ ì„¤ì •í•´ì£¼ì„¸ìš”.")

if job_df.empty or (job_df["count"].sum() == 0):
    validation_errors.append("ì§ë¬´ ì½”ë“œë¥¼ ì¶”ê°€í•˜ê³  ì¸ì›ìˆ˜ë¥¼ 1ëª… ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")

if job_df["code"].duplicated().any():
    validation_errors.append("ì¤‘ë³µëœ ì§ë¬´ ì½”ë“œê°€ ìˆìŠµë‹ˆë‹¤.")

# batched ëª¨ë“œê°€ ìˆìœ¼ë©´ ê·¸ë£¹ í¬ê¸° ì¼ê´€ì„± ê²€ì¦
if has_batched:
    batched_activities = acts_df[acts_df["mode"] == "batched"]
    min_caps = batched_activities["min_cap"].unique()
    max_caps = batched_activities["max_cap"].unique()
    
    if len(min_caps) > 1 or len(max_caps) > 1:
        validation_errors.append("ëª¨ë“  batched í™œë™ì˜ ê·¸ë£¹ í¬ê¸°(min_cap, max_cap)ëŠ” ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤.")
    
    # ë°© ìš©ëŸ‰ vs ê·¸ë£¹ í¬ê¸° ê²€ì¦
    for _, act in batched_activities.iterrows():
        room_type = act["room_type"]
        max_cap = act["max_cap"]
        room_cap_col = f"{room_type}_cap"
        
        if room_cap_col in room_plan.columns:
            room_cap = room_plan[room_cap_col].iloc[0] if not room_plan.empty else 0
            if room_cap < max_cap:
                validation_errors.append(f"{room_type}ì˜ ìš©ëŸ‰({room_cap})ì´ {act['activity']}ì˜ ìµœëŒ€ ê·¸ë£¹ í¬ê¸°({max_cap})ë³´ë‹¤ ì‘ìŠµë‹ˆë‹¤.")

# room_plan ê²€ì¦: room_templateì´ ìˆìœ¼ë©´ ìœ íš¨í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼
room_template = st.session_state.get("room_template", {})
if room_plan.empty and not room_template:
    validation_errors.append("ìš´ì˜ ê³µê°„ì„ ì„¤ì •í•´ì£¼ì„¸ìš”.")

if validation_errors:
    st.error("ë‹¤ìŒ í•­ëª©ì„ ì„¤ì •í•´ì£¼ì„¸ìš”:")
    for error in validation_errors:
        st.error(f"â€¢ {error}")
    st.info("â¬‡ï¸ ì•„ë˜ ì„¹ì…˜ë“¤ì—ì„œ í•„ìš”í•œ ì„¤ì •ì„ ì™„ë£Œí•œ í›„ ë‹¤ì‹œ ì¶”ì •í•´ë³´ì„¸ìš”.")
else:
    st.success("âœ… ì…ë ¥ ë°ì´í„° ê²€ì¦ í†µê³¼ â€“ ìš´ì˜ì¼ì •ì¶”ì •ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")

# ìš´ì˜ì¼ì • ì¶”ì • ì‹¤í–‰
if st.button("ğŸš€ ìš´ì˜ì¼ì •ì¶”ì • ì‹œì‘", type="primary", use_container_width=True, on_click=reset_run_state):
    if not validation_errors:
        with st.spinner("ìµœì ì˜ ìš´ì˜ ì¼ì •ì„ ê³„ì‚° ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                cfg = core.build_config(st.session_state)
                
                # solve_for_daysê°€ ë‚´ë¶€ì ìœ¼ë¡œ batched ëª¨ë“œë¥¼ ì²˜ë¦¬í•˜ë„ë¡ í•¨
                # ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™” (ë¬¸ì œ ì¶”ì ì„ ìœ„í•´)
                status, final_wide, logs, limit = solve_for_days(cfg, params, debug=True)
                
                st.session_state['last_solve_logs'] = logs
                st.session_state['solver_status'] = status
                st.session_state['daily_limit'] = limit
                
                if status == "OK" and final_wide is not None and not final_wide.empty:
                    st.session_state['final_schedule'] = final_wide
                    st.balloons()
                else:
                    st.session_state['final_schedule'] = None
            except Exception as e:
                st.error(f"ê³„ì‚° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                st.session_state['solver_status'] = "ERROR"

# ê²°ê³¼ í‘œì‹œ
st.markdown("---")
status = st.session_state.get('solver_status', 'ë¯¸ì‹¤í–‰')
daily_limit = st.session_state.get('daily_limit', 0)

col1, col2 = st.columns(2)
with col1:
    st.info(f"Solver Status: `{status}`")
with col2:
    if daily_limit > 0:
        st.info(f"ê³„ì‚°ëœ ì¼ì¼ ìµœëŒ€ ì²˜ë¦¬ ì¸ì›: **{daily_limit}ëª…**")

# ë””ë²„ê·¸ ì •ë³´ ìƒì„± í•¨ìˆ˜
def generate_debug_info():
    """ë¬¸ì œ ì§„ë‹¨ì„ ìœ„í•œ ì¢…í•© ë””ë²„ê·¸ ì •ë³´ ìƒì„±"""
    import json
    from datetime import datetime
    
    debug_info = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "solver_status": st.session_state.get('solver_status', 'ë¯¸ì‹¤í–‰'),
        "daily_limit": st.session_state.get('daily_limit', 0),
        "total_candidates": 0,
        "settings": {}
    }
    
    # 1. í™œë™ ì •ì˜
    activities_df = st.session_state.get("activities", pd.DataFrame())
    if not activities_df.empty:
        debug_info["settings"]["activities"] = activities_df.to_dict('records')
        
        # í™œë™ë³„ í†µê³„
        active_activities = activities_df[activities_df["use"] == True]
        debug_info["settings"]["active_activities_count"] = len(active_activities)
        debug_info["settings"]["activity_modes"] = active_activities["mode"].value_counts().to_dict()
    
    # 2. ì§ë¬´ë³„ ì¸ì›ìˆ˜ì™€ í™œë™
    job_acts_df = st.session_state.get("job_acts_map", pd.DataFrame())
    if not job_acts_df.empty:
        debug_info["settings"]["job_activities"] = job_acts_df.to_dict('records')
        debug_info["total_candidates"] = int(job_acts_df["count"].sum())
        debug_info["settings"]["job_count"] = len(job_acts_df)
    
    # 3. ì„ í›„í–‰ ì œì•½
    precedence_df = st.session_state.get("precedence", pd.DataFrame())
    if not precedence_df.empty:
        debug_info["settings"]["precedence"] = precedence_df.to_dict('records')
    else:
        debug_info["settings"]["precedence"] = []
    
    # 4. ë°© ì„¤ì •
    room_template = st.session_state.get("room_template", {})
    room_plan_df = st.session_state.get("room_plan", pd.DataFrame())
    
    debug_info["settings"]["room_template"] = room_template
    if not room_plan_df.empty:
        debug_info["settings"]["room_plan"] = room_plan_df.to_dict('records')
    
    # ë°©ë³„ ì´ ìš©ëŸ‰ ê³„ì‚°
    total_room_capacity = {}
    for room_type, values in room_template.items():
        total_room_capacity[room_type] = {
            "count": values.get("count", 0),
            "capacity_per_room": values.get("cap", 0),
            "total_capacity": values.get("count", 0) * values.get("cap", 0)
        }
    debug_info["settings"]["room_capacity_summary"] = total_room_capacity
    
    # 5. ìš´ì˜ ì‹œê°„
    oper_window_df = st.session_state.get("oper_window", pd.DataFrame())
    if not oper_window_df.empty:
        debug_info["settings"]["operating_hours"] = oper_window_df.to_dict('records')[0]
    else:
        debug_info["settings"]["operating_hours"] = {
            "start_time": st.session_state.get("oper_start_time", time(9, 0)).strftime("%H:%M"),
            "end_time": st.session_state.get("oper_end_time", time(18, 0)).strftime("%H:%M")
        }
    
    # ìš´ì˜ ì‹œê°„ ê³„ì‚°
    start_time = st.session_state.get("oper_start_time", time(9, 0))
    end_time = st.session_state.get("oper_end_time", time(18, 0))
    operating_minutes = (end_time.hour * 60 + end_time.minute) - (start_time.hour * 60 + start_time.minute)
    debug_info["settings"]["operating_minutes_per_day"] = operating_minutes
    
    # 6. ì§‘ë‹¨ë©´ì ‘ ì„¤ì • (batched ëª¨ë“œê°€ ìˆì„ ë•Œë§Œ)
    if "batched" in debug_info["settings"].get("activity_modes", {}):
        debug_info["settings"]["batched_settings"] = {
            "group_min_size": st.session_state.get('group_min_size', 4),
            "group_max_size": st.session_state.get('group_max_size', 6),
            "global_gap_min": st.session_state.get('global_gap_min', 5),
            "max_stay_hours": st.session_state.get('max_stay_hours', 8)
        }
    
    # 7. ì˜ˆìƒ ì²˜ë¦¬ëŸ‰ ë¶„ì„
    if activities_df.empty or room_template == {}:
        debug_info["analysis"] = {"error": "í™œë™ ë˜ëŠ” ë°© ì„¤ì •ì´ ì—†ìŒ"}
    else:
        analysis = {}
        active_activities = activities_df[activities_df["use"] == True]
        
        # ê° í™œë™ë³„ ë³‘ëª© ë¶„ì„
        for _, activity in active_activities.iterrows():
            room_type = activity["room_type"]
            if room_type in room_template:
                room_count = room_template[room_type]["count"]
                room_cap = room_template[room_type]["cap"]
                duration = activity["duration_min"]
                
                # í•˜ë£¨ ë™ì•ˆ í•œ ë°©ì—ì„œ ì²˜ë¦¬ ê°€ëŠ¥í•œ ìµœëŒ€ ì¸ì›
                slots_per_day = operating_minutes // duration
                max_per_room = slots_per_day * room_cap
                max_total = max_per_room * room_count
                
                analysis[activity["activity"]] = {
                    "duration_min": duration,
                    "room_type": room_type,
                    "room_count": room_count,
                    "room_capacity": room_cap,
                    "max_candidates_per_day": max_total,
                    "slots_per_day_per_room": slots_per_day
                }
        
        debug_info["analysis"] = analysis
        
        # ì „ì²´ ë³‘ëª© í™œë™ ì°¾ê¸°
        if analysis:
            bottleneck = min(analysis.items(), key=lambda x: x[1]["max_candidates_per_day"])
            debug_info["analysis"]["bottleneck_activity"] = bottleneck[0]
            debug_info["analysis"]["bottleneck_capacity"] = bottleneck[1]["max_candidates_per_day"]
    
    # 8. ë§ˆì§€ë§‰ ì‹¤í–‰ ë¡œê·¸ (ì²˜ìŒ 100ì¤„ë§Œ)
    last_logs = st.session_state.get('last_solve_logs', "")
    if last_logs:
        log_lines = last_logs.split('\n')[:100]
        debug_info["last_logs_preview"] = '\n'.join(log_lines)
        debug_info["total_log_lines"] = len(last_logs.split('\n'))
    
    return debug_info

# ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ (NO_SOLUTIONì´ê±°ë‚˜ ì‚¬ìš©ìê°€ ì›í•  ë•Œ)
# NO_SOLUTIONì´ë‚˜ ERRORì¼ ë•ŒëŠ” ë¬´ì¡°ê±´ í‘œì‹œ, ê·¸ ì™¸ì—ëŠ” ì²´í¬ë°•ìŠ¤ë¡œ ì„ íƒ
show_debug = False
if status in ["NO_SOLUTION", "ERROR"]:
    show_debug = True
else:
    show_debug = st.checkbox("ğŸ” ë””ë²„ê·¸ ì •ë³´ ë³´ê¸°", value=False)

if show_debug:
    if status == "ERROR":
        st.error("âŒ ìŠ¤ì¼€ì¤„ë§ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")
    elif status == "NO_SOLUTION":
        st.warning("âš ï¸ ë¬¸ì œ ì§„ë‹¨ì„ ìœ„í•œ ë””ë²„ê·¸ ì •ë³´")
    
    debug_info = generate_debug_info()
    
    # ì£¼ìš” ì •ë³´ ìš”ì•½
    st.markdown("### ğŸ“Š ì£¼ìš” ì •ë³´ ìš”ì•½")
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ì´ ì§€ì›ì", f"{debug_info['total_candidates']}ëª…")
    with col2:
        st.metric("í™œì„± í™œë™", f"{debug_info['settings'].get('active_activities_count', 0)}ê°œ")
    with col3:
        st.metric("ìš´ì˜ ì‹œê°„", f"{debug_info['settings'].get('operating_minutes_per_day', 0)}ë¶„")
    with col4:
        st.metric("ì„ í›„í–‰ ì œì•½", f"{len(debug_info['settings'].get('precedence', []))}ê°œ")
    
    # ë³‘ëª© ë¶„ì„
    if "bottleneck_activity" in debug_info.get("analysis", {}):
        st.error(f"ğŸš¨ ë³‘ëª© í™œë™: **{debug_info['analysis']['bottleneck_activity']}** "
                f"(ì¼ì¼ ìµœëŒ€ {debug_info['analysis']['bottleneck_capacity']}ëª…)")
    
    # êµ¬ì¡°ì  ë¬¸ì œ í™•ì¸
    # Batched/Parallel â†’ Individual adjacent ì œì•½ ê²€ì‚¬
    activities_df = st.session_state.get("activities", pd.DataFrame())
    precedence_df = st.session_state.get("precedence", pd.DataFrame())
    
    if not activities_df.empty and not precedence_df.empty and 'mode' in activities_df.columns:
        structural_problems = []
        
        for _, rule in precedence_df.iterrows():
            if not rule.get('adjacent', False):
                continue
                
            pred = rule['predecessor']
            succ = rule['successor']
            
            pred_act = activities_df[activities_df['activity'] == pred]
            succ_act = activities_df[activities_df['activity'] == succ]
            
            if pred_act.empty or succ_act.empty:
                continue
                
            pred_mode = pred_act.iloc[0].get('mode', 'individual')
            succ_mode = succ_act.iloc[0].get('mode', 'individual')
            pred_cap = int(pred_act.iloc[0].get('max_cap', 1))
            succ_cap = int(succ_act.iloc[0].get('max_cap', 1))
            
            # Batched â†’ Individual/Parallel adjacent ë¬¸ì œ
            if pred_mode == 'batched' and succ_mode in ['individual', 'parallel']:
                # ê·¸ë£¹ í¬ê¸° í™•ì¸
                group_size = debug_info['settings'].get('batched_settings', {}).get('group_max_size', 6)
                succ_room_type = succ_act.iloc[0]['room_type']
                succ_room_count = debug_info['settings']['room_template'].get(succ_room_type, {}).get('count', 1)
                
                if group_size > succ_room_count * succ_cap:
                    structural_problems.append({
                        'type': 'batched_to_individual_adjacent',
                        'pred': pred,
                        'succ': succ,
                        'group_size': group_size,
                        'succ_capacity': succ_room_count * succ_cap,
                        'message': f"{pred}(ê·¸ë£¹ {group_size}ëª…) â†’ {succ}(ë™ì‹œ {succ_room_count * succ_cap}ëª…) adjacent ë¶ˆê°€ëŠ¥"
                    })
            
            # Parallel â†’ Individual adjacent ë¬¸ì œ
            elif pred_mode == 'parallel' and succ_mode == 'individual':
                succ_room_type = succ_act.iloc[0]['room_type']
                succ_room_count = debug_info['settings']['room_template'].get(succ_room_type, {}).get('count', 1)
                
                if pred_cap > succ_room_count:
                    structural_problems.append({
                        'type': 'parallel_to_individual_adjacent',
                        'pred': pred,
                        'succ': succ,
                        'pred_capacity': pred_cap,
                        'succ_capacity': succ_room_count,
                        'message': f"{pred}(ë™ì‹œ {pred_cap}ëª…) â†’ {succ}(ë™ì‹œ {succ_room_count}ëª…) adjacent ë¶ˆê°€ëŠ¥"
                    })
        
        if structural_problems:
            st.error("### ğŸš« êµ¬ì¡°ì  ë¬¸ì œ ë°œê²¬")
            for problem in structural_problems:
                st.error(f"**{problem['message']}**")
                
                if problem['type'] == 'batched_to_individual_adjacent':
                    st.markdown(f"""
                    **ë¬¸ì œ ìƒì„¸:**
                    - {problem['pred']}ì€ **{problem['group_size']}ëª…ì´ í•œ ê·¸ë£¹**ìœ¼ë¡œ í™œë™
                    - {problem['succ']}ì€ **ë™ì‹œì— {problem['succ_capacity']}ëª…ë§Œ** ìˆ˜ìš© ê°€ëŠ¥
                    - Adjacent ì œì•½ìœ¼ë¡œ ì¸í•´ {problem['pred']} ì§í›„ {problem['succ']}ë¥¼ í•´ì•¼ í•¨
                    - **{problem['group_size'] - problem['succ_capacity']}ëª…ì´ ëŒ€ê¸°**í•´ì•¼ í•˜ë¯€ë¡œ adjacent ì œì•½ ìœ„ë°˜
                    
                    **í•´ê²° ë°©ë²•:**
                    1. **Adjacent ì œì•½ ì œê±°**: {problem['pred']} â†’ {problem['succ']}ì˜ 'adjacent'ë¥¼ falseë¡œ ë³€ê²½
                    2. **ë°© ì¦ì„¤**: {problem['succ']} ë°©ì„ {problem['group_size'] // int(succ_cap) + (1 if problem['group_size'] % int(succ_cap) else 0)}ê°œë¡œ ì¦ê°€
                    3. **ê·¸ë£¹ í¬ê¸° ì¶•ì†Œ**: ì§‘ë‹¨ë©´ì ‘ ê·¸ë£¹ì„ {problem['succ_capacity']}ëª… ì´í•˜ë¡œ ì„¤ì •
                    """)
                elif problem['type'] == 'parallel_to_individual_adjacent':
                    st.markdown(f"""
                    **ë¬¸ì œ ìƒì„¸:**
                    - {problem['pred']}ì€ **ë™ì‹œì— {problem['pred_capacity']}ëª…** ì§„í–‰
                    - {problem['succ']}ì€ **ë™ì‹œì— {problem['succ_capacity']}ëª…ë§Œ** ìˆ˜ìš© ê°€ëŠ¥
                    - Adjacent ì œì•½ìœ¼ë¡œ ì¸í•´ ë‚˜ë¨¸ì§€ **{problem['pred_capacity'] - problem['succ_capacity']}ëª…ì´ ëŒ€ê¸°**
                    
                    **í•´ê²° ë°©ë²•:**
                    1. **Adjacent ì œì•½ ì œê±°**: ë” ìœ ì—°í•œ ìŠ¤ì¼€ì¤„ë§ í—ˆìš©
                    2. **ë°© ì¦ì„¤**: {problem['succ']} ë°©ì„ {problem['pred_capacity']}ê°œë¡œ ì¦ê°€
                    3. **ìš©ëŸ‰ ì¡°ì •**: {problem['pred']}ì˜ max_capì„ {problem['succ_capacity']}ë¡œ ì¶•ì†Œ
                    """)
            
            st.info("ğŸ’¡ **ê¶Œì¥ì‚¬í•­**: Adjacent ì œì•½ì€ ë¬¼ë¦¬ì ìœ¼ë¡œ ì—°ì†ëœ ê³µê°„ì´ë‚˜ ì¦‰ê°ì ì¸ ì´ë™ì´ í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.")
    
    # ë””ë²„ê·¸ ì •ë³´ JSON í‘œì‹œ
    with st.expander("ğŸ”§ ì „ì²´ ë””ë²„ê·¸ ì •ë³´ (ë³µì‚¬í•´ì„œ ê³µìœ  ê°€ëŠ¥)", expanded=True):
        # JSON í˜•íƒœë¡œ ì˜ˆì˜ê²Œ ì¶œë ¥
        debug_json = json.dumps(debug_info, indent=2, ensure_ascii=False)
        st.code(debug_json, language="json")
        
        # ë³µì‚¬ ë²„íŠ¼
        st.download_button(
            label="ğŸ“¥ ë””ë²„ê·¸ ì •ë³´ ë‹¤ìš´ë¡œë“œ",
            data=debug_json,
            file_name=f"debug_info_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )
    


if "ì†”ë²„ ì‹œê°„ ì´ˆê³¼" in st.session_state.get('last_solve_logs', ''):
    st.warning("âš ï¸ ì—°ì‚° ì‹œê°„ì´ 2ë¶„(120ì´ˆ)ì„ ì´ˆê³¼í•˜ì—¬, í˜„ì¬ê¹Œì§€ ì°¾ì€ ìµœì ì˜ ìŠ¤ì¼€ì¤„ì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤. ê²°ê³¼ëŠ” ìµœìƒì´ ì•„ë‹ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# ê²°ê³¼ ì¶œë ¥
final_schedule = st.session_state.get('final_schedule')
if final_schedule is not None and not final_schedule.empty:
    st.success("ğŸ‰ ìš´ì˜ì¼ì • ì¶”ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ìš”ì•½ ì •ë³´
    total_candidates = len(final_schedule)
    total_days = final_schedule['interview_date'].nunique()
    st.info(f"ì´ {total_candidates}ëª…ì˜ ì§€ì›ìë¥¼ {total_days}ì¼ì— ê±¸ì³ ë©´ì ‘ ì§„í–‰")
    
    # ì²´ë¥˜ì‹œê°„ ë¶„ì„ ì¶”ê°€
    st.subheader("â±ï¸ ì§ë¬´ë³„ ì²´ë¥˜ì‹œê°„ ë¶„ì„")
    
    def calculate_stay_duration_stats(schedule_df):
        """ê° ì§€ì›ìì˜ ì²´ë¥˜ì‹œê°„ì„ ê³„ì‚°í•˜ê³  ì§ë¬´ë³„ í†µê³„ë¥¼ ë°˜í™˜"""
        stats_data = []
        
        # ì»¬ëŸ¼ëª… ë§¤í•‘ (ì‹¤ì œ ë°ì´í„°ì— ë§ê²Œ ì¡°ì •)
        id_col = 'id' if 'id' in schedule_df.columns else 'candidate_id'
        job_col = 'code' if 'code' in schedule_df.columns else 'job_code'
        
        # ì‹œê°„ ì»¬ëŸ¼ë“¤ ì°¾ê¸° (start_í™œë™ëª…, end_í™œë™ëª… í˜•íƒœ)
        start_cols = [col for col in schedule_df.columns if col.startswith('start_')]
        end_cols = [col for col in schedule_df.columns if col.startswith('end_')]
        
        if not start_cols or not end_cols:
            st.error("ì‹œê°„ ì •ë³´ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. start_* ë˜ëŠ” end_* í˜•íƒœì˜ ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            return pd.DataFrame(), pd.DataFrame()
        
        # ì§€ì›ìë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì²´ë¥˜ì‹œê°„ ê³„ì‚°
        for candidate_id, candidate_data in schedule_df.groupby(id_col):
            # í•´ë‹¹ ì§€ì›ìì˜ ëª¨ë“  í™œë™ ì‹œê°„ ì •ë³´ ìˆ˜ì§‘
            all_start_times = []
            all_end_times = []
            
            for _, row in candidate_data.iterrows():
                for start_col in start_cols:
                    if pd.notna(row[start_col]) and row[start_col] != '':
                        try:
                            # ì‹œê°„ ë¬¸ìì—´ì„ datetimeìœ¼ë¡œ ë³€í™˜
                            time_str = str(row[start_col])
                            if ':' in time_str:
                                # HH:MM:SS ë˜ëŠ” HH:MM í˜•íƒœ
                                time_obj = pd.to_datetime(time_str, format='%H:%M:%S', errors='coerce')
                                if pd.isna(time_obj):
                                    time_obj = pd.to_datetime(time_str, format='%H:%M', errors='coerce')
                                if not pd.isna(time_obj):
                                    all_start_times.append(time_obj)
                        except:
                            continue
                
                for end_col in end_cols:
                    if pd.notna(row[end_col]) and row[end_col] != '':
                        try:
                            # ì‹œê°„ ë¬¸ìì—´ì„ datetimeìœ¼ë¡œ ë³€í™˜
                            time_str = str(row[end_col])
                            if ':' in time_str:
                                # HH:MM:SS ë˜ëŠ” HH:MM í˜•íƒœ
                                time_obj = pd.to_datetime(time_str, format='%H:%M:%S', errors='coerce')
                                if pd.isna(time_obj):
                                    time_obj = pd.to_datetime(time_str, format='%H:%M', errors='coerce')
                                if not pd.isna(time_obj):
                                    all_end_times.append(time_obj)
                        except:
                            continue
            
            if all_start_times and all_end_times:
                # ì „ì²´ ì²´ë¥˜ì‹œê°„ = ì²« ë²ˆì§¸ í™œë™ ì‹œì‘ ~ ë§ˆì§€ë§‰ í™œë™ ì¢…ë£Œ
                total_start = min(all_start_times)
                total_end = max(all_end_times)
                stay_duration_minutes = (total_end - total_start).total_seconds() / 60
                
                # ì§ë¬´ ì½”ë“œ (ì²« ë²ˆì§¸ í–‰ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
                job_code = candidate_data.iloc[0].get(job_col, 'Unknown')
                
                stats_data.append({
                    'candidate_id': candidate_id,
                    'job_code': job_code,
                    'stay_duration_minutes': stay_duration_minutes,
                    'start_time': total_start,
                    'end_time': total_end
                })
        
        if not stats_data:
            st.warning("ì²´ë¥˜ì‹œê°„ì„ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame(), pd.DataFrame()
        
        stats_df = pd.DataFrame(stats_data)
        
        # ì§ë¬´ë³„ í†µê³„ ê³„ì‚°
        job_stats = []
        for job_code, job_data in stats_df.groupby('job_code'):
            durations = job_data['stay_duration_minutes']
            job_stats.append({
                'job_code': job_code,
                'count': len(job_data),
                'min_duration': durations.min(),
                'max_duration': durations.max(),
                'avg_duration': durations.mean(),
                'median_duration': durations.median()
            })
        
        return pd.DataFrame(job_stats), stats_df
    
    try:
        job_stats_df, individual_stats_df = calculate_stay_duration_stats(final_schedule)
        
        if not job_stats_df.empty:
            # ì§ë¬´ë³„ í†µê³„ í‘œì‹œ
            st.markdown("**ğŸ“Š ì§ë¬´ë³„ ì²´ë¥˜ì‹œê°„ í†µê³„ (ë¶„ ë‹¨ìœ„)**")
            
            # í‘œì‹œìš© ë°ì´í„°í”„ë ˆì„ ìƒì„±
            display_stats = job_stats_df.copy()
            display_stats['min_duration'] = display_stats['min_duration'].round(1)
            display_stats['max_duration'] = display_stats['max_duration'].round(1)
            display_stats['avg_duration'] = display_stats['avg_duration'].round(1)
            display_stats['median_duration'] = display_stats['median_duration'].round(1)
            
            # ì»¬ëŸ¼ëª… í•œê¸€í™”
            display_stats.columns = ['ì§ë¬´ì½”ë“œ', 'ì¸ì›ìˆ˜', 'ìµœì†Œì‹œê°„(ë¶„)', 'ìµœëŒ€ì‹œê°„(ë¶„)', 'í‰ê· ì‹œê°„(ë¶„)', 'ì¤‘ê°„ê°’(ë¶„)']
            
            st.dataframe(display_stats, use_container_width=True)
            
            # ì‹œê°ì  ìš”ì•½
            col1, col2, col3 = st.columns(3)
            with col1:
                overall_min = job_stats_df['min_duration'].min()
                st.metric("ì „ì²´ ìµœì†Œ ì²´ë¥˜ì‹œê°„", f"{overall_min:.1f}ë¶„")
            with col2:
                overall_max = job_stats_df['max_duration'].max()
                st.metric("ì „ì²´ ìµœëŒ€ ì²´ë¥˜ì‹œê°„", f"{overall_max:.1f}ë¶„")
            with col3:
                overall_avg = (job_stats_df['avg_duration'] * job_stats_df['count']).sum() / job_stats_df['count'].sum()
                st.metric("ì „ì²´ í‰ê·  ì²´ë¥˜ì‹œê°„", f"{overall_avg:.1f}ë¶„")
            
            # ì²´ë¥˜ì‹œê°„ ì œí•œ í™•ì¸
            max_stay_minutes = params.get('max_stay_hours', 8) * 60
            if overall_max > max_stay_minutes:
                st.warning(f"âš ï¸ ì¼ë¶€ ì§€ì›ìì˜ ì²´ë¥˜ì‹œê°„ì´ ì„¤ì •ëœ ì œí•œ({params.get('max_stay_hours', 8)}ì‹œê°„)ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.")
    
    except Exception as e:
        st.error(f"ì²´ë¥˜ì‹œê°„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    # ìŠ¤ì¼€ì¤„ í‘œì‹œ ì˜µì…˜
    col1, col2 = st.columns([3, 1])
    with col1:
        # ë‚ ì§œë³„ ìš”ì•½ ì •ë³´
        date_summary = final_schedule.groupby('interview_date').size().reset_index(name='ì¸ì›ìˆ˜')
        date_summary['interview_date'] = pd.to_datetime(date_summary['interview_date']).dt.strftime('%Y-%m-%d')
        date_summary.columns = ['ë‚ ì§œ', 'ì¸ì›ìˆ˜']
        
        st.markdown("**ğŸ“… ë‚ ì§œë³„ ë©´ì ‘ ì¸ì›**")
        st.dataframe(date_summary, use_container_width=True, hide_index=True)
    
    with col2:
        st.markdown("**ğŸ’¾ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ**")
        excel_buffer = BytesIO()
        
        # ê·¸ë£¹ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ìˆë‹¤ë©´)
        group_info_data = st.session_state.get('last_group_info', None)
        
        df_to_excel(final_schedule, excel_buffer, group_info_data)
        excel_buffer.seek(0)
        
        st.download_button(
            label="ğŸ“¥ Excel ë‹¤ìš´ë¡œë“œ",
            data=excel_buffer,
            file_name=f"interview_schedule_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )
    
    # ìƒì„¸ ìŠ¤ì¼€ì¤„ í‘œì‹œ
    with st.expander("ğŸ“‹ ìƒì„¸ ìŠ¤ì¼€ì¤„ ë³´ê¸°", expanded=False):
        # ë‚ ì§œë³„ë¡œ íƒ­ ìƒì„±
        dates = sorted(final_schedule['interview_date'].unique())
        tabs = st.tabs([pd.to_datetime(d).strftime('%Y-%m-%d') for d in dates])
        
        for i, (tab, date) in enumerate(zip(tabs, dates)):
            with tab:
                day_schedule = final_schedule[final_schedule['interview_date'] == date].copy()
                
                # ì‹œê°„ ì»¬ëŸ¼ë“¤ì„ ë” ì½ê¸° ì‰½ê²Œ í‘œì‹œ
                display_cols = ['id', 'code']
                for col in day_schedule.columns:
                    if col.startswith(('start_', 'end_', 'loc_')) and col not in display_cols:
                        display_cols.append(col)
                
                day_schedule = day_schedule[display_cols]
                
                # ì¸ë±ìŠ¤ ìˆ¨ê¸°ê³  í‘œì‹œ
                st.dataframe(day_schedule, use_container_width=True, hide_index=True)
                
                # batched ëª¨ë“œê°€ ìˆìœ¼ë©´ ê·¸ë£¹ ì •ë³´ë„ í‘œì‹œ
                if has_batched:
                    # TODO: ê·¸ë£¹ ì •ë³´ í‘œì‹œ êµ¬í˜„
                    pass

st.divider()

# =============================================================================
# ì„¹ì…˜ 1: ë©´ì ‘í™œë™ ì •ì˜
# =============================================================================
col_header, col_refresh = st.columns([3, 2])
with col_header:
    st.header("1ï¸âƒ£ ë©´ì ‘í™œë™ ì •ì˜")
with col_refresh:
    st.markdown("<br>", unsafe_allow_html=True)  # í—¤ë”ì™€ ë†’ì´ ë§ì¶”ê¸°
    if st.button("ğŸ”„ ì„¹ì…˜ ìƒˆë¡œê³ ì¹¨", key="refresh_activities", help="í™œë™ ì •ì˜ AG-Gridê°€ ë¨¹í†µì¼ ë•Œ ìƒˆë¡œê³ ì¹¨"):
        # ì„¹ì…˜ë³„ ìƒˆë¡œê³ ì¹¨
        if "section_refresh_counter" not in st.session_state:
            st.session_state["section_refresh_counter"] = {}
        if "activities" not in st.session_state["section_refresh_counter"]:
            st.session_state["section_refresh_counter"]["activities"] = 0
        st.session_state["section_refresh_counter"]["activities"] += 1
        st.rerun()

st.markdown("ë©´ì ‘ í”„ë¡œì„¸ìŠ¤ì— í¬í•¨ë  í™œë™ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤. ê° í™œë™ì˜ ëª¨ë“œ, ì†Œìš”ì‹œê°„, í•„ìš”í•œ ê³µê°„ ë“±ì„ ì„¤ì •í•˜ì„¸ìš”.")

# ê¸°ë³¸ í…œí”Œë¦¿ í•¨ìˆ˜
def default_df() -> pd.DataFrame:
    return pd.DataFrame({
        "use": [True, True, True, True],
        "activity": ["ë©´ì ‘1", "ë©´ì ‘2", "ì¸ì„±ê²€ì‚¬", "ì»¤í”¼ì±—"],
        "mode": ["individual"] * 4,
        "duration_min": [10] * 4,
        "room_type": ["ë©´ì ‘1ì‹¤", "ë©´ì ‘2ì‹¤", "ì¸ì„±ê²€ì‚¬ì‹¤", "ì»¤í”¼ì±—ì‹¤"],
        "min_cap": [1] * 4,
        "max_cap": [1] * 4,
    })

df = st.session_state["activities"].copy()

# ëˆ„ë½ ì»¬ëŸ¼ ë³´ê°•
for col, default_val in {
    "use": True,
    "mode": "individual",
    "duration_min": 10,
    "room_type": "",
    "min_cap": 1,
    "max_cap": 1,
}.items():
    if col not in df.columns:
        df[col] = default_val

# AG-Grid ì„¤ì •
gb = GridOptionsBuilder.from_dataframe(df)

gb.configure_column(
    "use",
    header_name="ì‚¬ìš©",
    cellEditor="agCheckboxCellEditor",
    cellRenderer="agCheckboxCellRenderer",
    editable=True,
    singleClickEdit=True,
    width=80,
)

gb.configure_column("activity", header_name="í™œë™ ì´ë¦„", editable=True)

# mode_valuesì— parallelê³¼ batched ì¶”ê°€
mode_values = ["individual", "parallel", "batched"]
gb.configure_column(
    "mode",
    header_name="ëª¨ë“œ",
    editable=True,
    cellEditor="agSelectCellEditor",
    cellEditorParams={"values": mode_values},
    width=110,
)

# duration_minì€ í•­ìƒ í¸ì§‘ ê°€ëŠ¥
gb.configure_column(
    "duration_min",
    header_name="ì†Œìš”ì‹œê°„(ë¶„)",
    editable=True,
    type=["numericColumn", "numberColumnFilter"],
    width=120,
)

# min_cap, max_capì€ ì¡°ê±´ë¶€ í¸ì§‘ ê°€ëŠ¥ (individual ëª¨ë“œì—ì„œëŠ” ë¹„í™œì„±í™”)
for col, hdr in [("min_cap", "ìµœì†Œ ì¸ì›"), ("max_cap", "ìµœëŒ€ ì¸ì›")]:
    gb.configure_column(
        col,
        header_name=hdr,
        editable=True,
        type=["numericColumn", "numberColumnFilter"],
        width=120,
        cellEditor="agNumberCellEditor",
        cellEditorParams={
            "min": 1,
            "max": 50
        },
        # individual ëª¨ë“œì¼ ë•Œ í¸ì§‘ ë¶ˆê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ì¡°ê±´
        cellClassRules={
            "ag-cell-not-editable": "data.mode === 'individual'"
        },
        # individual ëª¨ë“œì¼ ë•Œ íšŒìƒ‰ìœ¼ë¡œ í‘œì‹œ
        cellStyle={
            "backgroundColor": "params.data.mode === 'individual' ? '#f0f0f0' : 'white'",
            "color": "params.data.mode === 'individual' ? '#888' : 'black'"
        }
    )

gb.configure_column("room_type", header_name="ë©´ì ‘ì‹¤ ì´ë¦„", editable=True)

grid_opts = gb.build()

st.markdown("#### í™œë™ ì •ì˜")

# AG-Gridì—ì„œ ë¹„í™œì„±í™”ëœ ì…€ ìŠ¤íƒ€ì¼ë§ì„ ìœ„í•œ CSS ì¶”ê°€
st.markdown("""
<style>
.ag-cell-not-editable {
    background-color: #f5f5f5 !important;
    color: #999 !important;
    cursor: not-allowed !important;
}
.ag-cell-not-editable:hover {
    background-color: #f0f0f0 !important;
}
</style>
""", unsafe_allow_html=True)

# ëª¨ë“œ ì„¤ëª… ì¶”ê°€
with st.expander("â„¹ï¸ ëª¨ë“œ ì„¤ëª…", expanded=False):
    st.markdown("""
    - **individual**: 1ëª…ì´ í˜¼ì ë©´ì ‘ (ê¸°ì¡´ ë°©ì‹)
      - ìµœì†Œ/ìµœëŒ€ ì¸ì›ì´ ìë™ìœ¼ë¡œ 1ëª…ìœ¼ë¡œ ê³ ì •ë©ë‹ˆë‹¤ (ìˆ˜ì • ë¶ˆê°€)
    - **parallel**: ì—¬ëŸ¬ëª…ì´ ê°™ì€ ê³µê°„ì—ì„œ ê°ì ë‹¤ë¥¸ í™œë™ (ì˜ˆ: ê°œë³„ ì‘ì—…)
      - ìµœì†Œ/ìµœëŒ€ ì¸ì›ì„ ììœ ë¡­ê²Œ ì„¤ì • ê°€ëŠ¥í•©ë‹ˆë‹¤
    - **batched**: ì—¬ëŸ¬ëª…ì´ ë™ì‹œì— ê°™ì€ í™œë™ (ì˜ˆ: ê·¸ë£¹í† ë¡ , PTë°œí‘œ)
      - ìµœì†Œ/ìµœëŒ€ ì¸ì›ì„ ììœ ë¡­ê²Œ ì„¤ì • ê°€ëŠ¥í•©ë‹ˆë‹¤
    
    **ì£¼ì˜**: 
    - **individual ëª¨ë“œ**: ì¸ì›ìˆ˜ ìˆ˜ì • ë¶ˆê°€ (1ëª… ê³ ì •)
    - **batched ëª¨ë“œ**: ëª¨ë“  batched í™œë™ì˜ min_cap, max_capì€ ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤
    """)

# í–‰ ì¶”ê°€/ì‚­ì œ ê¸°ëŠ¥ (ìœ„ë¡œ ì´ë™)
col_add, col_del = st.columns(2)

with col_add:
    if st.button("â• í™œë™ í–‰ ì¶”ê°€", key="add_activity"):
        new_row = {
            "use": True,
            "activity": "NEW_ACT",
            "mode": "individual",
            "duration_min": 10,
            "room_type": "",
            "min_cap": 1,
            "max_cap": 1,
        }
        st.session_state["activities"] = pd.concat(
            [st.session_state["activities"], pd.DataFrame([new_row])],
            ignore_index=True,
        )
        st.rerun()

with col_del:
    act_df = st.session_state["activities"].copy()
    if not act_df.empty:
        # ì¸ë±ìŠ¤ì™€ í™œë™ëª…ì„ ì•ˆì „í•˜ê²Œ ê²°í•©
        delete_options = []
        valid_indices = []
        for idx, row in act_df.iterrows():
            activity_name = str(row.get('activity', 'Unknown'))
            if activity_name and activity_name != 'nan':
                delete_options.append(f"{idx}: {activity_name}")
                valid_indices.append(idx)
        
        to_delete = st.multiselect(
            "ì‚­ì œí•  í™œë™ ì„ íƒ",
            options=delete_options,
            key="del_activity_select"
        )
        if st.button("âŒ ì„ íƒëœ í™œë™ ì‚­ì œ", key="del_activity"):
            if to_delete:
                # ì„ íƒëœ ì¸ë±ìŠ¤ ì¶”ì¶œ
                selected_indices = [int(s.split(":")[0]) for s in to_delete]
                
                # ì‹¤ì œ DataFrameì— ì¡´ì¬í•˜ëŠ” ì¸ë±ìŠ¤ë§Œ í•„í„°ë§
                valid_to_drop = [idx for idx in selected_indices if idx in act_df.index]
                
                if valid_to_drop:
                    kept = st.session_state["activities"].drop(valid_to_drop).reset_index(drop=True)
                    st.session_state["activities"] = kept
                    st.success(f"ì„ íƒëœ {len(valid_to_drop)}ê°œ í™œë™ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.rerun()
                else:
                    st.error("ì‚­ì œí•  ìœ íš¨í•œ í™œë™ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ì‚­ì œí•  í™œë™ì´ ì—†ìŠµë‹ˆë‹¤.")

# AG-Grid í‘œì‹œ (í–‰ ì¶”ê°€/ì‚­ì œ ê¸°ëŠ¥ ì•„ë˜ë¡œ ì´ë™)
# ì„¹ì…˜ë³„ ìƒˆë¡œê³ ì¹¨ì„ ìœ„í•œ ë™ì  key ìƒì„±
activities_refresh_count = st.session_state.get("section_refresh_counter", {}).get("activities", 0)

grid_ret = AgGrid(
    df,
    gridOptions=grid_opts,
    data_return_mode=DataReturnMode.AS_INPUT,
    update_mode=GridUpdateMode.VALUE_CHANGED,
    allow_unsafe_jscode=True,
    fit_columns_on_grid_load=True,
    theme="balham",
    key=f"activities_grid_{activities_refresh_count}",  # ë™ì  keyë¡œ ê°•ì œ ì¬ë Œë”ë§
)

# ê·¸ë¦¬ë“œ ë°ì´í„° ì²˜ë¦¬ ë° individual ëª¨ë“œ ê°•ì œ ì¡°ì •
activities_data = pd.DataFrame(grid_ret["data"])

# individual ëª¨ë“œì¸ í–‰ë“¤ì˜ min_cap, max_capì„ 1ë¡œ ê³ ì •
individual_mask = activities_data["mode"] == "individual"
activities_data.loc[individual_mask, "min_cap"] = 1
activities_data.loc[individual_mask, "max_cap"] = 1

st.session_state["activities"] = activities_data

# Activities â†’ Room Plan ìë™ ì—°ë™
activities_df = st.session_state["activities"]
room_plan_df = st.session_state.get("room_plan", pd.DataFrame())
room_template = st.session_state.get("room_template", {})

if not activities_df.empty and (not room_plan_df.empty or room_template):
    # ê° room_typeë³„ ìµœëŒ€ max_cap ê³„ì‚°
    room_capacity_updates = {}
    
    for room_type in activities_df["room_type"].unique():
        if pd.notna(room_type) and room_type != "":
            # í•´ë‹¹ room_typeì„ ì‚¬ìš©í•˜ëŠ” í™œë™ë“¤ì˜ ìµœëŒ€ max_cap
            max_cap_for_room = activities_df[activities_df["room_type"] == room_type]["max_cap"].max()
            
            if pd.notna(max_cap_for_room):
                room_capacity_updates[room_type] = int(max_cap_for_room)
    
    # room_template ì—…ë°ì´íŠ¸
    template_updated = False
    for room_type, new_capacity in room_capacity_updates.items():
        if room_type in room_template:
            if room_template[room_type]["cap"] < new_capacity:
                room_template[room_type]["cap"] = new_capacity
                template_updated = True
    
    # room_plan DataFrame ì—…ë°ì´íŠ¸
    plan_updated = False
    if not room_plan_df.empty:
        for room_type, new_capacity in room_capacity_updates.items():
            cap_col = f"{room_type}_cap"
            if cap_col in room_plan_df.columns:
                for idx in room_plan_df.index:
                    current_cap = room_plan_df.at[idx, cap_col]
                    if pd.notna(current_cap) and current_cap < new_capacity:
                        room_plan_df.at[idx, cap_col] = new_capacity
                        plan_updated = True
    
    # ë³€ê²½ì‚¬í•­ ì €ì¥ ë° ì•Œë¦¼
    if template_updated:
        st.session_state["room_template"] = room_template
    if plan_updated:
        st.session_state["room_plan"] = room_plan_df
    
    if template_updated or plan_updated:
        updated_rooms = [f"{rt}({cap}ëª…)" for rt, cap in room_capacity_updates.items()]
        st.info(f"ğŸ“ í™œë™ ê·¸ë£¹ í¬ê¸° ë³€ê²½ì— ë”°ë¼ ë°© ìˆ˜ìš© ì¸ì›ì´ ìë™ ì¡°ì •ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(updated_rooms)}")

# batched ëª¨ë“œ ì¼ê´€ì„± ê²€ì¦
batched_acts = st.session_state["activities"][st.session_state["activities"]["mode"] == "batched"]
if not batched_acts.empty:
    min_caps = batched_acts["min_cap"].unique()
    max_caps = batched_acts["max_cap"].unique()
    
    if len(min_caps) > 1 or len(max_caps) > 1:
        st.error("âš ï¸ ëª¨ë“  batched í™œë™ì˜ ê·¸ë£¹ í¬ê¸°(min_cap, max_cap)ëŠ” ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤!")
        st.info("í˜„ì¬ ì„¤ì •: " + 
                f"min_cap = {list(min_caps)}, " +
                f"max_cap = {list(max_caps)}")

st.divider()

# =============================================================================
# ì§‘ë‹¨ë©´ì ‘ ì„¤ì • (batched ëª¨ë“œê°€ ìˆì„ ë•Œë§Œ í‘œì‹œ)
# =============================================================================
acts_df = st.session_state.get("activities", pd.DataFrame())
has_batched = any(acts_df["mode"] == "batched") if not acts_df.empty and "mode" in acts_df.columns else False

if has_batched:
    with st.expander("ğŸ¯ ì§‘ë‹¨ë©´ì ‘ ì„¤ì •", expanded=True):
        st.markdown("ì§‘ë‹¨ë©´ì ‘(batched) í™œë™ì— ëŒ€í•œ ì „ì—­ ì„¤ì •ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.")
        
        # batched í™œë™ ëª©ë¡ í‘œì‹œ
        batched_activities = acts_df[acts_df["mode"] == "batched"]["activity"].tolist()
        st.info(f"ì§‘ë‹¨ë©´ì ‘ í™œë™: {', '.join(batched_activities)}")
        
        # ê·¸ë£¹ í¬ê¸° ì„¤ì •
        col1, col2 = st.columns(2)
        
        # batched í™œë™ í•„í„°ë§ ì¶”ê°€
        batched_acts = acts_df[acts_df["mode"] == "batched"]
        
        with col1:
            # ê¸°ì¡´ ê°’ ê°€ì ¸ì˜¤ê¸°
            current_min = st.session_state.get('group_min_size', 4)
            # batched í™œë™ì´ ìˆìœ¼ë©´ ê·¸ ê°’ ì‚¬ìš©
            if not batched_acts.empty:
                current_min = int(batched_acts.iloc[0]['min_cap'])
            
            # min_valueë³´ë‹¤ ì‘ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
            if current_min < 2:
                current_min = 4
            
            group_min = st.number_input(
                "ê·¸ë£¹ ìµœì†Œ ì¸ì›",
                min_value=2,
                max_value=20,
                value=current_min,
                key="group_min_input",
                help="ëª¨ë“  ì§‘ë‹¨ë©´ì ‘ í™œë™ì— ì ìš©ë©ë‹ˆë‹¤"
            )
        
        with col2:
            # ê¸°ì¡´ ê°’ ê°€ì ¸ì˜¤ê¸°
            current_max = st.session_state.get('group_max_size', 6)
            # batched í™œë™ì´ ìˆìœ¼ë©´ ê·¸ ê°’ ì‚¬ìš©
            if not batched_acts.empty:
                current_max = int(batched_acts.iloc[0]['max_cap'])
            
            # min_valueë³´ë‹¤ ì‘ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
            if current_max < group_min:
                current_max = max(6, group_min)
            
            group_max = st.number_input(
                "ê·¸ë£¹ ìµœëŒ€ ì¸ì›",
                min_value=group_min,
                max_value=30,
                value=current_max,
                key="group_max_input",
                help="ëª¨ë“  ì§‘ë‹¨ë©´ì ‘ í™œë™ì— ì ìš©ë©ë‹ˆë‹¤"
            )
        
        # ê°’ì´ ë³€ê²½ë˜ë©´ ëª¨ë“  batched í™œë™ì— ì ìš©
        if group_min != st.session_state.get('group_min_size') or group_max != st.session_state.get('group_max_size'):
            st.session_state['group_min_size'] = group_min
            st.session_state['group_max_size'] = group_max
            
            # activities DataFrame ì—…ë°ì´íŠ¸
            acts_df = st.session_state["activities"]
            acts_df.loc[acts_df["mode"] == "batched", "min_cap"] = group_min
            acts_df.loc[acts_df["mode"] == "batched", "max_cap"] = group_max
            st.session_state["activities"] = acts_df
            
            # ì§‘ë‹¨ë©´ì ‘ ì„¤ì • â†’ Room Plan ìë™ ì—°ë™
            room_plan_df = st.session_state.get("room_plan", pd.DataFrame())
            room_template = st.session_state.get("room_template", {})
            
            if not room_plan_df.empty and room_template:
                # batched í™œë™ì´ ì‚¬ìš©í•˜ëŠ” room_typeë“¤ì˜ capacity ì—…ë°ì´íŠ¸
                batched_room_types = acts_df[acts_df["mode"] == "batched"]["room_type"].unique()
                
                room_updated = False
                for room_type in batched_room_types:
                    if pd.notna(room_type) and room_type != "":
                        # room_template ì—…ë°ì´íŠ¸
                        if room_type in room_template:
                            if room_template[room_type]["cap"] < group_max:
                                room_template[room_type]["cap"] = group_max
                                room_updated = True
                        
                        # room_plan DataFrame ì—…ë°ì´íŠ¸
                        cap_col = f"{room_type}_cap"
                        if cap_col in room_plan_df.columns:
                            for idx in room_plan_df.index:
                                current_cap = room_plan_df.at[idx, cap_col]
                                if pd.notna(current_cap) and current_cap < group_max:
                                    room_plan_df.at[idx, cap_col] = group_max
                                    room_updated = True
                
                if room_updated:
                    st.session_state["room_template"] = room_template
                    st.session_state["room_plan"] = room_plan_df
                    st.info(f"ğŸ“ ì§‘ë‹¨ë©´ì ‘ ê·¸ë£¹ í¬ê¸° ë³€ê²½ì— ë”°ë¼ ê´€ë ¨ ë°©ì˜ ìˆ˜ìš© ì¸ì›ì´ {group_max}ëª…ìœ¼ë¡œ ìë™ ì¡°ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            st.success(f"âœ… ëª¨ë“  ì§‘ë‹¨ë©´ì ‘ í™œë™ì˜ ê·¸ë£¹ í¬ê¸°ê°€ {group_min}~{group_max}ëª…ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì¶”ê°€ ì„¤ì •ë“¤
        st.markdown("### ê³ ê¸‰ ì„¤ì •")
        
        col3, col4 = st.columns(2)
        
        with col3:
            global_gap = st.number_input(
                "ì „ì—­ í™œë™ ê°„ê²©(ë¶„)",
                min_value=0,
                max_value=60,
                value=st.session_state.get('global_gap_min', 5),
                key="global_gap_input",
                help="ëª¨ë“  í™œë™ ê°„ ê¸°ë³¸ ê°„ê²©ì…ë‹ˆë‹¤. Precedenceì—ì„œ ê°œë³„ ì„¤ì • ê°€ëŠ¥í•©ë‹ˆë‹¤."
            )
            st.session_state['global_gap_min'] = global_gap
        
        with col4:
            max_stay = st.number_input(
                "ìµœëŒ€ ì²´ë¥˜ì‹œê°„(ì‹œê°„)",
                min_value=1,
                max_value=12,
                value=st.session_state.get('max_stay_hours', 8),
                key="max_stay_input",
                help="ì§€ì›ìê°€ ë©´ì ‘ì¥ì— ë¨¸ë¬´ë¥¼ ìˆ˜ ìˆëŠ” ìµœëŒ€ ì‹œê°„ì…ë‹ˆë‹¤."
            )
            st.session_state['max_stay_hours'] = max_stay
        
        # ì§ë¬´ë³„ ë¶„ë¦¬ ì›ì¹™ í‘œì‹œ
        st.markdown("### ê·¸ë£¹ êµ¬ì„± ì›ì¹™")
        st.info("""
        âœ… **ì§ë¬´ë³„ ë¶„ë¦¬**: ê°™ì€ ì§ë¬´ë¼ë¦¬ë§Œ ê·¸ë£¹ êµ¬ì„±
        âœ… **ê·¸ë£¹ ì¼ê´€ì„±**: í•œ ë²ˆ êµ¬ì„±ëœ ê·¸ë£¹ì€ ëª¨ë“  batched í™œë™ì—ì„œ ìœ ì§€
        âœ… **ë™ì¼ ì§ë¬´ ë™ì¼ ë°©**: ê°™ì€ ì§ë¬´ëŠ” ëª¨ë“  í™œë™ì—ì„œ ë™ì¼í•œ ì ‘ë¯¸ì‚¬(A,B,C...) ì‚¬ìš©
        âœ… **ê·¸ë£¹ ìˆ˜ ìµœì†Œí™”**: ë”ë¯¸ ì§€ì›ìë¥¼ í™œìš©í•˜ì—¬ ê·¸ë£¹ ìˆ˜ ìµœì†Œí™”
        """)

    st.divider()

# =============================================================================
# ì„¹ì…˜ 2: ì„ í›„í–‰ ì œì•½ ì„¤ì •
# =============================================================================
col_header, col_refresh = st.columns([3, 2])
with col_header:
    st.header("2ï¸âƒ£ ì„ í›„í–‰ ì œì•½ ì„¤ì •")
with col_refresh:
    st.markdown("<br>", unsafe_allow_html=True)  # í—¤ë”ì™€ ë†’ì´ ë§ì¶”ê¸°
    if st.button("ğŸ”„ ì„¹ì…˜ ìƒˆë¡œê³ ì¹¨", key="refresh_precedence", help="ì„ í›„í–‰ ì œì•½ UIê°€ ë¨¹í†µì¼ ë•Œ ìƒˆë¡œê³ ì¹¨"):
        # ì„¹ì…˜ë³„ ìƒˆë¡œê³ ì¹¨
        if "section_refresh_counter" not in st.session_state:
            st.session_state["section_refresh_counter"] = {}
        if "precedence" not in st.session_state["section_refresh_counter"]:
            st.session_state["section_refresh_counter"]["precedence"] = 0
        st.session_state["section_refresh_counter"]["precedence"] += 1
        st.rerun()

st.markdown("ë©´ì ‘ í™œë™ ê°„ì˜ ìˆœì„œ ì œì•½ê³¼ ì‹œê°„ ê°„ê²©ì„ ì„¤ì •í•©ë‹ˆë‹¤.")

# ê³µí†µ ë°ì´í„° ë¡œë“œ
acts_df = st.session_state.get("activities", pd.DataFrame())
jobs_df = st.session_state.get("job_acts_map", pd.DataFrame())

if not acts_df.empty:
    ACT_OPTS = acts_df.query("use == True")["activity"].tolist()
    
    # precedence ê·œì¹™ ì´ˆê¸°í™” (ë¹ˆ ë¬¸ìì—´ë„ í—ˆìš©)
    prec_df = st.session_state["precedence"].copy()
    valid_acts = set(ACT_OPTS) | {"__START__", "__END__", ""}
    prec_df = prec_df[prec_df["predecessor"].isin(valid_acts) & prec_df["successor"].isin(valid_acts)]
    st.session_state["precedence"] = prec_df
    
    # ë™ì„  ë¯¸ë¦¬ë³´ê¸° í•¨ìˆ˜
    def generate_flow_preview():
        """í˜„ì¬ ì„ í›„í–‰ ì œì•½ ê·œì¹™ì„ ë°”íƒ•ìœ¼ë¡œ ê°€ëŠ¥í•œ ë™ì„ ì„ ì‹œê°í™”"""
        prec_rules = st.session_state["precedence"].copy()
        if prec_rules.empty:
            return "ğŸ“‹ ì„¤ì •ëœ ì œì•½ ê·œì¹™ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  í™œë™ì´ ììœ ë¡­ê²Œ ë°°ì¹˜ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        
        # STARTì™€ END ê·œì¹™ ë¶„ë¦¬
        start_rules = prec_rules[prec_rules["predecessor"] == "__START__"]
        end_rules = prec_rules[prec_rules["successor"] == "__END__"]
        middle_rules = prec_rules[
            (~prec_rules["predecessor"].isin(["__START__", "__END__"])) &
            (~prec_rules["successor"].isin(["__START__", "__END__"]))
        ]
        
        flow_text = "ğŸ”„ **ì˜ˆìƒ ë©´ì ‘ ë™ì„ :**\n\n"
        
        # START ê·œì¹™ì´ ìˆëŠ” ê²½ìš°
        if not start_rules.empty:
            first_acts = start_rules["successor"].tolist()
            flow_text += f"**ì‹œì‘:** ğŸ â†’ {' / '.join(first_acts)}\n\n"
        else:
            flow_text += "**ì‹œì‘:** ğŸ â†’ (ëª¨ë“  í™œë™ ê°€ëŠ¥)\n\n"
        
        # ì¤‘ê°„ ê·œì¹™ë“¤
        if not middle_rules.empty:
            flow_text += "**ì¤‘ê°„ ì—°ê²°:**\n"
            for _, rule in middle_rules.iterrows():
                gap_info = f" ({rule['gap_min']}ë¶„ ê°„ê²©)" if rule['gap_min'] > 0 else ""
                adj_info = " [ì¸ì ‘]" if rule['adjacent'] else ""
                flow_text += f"â€¢ {rule['predecessor']} â†’ {rule['successor']}{gap_info}{adj_info}\n"
            flow_text += "\n"
        
        # END ê·œì¹™ì´ ìˆëŠ” ê²½ìš°
        if not end_rules.empty:
            last_acts = end_rules["predecessor"].tolist()
            flow_text += f"**ì¢…ë£Œ:** {' / '.join(last_acts)} â†’ ğŸ"
        else:
            flow_text += "**ì¢…ë£Œ:** (ëª¨ë“  í™œë™ ê°€ëŠ¥) â†’ ğŸ"
        
        return flow_text
    
    # ê°€ëŠ¥í•œ ëª¨ë“  í™œë™ ìˆœì„œ ê³„ì‚° í•¨ìˆ˜ (ê³¼ê±° ì½”ë“œ ë³µì›)
    def render_dynamic_flows(prec_df: pd.DataFrame, base_nodes: list[str]) -> list[str]:
        """
        prec_df: ['predecessor','successor','gap_min','adjacent']
        base_nodes: ìˆœì„œì— í¬í•¨ë  í™œë™ ë¦¬ìŠ¤íŠ¸
        """
        import itertools
        
        # 1) ê·œì¹™(rules)ì— adjacentê¹Œì§€ í•¨ê»˜ ì½ì–´ì˜¤ê¸°
        rules = [
            (row.predecessor, row.successor,
             int(row.gap_min),
             bool(getattr(row, "adjacent", False)))
            for row in prec_df.itertuples()
        ]
        n = len(base_nodes)
        valid_orders = []

        # 2) ì¸í„°ë·° ëŠë‚Œ ì´ëª¨ì§€ í’€(10ê°œ) + ë™ì  ë§¤í•‘
        emoji_pool = ["ğŸ“","ğŸ§‘â€ğŸ’¼","ğŸ¤","ğŸ’¼","ğŸ—£ï¸","ğŸ¤","ğŸ¯","ğŸ”","ğŸ“‹","â°"]
        icons = { act: emoji_pool[i % len(emoji_pool)]
                  for i, act in enumerate(base_nodes) }

        # 3) ëª¨ë“  ìˆœì—´ ê²€ì‚¬
        for perm in itertools.permutations(base_nodes, n):
            ok = True
            for p, s, gap, adj in rules:
                # START â†’ S
                if p == "__START__":
                    if perm[0] != s:
                        ok = False
                    if not ok: break
                    else: continue
                # P â†’ END
                if s == "__END__":
                    if perm[-1] != p:
                        ok = False
                    if not ok: break
                    else: continue
                # ì¼ë°˜ í™œë™ ê°„ ì œì•½
                if p in perm and s in perm:
                    i_p, i_s = perm.index(p), perm.index(s)
                    # ë¶™ì´ê¸°(adjacent) ë˜ëŠ” gap>0 ëª¨ë‘ "ì¸ì ‘" ì²˜ë¦¬
                    if adj or gap > 0:
                        if i_s != i_p + 1:
                            ok = False
                            break
                    else:
                        # gap==0: ìˆœì„œë§Œ ë³´ì¥
                        if i_p >= i_s:
                            ok = False
                            break
            if ok:
                valid_orders.append(perm)

        # 4) ë¬¸ìì—´ë¡œ ë³€í™˜ (ì•„ì´ì½˜ + í™œë™ëª…)
        flow_strs = []
        for order in valid_orders:
            labels = [f"{icons[act]} {act}" for act in order]
            flow_strs.append(" â” ".join(labels))
        return flow_strs
    
    # ì‹¤ì‹œê°„ ë™ì„ (í™œë™ ìˆœì„œ) ë¯¸ë¦¬ë³´ê¸°
    with st.expander("ğŸ” ì‹¤ì‹œê°„ ë™ì„ (í™œë™ ìˆœì„œ) ë¯¸ë¦¬ë³´ê¸°", expanded=True):
        prec_df_latest = st.session_state["precedence"]
        
        # ê¸°ë³¸ ê·œì¹™ í‘œì‹œ
        st.markdown("**ğŸ“‹ í˜„ì¬ ì„¤ì •ëœ ì„ í›„í–‰ ì œì•½ ê·œì¹™:**")
        if prec_df_latest.empty:
            st.info("ì„¤ì •ëœ ì œì•½ ê·œì¹™ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  í™œë™ì´ ììœ ë¡­ê²Œ ë°°ì¹˜ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        else:
            # ê·œì¹™ì„ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ í‘œì‹œ
            for _, rule in prec_df_latest.iterrows():
                pred = rule['predecessor']
                succ = rule['successor']
                gap = rule['gap_min']
                adj = rule['adjacent']
                
                # í‘œì‹œ í˜•ì‹ ê°œì„ 
                if pred == "__START__":
                    pred_display = "ğŸ ì‹œì‘"
                elif pred == "":
                    pred_display = "ğŸ ì‹œì‘"
                else:
                    pred_display = f"ğŸ“ {pred}"
                
                if succ == "__END__":
                    succ_display = "ğŸ ì¢…ë£Œ"
                elif succ == "":
                    succ_display = "ğŸ ì¢…ë£Œ"
                else:
                    succ_display = f"ğŸ“ {succ}"
                
                gap_info = f" ({gap}ë¶„ ê°„ê²©)" if gap > 0 else ""
                adj_info = " [ì¸ì ‘ ë°°ì¹˜]" if adj else ""
                
                st.markdown(f"â€¢ {pred_display} â†’ {succ_display}{gap_info}{adj_info}")
        
        st.markdown("---")
        
        # ê°€ëŠ¥í•œ í™œë™ ìˆœì„œ ê³„ì‚° ë° í‘œì‹œ
        if ACT_OPTS:
            flows = render_dynamic_flows(prec_df_latest, ACT_OPTS)
            if not flows:
                st.warning("âš ï¸ í˜„ì¬ ì œì•½ì„ ë§Œì¡±í•˜ëŠ” í™œë™ ìˆœì„œê°€ ì—†ìŠµë‹ˆë‹¤. ì œì•½ ì¡°ê±´ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            else:
                st.markdown("**ğŸ”„ ê°€ëŠ¥í•œ ëª¨ë“  í™œë™ ìˆœì„œ:**")
                for i, f in enumerate(flows, 1):
                    st.markdown(f"{i}. {f}")
                
                if len(flows) == 1:
                    st.success("âœ… ì œì•½ ì¡°ê±´ì— ë”°ë¼ í™œë™ ìˆœì„œê°€ ê³ ìœ í•˜ê²Œ ê²°ì •ë©ë‹ˆë‹¤!")
                else:
                    st.info(f"ğŸ’¡ ì´ {len(flows)}ê°€ì§€ ê°€ëŠ¥í•œ í™œë™ ìˆœì„œê°€ ìˆìŠµë‹ˆë‹¤.")
        else:
            st.warning("í™œì„±í™”ëœ í™œë™ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í™œë™ì„ ì •ì˜í•´ì£¼ì„¸ìš”.")

    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ¯ ë©´ì ‘ ìˆœì„œ ì„¤ì • (ë‹¨ê³„ë³„ ê°€ì´ë“œ)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    # í˜„ì¬ ì„¤ì •ëœ START/END ê·œì¹™ í™•ì¸
    current_start = None
    current_end = None
    for _, rule in prec_df.iterrows():
        if rule['predecessor'] == "__START__":
            current_start = rule['successor']
        if rule['successor'] == "__END__":
            current_end = rule['predecessor']
    
    # ì„¹ì…˜ë³„ ìƒˆë¡œê³ ì¹¨ì„ ìœ„í•œ ë™ì  key ìƒì„±
    precedence_refresh_count = st.session_state.get("section_refresh_counter", {}).get("precedence", 0)
    
    st.markdown("---")
    st.subheader("ğŸ¯ ë©´ì ‘ ìˆœì„œ ì„¤ì •")
    st.markdown("ë©´ì ‘ í™œë™ë“¤ì˜ ìˆœì„œì™€ ì œì•½ì„ ì„¤ì •í•©ë‹ˆë‹¤.")
    
    # íƒ­ìœ¼ë¡œ ê¸°ëŠ¥ êµ¬ë¶„
    tab1, tab2 = st.tabs(["ğŸ ì‹œì‘/ë ê·œì¹™", "ğŸ”— ìˆœì„œ ê·œì¹™"])
    
    with tab1:
        st.markdown("ğŸ’¡ **ë©´ì ‘ì˜ ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ í™œë™ì„ ì§€ì •í•˜ì„¸ìš”.** (ì„ íƒì‚¬í•­)")
        
        col1, col2, col3 = st.columns([2, 2, 1])
        
        # í˜„ì¬ ê°’ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
        start_idx = 0
        end_idx = 0
        if current_start and current_start in ACT_OPTS:
            start_idx = ACT_OPTS.index(current_start) + 1
        if current_end and current_end in ACT_OPTS:
            end_idx = ACT_OPTS.index(current_end) + 1
        
        with col1:
            first = st.selectbox(
                "ğŸ ê°€ì¥ ë¨¼ì € í•  í™œë™", 
                ["(ì§€ì • ì•ˆ í•¨)"] + ACT_OPTS, 
                index=start_idx, 
                key=f"first_act_{precedence_refresh_count}",
                help="ë©´ì ‘ í”„ë¡œì„¸ìŠ¤ì˜ ì²« ë²ˆì§¸ í™œë™ì„ ì„ íƒí•˜ì„¸ìš”"
            )
        
        with col2:
            last = st.selectbox(
                "ğŸ ê°€ì¥ ë§ˆì§€ë§‰ í™œë™", 
                ["(ì§€ì • ì•ˆ í•¨)"] + ACT_OPTS, 
                index=end_idx, 
                key=f"last_act_{precedence_refresh_count}",
                help="ë©´ì ‘ í”„ë¡œì„¸ìŠ¤ì˜ ë§ˆì§€ë§‰ í™œë™ì„ ì„ íƒí•˜ì„¸ìš”"
            )
        
        with col3:
            st.markdown("<br>", unsafe_allow_html=True)  # ë²„íŠ¼ ë†’ì´ ë§ì¶”ê¸°
            if st.button("âœ… ì ìš©", key="btn_add_start_end", type="primary", use_container_width=True):
                # ê¸°ì¡´ __START__/__END__ ê´€ë ¨ í–‰ ì œê±°
                tmp = prec_df[
                    (~prec_df["predecessor"].isin(["__START__", "__END__"])) &
                    (~prec_df["successor"].isin(["__START__", "__END__"]))
                ].copy()
                
                rows = []
                if first != "(ì§€ì • ì•ˆ í•¨)":
                    rows.append({"predecessor": "__START__", "successor": first, "gap_min": 0, "adjacent": True})
                if last != "(ì§€ì • ì•ˆ í•¨)":
                    rows.append({"predecessor": last, "successor": "__END__", "gap_min": 0, "adjacent": True})
                
                st.session_state["precedence"] = pd.concat([tmp, pd.DataFrame(rows)], ignore_index=True)
                st.success("âœ… ì‹œì‘/ë í™œë™ì´ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
    
    with tab2:
        st.markdown("ğŸ’¡ **íŠ¹ì • í™œë™ ë‹¤ìŒì— ë°˜ë“œì‹œ ì™€ì•¼ í•˜ëŠ” í™œë™ì„ ì—°ê²°í•˜ì„¸ìš”.** (ì„ íƒì‚¬í•­)")
        st.markdown("ğŸ“ **ì˜ˆì‹œ:** ë©´ì ‘1 â†’ ë©´ì ‘2 (ë©´ì ‘1 í›„ì— ë°˜ë“œì‹œ ë©´ì ‘2ê°€ ì™€ì•¼ í•¨)")
        
        # ê¸°ë³¸ ì—°ê²° ì„¤ì •
        st.markdown("#### ğŸ“Œ í™œë™ ì—°ê²°")
        col_form1, col_form2, col_form3 = st.columns([2, 2, 1])
        
        with col_form1:
            p = st.selectbox("ğŸ”¸ ë¨¼ì € í•  í™œë™", ACT_OPTS, key=f"pred_select_{precedence_refresh_count}", help="ì„ í–‰ í™œë™ì„ ì„ íƒí•˜ì„¸ìš”")
        
        with col_form2:
            s = st.selectbox("ğŸ”¹ ë‹¤ìŒì— í•  í™œë™", ACT_OPTS, key=f"succ_select_{precedence_refresh_count}", help="í›„í–‰ í™œë™ì„ ì„ íƒí•˜ì„¸ìš”")
        
        with col_form3:
            st.markdown("<br>", unsafe_allow_html=True)  # ë²„íŠ¼ ë†’ì´ ë§ì¶”ê¸°
            add_rule_btn = st.button("âœ… ì ìš©", key="btn_add_sequence", type="primary", use_container_width=True)
        
        # ê³ ê¸‰ ì˜µì…˜ì„ ë³„ë„ ì˜ì—­ìœ¼ë¡œ ë¶„ë¦¬
        st.markdown("#### âš™ï¸ ê³ ê¸‰ ì˜µì…˜")
        col_gap, col_adj = st.columns(2)
        with col_gap:
            g = st.number_input("â±ï¸ ìµœì†Œ ê°„ê²© (ë¶„)", 0, 60, 5, key=f"gap_input_{precedence_refresh_count}", help="ë‘ í™œë™ ì‚¬ì´ì˜ ìµœì†Œ ì‹œê°„ ê°„ê²©")
        with col_adj:
            adj = st.checkbox("ğŸ“Œ ì—°ì† ë°°ì¹˜ (ë¶™ì—¬ì„œ ì§„í–‰)", value=True, key=f"adj_checkbox_{precedence_refresh_count}", help="ë‘ í™œë™ì„ ì‹œê°„ì ìœ¼ë¡œ ì—°ì†í•´ì„œ ë°°ì¹˜")
        
        if add_rule_btn:
            df = st.session_state["precedence"]
            dup = ((df["predecessor"] == p) & (df["successor"] == s)).any()
            if p == s:
                st.error("âŒ ê°™ì€ í™œë™ë¼ë¦¬ëŠ” ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            elif dup:
                st.warning("âš ï¸ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê·œì¹™ì…ë‹ˆë‹¤.")
            else:
                st.session_state["precedence"] = pd.concat(
                    [df, pd.DataFrame([{"predecessor": p, "successor": s, "gap_min": g, "adjacent": adj}])],
                    ignore_index=True
                )
                st.success(f"âœ… ê·œì¹™ ì¶”ê°€: {p} â†’ {s}")
                st.rerun()
    
    # ì„¤ì •ëœ ê·œì¹™ ê´€ë¦¬ ë° ì‚­ì œ
    with st.expander("ğŸ—‚ï¸ ì„¤ì •ëœ ê·œì¹™ ê´€ë¦¬", expanded=True):
        prec_df = st.session_state["precedence"].copy()
        
        if not prec_df.empty:
            # ê·œì¹™ì„ ë³´ê¸° ì¢‹ê²Œ í‘œì‹œ
            prec_df["ê·œì¹™í‘œì‹œìš©"] = prec_df.apply(
                lambda r: f"{r.predecessor} â†’ {r.successor}" + 
                         (f" (ê°„ê²©: {r.gap_min}ë¶„)" if r.gap_min > 0 else "") +
                         (" [ì—°ì†ë°°ì¹˜]" if r.adjacent else ""), axis=1
            )
            
            # 2ë‹¨ êµ¬ì¡°: ì™¼ìª½ì€ ê·œì¹™ ëª©ë¡, ì˜¤ë¥¸ìª½ì€ ì‚­ì œ ê¸°ëŠ¥
            col_rules, col_actions = st.columns([3, 2])
            
            with col_rules:
                st.markdown("**ğŸ“‹ í˜„ì¬ ì„¤ì •ëœ ê·œì¹™ë“¤**")
                
                # START/END ê·œì¹™ê³¼ ì¼ë°˜ ê·œì¹™ ë¶„ë¦¬í•´ì„œ í‘œì‹œ
                start_end_rules = prec_df[
                    (prec_df["predecessor"] == "__START__") | (prec_df["successor"] == "__END__")
                ]
                normal_rules = prec_df[
                    (~prec_df["predecessor"].isin(["__START__", "__END__"])) &
                    (~prec_df["successor"].isin(["__START__", "__END__"]))
                ]
                
                if not start_end_rules.empty:
                    st.markdown("**ğŸ ì‹œì‘/ë ê·œì¹™:**")
                    for rule in start_end_rules["ê·œì¹™í‘œì‹œìš©"]:
                        st.markdown(f"â€¢ {rule}")
                
                if not normal_rules.empty:
                    st.markdown("**ğŸ”— ìˆœì„œ ì—°ê²° ê·œì¹™:**")
                    for rule in normal_rules["ê·œì¹™í‘œì‹œìš©"]:
                        st.markdown(f"â€¢ {rule}")
            
            with col_actions:
                st.markdown("**ğŸ—‘ï¸ ê·œì¹™ ì‚­ì œ**")
                
                # ì‚­ì œí•  ê·œì¹™ ì„ íƒ
                delete_options = prec_df["ê·œì¹™í‘œì‹œìš©"].tolist()
                to_delete = st.multiselect(
                    "ì‚­ì œí•  ê·œì¹™ ì„ íƒ",
                    options=delete_options,
                    key=f"del_prec_select_{precedence_refresh_count}",
                    help="ì—¬ëŸ¬ ê·œì¹™ì„ í•œ ë²ˆì— ì„ íƒ ê°€ëŠ¥"
                )
                
                # ì‚­ì œ ë²„íŠ¼ë“¤
                if st.button("âŒ ì„ íƒ ì‚­ì œ", key="del_prec", disabled=not to_delete, use_container_width=True):
                    if to_delete:
                        new_prec = prec_df[~prec_df["ê·œì¹™í‘œì‹œìš©"].isin(to_delete)].drop(
                            columns="ê·œì¹™í‘œì‹œìš©"
                        ).reset_index(drop=True)
                        st.session_state["precedence"] = new_prec.copy()
                        st.success(f"âœ… {len(to_delete)}ê°œ ê·œì¹™ ì‚­ì œ!")
                        st.rerun()
                
                if st.button("ğŸ—‘ï¸ ì „ì²´ ì‚­ì œ", key="clear_all_prec", type="secondary", use_container_width=True):
                    st.session_state["precedence"] = pd.DataFrame(columns=["predecessor", "successor", "gap_min", "adjacent"])
                    st.success("âœ… ëª¨ë“  ê·œì¹™ ì‚­ì œ!")
                    st.rerun()
        else:
            st.info("ğŸ“‹ ì„¤ì •ëœ ì„ í›„í–‰ ì œì•½ ê·œì¹™ì´ ì—†ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ ê·œì¹™ì„ ì¶”ê°€í•´ë³´ì„¸ìš”.")

st.divider()

# =============================================================================
# ì„¹ì…˜ 3: ì§ë¬´ë³„ ë©´ì ‘í™œë™ ì •ì˜ (ì„ í›„í–‰ ì œì•½ ì„¤ì • ë‹¤ìŒìœ¼ë¡œ ì´ë™)
# =============================================================================
col_header, col_refresh = st.columns([3, 2])
with col_header:
    st.header("3ï¸âƒ£ ì§ë¬´ë³„ ë©´ì ‘í™œë™ ì •ì˜")
with col_refresh:
    st.markdown("<br>", unsafe_allow_html=True)  # í—¤ë”ì™€ ë†’ì´ ë§ì¶”ê¸°
    if st.button("ğŸ”„ ì„¹ì…˜ ìƒˆë¡œê³ ì¹¨", key="refresh_job_activities", help="ì§ë¬´ë³„ ë©´ì ‘í™œë™ AG-Gridê°€ ë¨¹í†µì¼ ë•Œ ìƒˆë¡œê³ ì¹¨"):
        # ì„¹ì…˜ë³„ ìƒˆë¡œê³ ì¹¨
        if "section_refresh_counter" not in st.session_state:
            st.session_state["section_refresh_counter"] = {}
        if "job_activities" not in st.session_state["section_refresh_counter"]:
            st.session_state["section_refresh_counter"]["job_activities"] = 0
        st.session_state["section_refresh_counter"]["job_activities"] += 1
        st.rerun()

st.markdown("ê° ì§ë¬´ ì½”ë“œë³„ë¡œ ì–´ë–¤ ë©´ì ‘í™œë™ì„ ì§„í–‰í• ì§€ ì„¤ì •í•˜ê³  ì¸ì›ìˆ˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.")

# í™œë™ ëª©ë¡ í™•ë³´
acts_df = st.session_state.get("activities")
if acts_df is None or acts_df.empty:
    st.error("ë¨¼ì € ë©´ì ‘í™œë™ì„ ì •ì˜í•´ì£¼ì„¸ìš”.")
else:
    act_list = acts_df.query("use == True")["activity"].tolist()
    
    if not act_list:
        st.error("í™œë™ì„ ìµœì†Œ 1ê°œ 'ì‚¬ìš©'ìœ¼ë¡œ ì²´í¬í•´ì•¼ í•©ë‹ˆë‹¤.")
    else:
        # ì§ë¬´ ë§¤í•‘ ë°ì´í„° ë¡œë“œ
        if "job_acts_map" in st.session_state:
            job_df = st.session_state["job_acts_map"].copy()
        else:
            job_df = pd.DataFrame({"code": ["JOB01"], "count": [1]})
        
        # ì»¬ëŸ¼ ë™ê¸°í™”
        for act in act_list:
            if act not in job_df.columns:
                job_df[act] = True
        
        if "count" not in job_df.columns:
            job_df["count"] = 1
        
        # ì—´ ìˆœì„œ ì •ë¦¬
        cols = ["code", "count"] + act_list
        job_df = job_df.reindex(columns=cols, fill_value=True)
        
        st.session_state["job_acts_map"] = job_df
        
        # í–‰ ì¶”ê°€/ì‚­ì œ ê¸°ëŠ¥
        col_add2, col_del2 = st.columns(2)
        
        with col_add2:
            if st.button("â• ì§ë¬´ ì½”ë“œ í–‰ ì¶”ê°€", key="add_job"):
                current = st.session_state["job_acts_map"].copy()
                
                # ìƒˆ ì½”ë“œ ìë™ ìƒì„±
                pattern = re.compile(r"^([A-Za-z]+)(\d+)$")
                prefixes, numbers = [], []
                for c in current["code"]:
                    m = pattern.match(str(c))
                    if m:
                        prefixes.append(m.group(1))
                        numbers.append(int(m.group(2)))
                
                if prefixes:
                    pref = pd.Series(prefixes).mode()[0]
                    max_num = max(n for p, n in zip(prefixes, numbers) if p == pref)
                    next_num = max_num + 1
                else:
                    pref, next_num = "JOB", 1
                
                new_code = f"{pref}{next_num:02d}"
                new_row = {"code": new_code, "count": 1, **{act: True for act in act_list}}
                
                current = pd.concat([current, pd.DataFrame([new_row])], ignore_index=True)
                st.session_state["job_acts_map"] = current
                st.success(f"'{new_code}' í–‰ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()
        
        with col_del2:
            codes = job_df["code"].tolist()
            to_delete2 = st.multiselect(
                "ì‚­ì œí•  ì½”ë“œ ì„ íƒ", 
                options=codes, 
                key="del_job_select"
            )
            
            if st.button("âŒ ì„ íƒ ì½”ë“œ ì‚­ì œ", key="del_job"):
                if to_delete2:
                    kept = job_df[~job_df["code"].isin(to_delete2)].reset_index(drop=True)
                    st.session_state["job_acts_map"] = kept
                    st.success("ì‚­ì œ ì™„ë£Œ!")
                    st.rerun()
        
        # í¸ì§‘ìš© AG-Grid
        df_to_display = st.session_state["job_acts_map"].copy()
        
        gb2 = GridOptionsBuilder.from_dataframe(df_to_display)
        gb2.configure_selection(selection_mode="none")
        gb2.configure_default_column(resizable=True, editable=True)
        
        gb2.configure_column("code", header_name="ì§ë¬´ ì½”ë“œ", width=120, editable=True)
        gb2.configure_column(
            "count", header_name="ì¸ì›ìˆ˜", type=["numericColumn"], width=90, editable=True
        )
        
        for act in act_list:
            gb2.configure_column(
                act,
                header_name=act,
                cellRenderer="agCheckboxCellRenderer",
                cellEditor="agCheckboxCellEditor",
                editable=True,
                singleClickEdit=True,
                width=110,
            )
        
        grid_opts2 = gb2.build()
        
        # ì„¹ì…˜ë³„ ìƒˆë¡œê³ ì¹¨ì„ ìœ„í•œ ë™ì  key ìƒì„±
        job_activities_refresh_count = st.session_state.get("section_refresh_counter", {}).get("job_activities", 0)
        
        grid_ret2 = AgGrid(
            df_to_display,
            gridOptions=grid_opts2,
            update_mode=GridUpdateMode.VALUE_CHANGED,
            data_return_mode=DataReturnMode.AS_INPUT,
            fit_columns_on_grid_load=True,
            theme="balham",
            key=f"job_grid_display_{job_activities_refresh_count}",  # ë™ì  keyë¡œ ê°•ì œ ì¬ë Œë”ë§
        )
        
        edited_df = pd.DataFrame(grid_ret2["data"])
        
        # ë°ì´í„° ê²€ì¦
        def validate_job_data(df: pd.DataFrame) -> tuple[pd.DataFrame, list[str]]:
            msgs: list[str] = []
            df = df.copy()
            df["code"] = df["code"].astype(str).str.strip()
            df["count"] = pd.to_numeric(df["count"], errors="coerce").fillna(0).astype(int)
            
            # ë¹ˆ ì½”ë“œ
            if (df["code"] == "").any():
                msgs.append("ë¹ˆ ì½”ë“œê°€ ìˆìŠµë‹ˆë‹¤.")
                df = df[df["code"] != ""].reset_index(drop=True)
            
            # ì¤‘ë³µ ì½”ë“œ
            dup_codes = df[df["code"].duplicated()]["code"].unique().tolist()
            if dup_codes:
                msgs.append(f"ì¤‘ë³µ ì½”ë“œ: {', '.join(dup_codes)}")
            
            # count â‰¤ 0
            zero_cnt = df[df["count"] <= 0]["code"].tolist()
            if zero_cnt:
                msgs.append(f"0 ì´í•˜ ì¸ì›ìˆ˜: {', '.join(map(str, zero_cnt))}")
            
            # í™œë™ì´ í•˜ë‚˜ë„ ì„ íƒë˜ì§€ ì•Šì€ í–‰
            no_act = [
                row.code
                for row in df.itertuples()
                if not any(getattr(row, a) for a in act_list)
            ]
            if no_act:
                msgs.append(f"ëª¨ë“  í™œë™ì´ Falseì¸ ì½”ë“œ: {', '.join(no_act)}")
            
            return df, msgs
        
        clean_df, errors = validate_job_data(edited_df)
        
        if errors:
            for msg in errors:
                st.error(msg)
        else:
            st.success("ëª¨ë“  ì…ë ¥ì´ ìœ íš¨í•©ë‹ˆë‹¤!")
        
        st.info(f"ì´ ì¸ì›ìˆ˜: **{clean_df['count'].sum()}** ëª…")
        st.session_state["job_acts_map"] = clean_df

st.divider()

# =============================================================================
# ì„¹ì…˜ 4: ìš´ì˜ ê³µê°„ ì„¤ì •
# =============================================================================
col_header, col_refresh = st.columns([3, 2])
with col_header:
    st.header("4ï¸âƒ£ ìš´ì˜ ê³µê°„ ì„¤ì •")
with col_refresh:
    st.markdown("<br>", unsafe_allow_html=True)  # í—¤ë”ì™€ ë†’ì´ ë§ì¶”ê¸°
    if st.button("ğŸ”„ ì„¹ì…˜ ìƒˆë¡œê³ ì¹¨", key="refresh_room_settings", help="ìš´ì˜ ê³µê°„ ì„¤ì • UIê°€ ë¨¹í†µì¼ ë•Œ ìƒˆë¡œê³ ì¹¨"):
        # ì„¹ì…˜ë³„ ìƒˆë¡œê³ ì¹¨
        if "section_refresh_counter" not in st.session_state:
            st.session_state["section_refresh_counter"] = {}
        if "room_settings" not in st.session_state["section_refresh_counter"]:
            st.session_state["section_refresh_counter"]["room_settings"] = 0
        st.session_state["section_refresh_counter"]["room_settings"] += 1
        st.rerun()

st.markdown("ë©´ì ‘ì„ ìš´ì˜í•  ê²½ìš°, í•˜ë£¨ì— ë™ì› ê°€ëŠ¥í•œ ëª¨ë“  ê³µê°„ì˜ ì¢…ë¥˜ì™€ ìˆ˜, ê·¸ë¦¬ê³  ìµœëŒ€ ìˆ˜ìš© ì¸ì›ì„ ì„¤ì •í•©ë‹ˆë‹¤.")

# í™œë™ DFì—ì„œ room_types í™•ë³´
acts_df = st.session_state.get("activities")
if acts_df is not None and not acts_df.empty:
    room_types = sorted(
        acts_df.query("use == True and room_type != '' and room_type.notna()")["room_type"].unique()
    )
    
    if room_types:
        min_cap_req = acts_df.set_index("room_type")["min_cap"].to_dict()
        max_cap_req = acts_df.set_index("room_type")["max_cap"].to_dict()
        
        # ê³µê°„ í…œí”Œë¦¿ ì„¤ì •
        tpl_dict = st.session_state.get("room_template", {})
        
        # room_types ë™ê¸°í™”
        for rt in room_types:
            tpl_dict.setdefault(rt, {"count": 1, "cap": max_cap_req.get(rt, 1)})
        for rt in list(tpl_dict):
            if rt not in room_types:
                tpl_dict.pop(rt)
        
        st.subheader("í•˜ë£¨ ê¸°ì¤€ ìš´ì˜ ê³µê°„ ì„¤ì •")
        
        # ì„¹ì…˜ë³„ ìƒˆë¡œê³ ì¹¨ì„ ìœ„í•œ ë™ì  key ìƒì„±
        room_settings_refresh_count = st.session_state.get("section_refresh_counter", {}).get("room_settings", 0)
        
        col_cnt, col_cap = st.columns(2, gap="large")
        
        with col_cnt:
            st.markdown("#### ë°© ê°œìˆ˜")
            for rt in room_types:
                tpl_dict[rt]["count"] = st.number_input(
                    f"{rt} ê°œìˆ˜", 
                    min_value=0, 
                    max_value=50, 
                    value=tpl_dict[rt].get("count", 1), 
                    key=f"tpl_{rt}_cnt_{room_settings_refresh_count}"  # ë™ì  keyë¡œ ê°•ì œ ì¬ë Œë”ë§
                )
        
        with col_cap:
            st.markdown("#### ìµœëŒ€ ë™ì‹œ ìˆ˜ìš© ì¸ì›")
            for rt in room_types:
                min_val = min_cap_req.get(rt, 1)
                max_val = max_cap_req.get(rt, 50)
                current_val = tpl_dict[rt].get("cap", max_val)
                safe_val = max(min_val, min(current_val, max_val))
                
                tpl_dict[rt]["cap"] = st.number_input(
                    f"{rt} ìµœëŒ€ ë™ì‹œ ìˆ˜ìš© ì¸ì›",
                    min_value=min_val,
                    max_value=max_val,
                    value=safe_val,
                    key=f"tpl_{rt}_cap_{room_settings_refresh_count}",  # ë™ì  keyë¡œ ê°•ì œ ì¬ë Œë”ë§
                )
        
        # ë³€ê²½ëœ í…œí”Œë¦¿ ì •ë³´ë¥¼ ì„¸ì…˜ì— ì €ì¥
        st.session_state['room_template'] = tpl_dict
        
        # room_plan ìƒì„± ë° ì €ì¥
        final_plan_dict = {}
        for rt, values in tpl_dict.items():
            final_plan_dict[f"{rt}_count"] = values['count']
            final_plan_dict[f"{rt}_cap"] = values['cap']
        
        st.session_state['room_plan'] = pd.DataFrame([final_plan_dict])
        
        # Room Plan â†’ Activities ì—­ë°©í–¥ ìë™ ì—°ë™
        activities_df = st.session_state.get("activities", pd.DataFrame())
        if not activities_df.empty:
            capacity_changed = False
            for rt, values in tpl_dict.items():
                new_capacity = values['cap']
                
                # í•´ë‹¹ room_typeì„ ì‚¬ìš©í•˜ëŠ” í™œë™ë“¤ì˜ max_cap ì—…ë°ì´íŠ¸
                room_activities = activities_df[activities_df["room_type"] == rt]
                for idx in room_activities.index:
                    current_max_cap = activities_df.at[idx, 'max_cap']
                    if current_max_cap != new_capacity:
                        activities_df.at[idx, 'max_cap'] = new_capacity
                        # min_capë„ ì¡°ì • (max_capë³´ë‹¤ í¬ë©´ ì•ˆë¨)
                        if activities_df.at[idx, 'min_cap'] > new_capacity:
                            activities_df.at[idx, 'min_cap'] = new_capacity
                        capacity_changed = True
            
            if capacity_changed:
                st.session_state["activities"] = activities_df
                st.info("ğŸ“ ë°© ìˆ˜ìš© ì¸ì› ë³€ê²½ì— ë”°ë¼ í™œë™ì˜ ê·¸ë£¹ í¬ê¸°ê°€ ìë™ ì¡°ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        with st.expander("ğŸ—‚ ì €ì¥ëœ room_plan ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
            st.dataframe(st.session_state.get('room_plan', pd.DataFrame()), use_container_width=True)
    else:
        st.error("ì‚¬ìš©(use=True)í•˜ë„ë¡ ì„¤ì •ëœ í™œë™ ì¤‘, 'room_type'ì´ ì§€ì •ëœ í™œë™ì´ ì—†ìŠµë‹ˆë‹¤.")

st.divider()

# =============================================================================
# ì„¹ì…˜ 5: ìš´ì˜ ì‹œê°„ ì„¤ì •
# =============================================================================
col_header, col_refresh = st.columns([3, 2])
with col_header:
    st.header("5ï¸âƒ£ ìš´ì˜ ì‹œê°„ ì„¤ì •")
with col_refresh:
    st.markdown("<br>", unsafe_allow_html=True)  # í—¤ë”ì™€ ë†’ì´ ë§ì¶”ê¸°
    if st.button("ğŸ”„ ì„¹ì…˜ ìƒˆë¡œê³ ì¹¨", key="refresh_time_settings", help="ìš´ì˜ ì‹œê°„ ì„¤ì • UIê°€ ë¨¹í†µì¼ ë•Œ ìƒˆë¡œê³ ì¹¨"):
        # ì„¹ì…˜ë³„ ìƒˆë¡œê³ ì¹¨
        if "section_refresh_counter" not in st.session_state:
            st.session_state["section_refresh_counter"] = {}
        if "time_settings" not in st.session_state["section_refresh_counter"]:
            st.session_state["section_refresh_counter"]["time_settings"] = 0
        st.session_state["section_refresh_counter"]["time_settings"] += 1
        st.rerun()

st.markdown("ë©´ì ‘ì„ ìš´ì˜í•  ê²½ìš°ì˜ í•˜ë£¨ ê¸°ì¤€ ìš´ì˜ ì‹œì‘ ë° ì¢…ë£Œ ì‹œê°„ì„ ì„¤ì •í•©ë‹ˆë‹¤.")

# ê¸°ì¡´ ê°’ ë¶ˆëŸ¬ì˜¤ê¸°
init_start = st.session_state.get("oper_start_time", time(9, 0))
init_end = st.session_state.get("oper_end_time", time(18, 0))

st.subheader("í•˜ë£¨ ê¸°ì¤€ ê³µí†µ ìš´ì˜ ì‹œê°„")

# ì„¹ì…˜ë³„ ìƒˆë¡œê³ ì¹¨ì„ ìœ„í•œ ë™ì  key ìƒì„±
time_settings_refresh_count = st.session_state.get("section_refresh_counter", {}).get("time_settings", 0)

col_start, col_end = st.columns(2)

with col_start:
    t_start = st.time_input("ìš´ì˜ ì‹œì‘ ì‹œê°„", value=init_start, key=f"oper_start_{time_settings_refresh_count}")

with col_end:
    t_end = st.time_input("ìš´ì˜ ì¢…ë£Œ ì‹œê°„", value=init_end, key=f"oper_end_{time_settings_refresh_count}")

if t_start >= t_end:
    st.error("ì˜¤ë¥˜: ìš´ì˜ ì‹œì‘ ì‹œê°„ì€ ì¢…ë£Œ ì‹œê°„ë³´ë‹¤ ë¹¨ë¼ì•¼ í•©ë‹ˆë‹¤.")
else:
    # ì„¤ì •ëœ ì‹œê°„ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
    st.session_state["oper_start_time"] = t_start
    st.session_state["oper_end_time"] = t_end
    
    # oper_window DataFrame ìƒì„± ë° ì €ì¥
    oper_window_dict = {
        "start_time": t_start.strftime("%H:%M"),
        "end_time": t_end.strftime("%H:%M")
    }
    st.session_state['oper_window'] = pd.DataFrame([oper_window_dict])
    
    with st.expander("ğŸ—‚ ì €ì¥ëœ oper_window ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
        st.dataframe(st.session_state.get('oper_window', pd.DataFrame()), use_container_width=True)
    
    st.success(f"ìš´ì˜ ì‹œê°„ì´ {t_start.strftime('%H:%M')}ë¶€í„° {t_end.strftime('%H:%M')}ê¹Œì§€ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")

st.divider()

# ìœ„ë¡œ ê°€ê¸° ê¸°ëŠ¥
st.markdown("---")

# ì¤‘ì•™ ë§í¬ ë°©ì‹
st.markdown("""
<div style="text-align: center; margin: 20px 0;">
    <a href="#top" style="
        display: inline-block;
        background: linear-gradient(90deg, #ff6b6b, #4ecdc4);
        color: white;
        text-decoration: none;
        padding: 12px 24px;
        border-radius: 25px;
        font-weight: bold;
        box-shadow: 0 4px 15px rgba(0,0,0,0.2);
        transition: all 0.3s ease;
    ">
        â¬†ï¸ ë¹ ë¥¸ ì´ë™: ë§¨ ìœ„ë¡œ
    </a>
</div>
""", unsafe_allow_html=True)

# ìš°í•˜ë‹¨ ê³ ì • ë²„íŠ¼ (ê°œì„ ëœ ë²„ì „)
st.markdown("""
<style>
    .floating-top-button {
        position: fixed;
        bottom: 30px;
        right: 30px;
        z-index: 999;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 50%;
        width: 60px;
        height: 60px;
        font-size: 20px;
        cursor: pointer;
        box-shadow: 0 4px 20px rgba(0,0,0,0.3);
        transition: all 0.3s ease;
        display: flex;
        align-items: center;
        justify-content: center;
        text-decoration: none;
    }
    
    .floating-top-button:hover {
        transform: translateY(-3px) scale(1.1);
        box-shadow: 0 6px 25px rgba(0,0,0,0.4);
        background: linear-gradient(135deg, #764ba2 0%, #667eea 100%);
    }
    
    .floating-top-button:active {
        transform: translateY(-1px) scale(1.05);
    }
</style>

<a href="#top" class="floating-top-button" title="ë§¨ ìœ„ë¡œ ì´ë™">
    â¬†ï¸
</a>
""", unsafe_allow_html=True)

# ì„¹ì…˜ 6ì€ ì„¹ì…˜ 1 ì•„ë˜ë¡œ ì´ë™ë¨