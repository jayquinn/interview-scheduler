#!/usr/bin/env python3
"""
ì²´ë¥˜ ì‹œê°„ í•˜ë“œ ì œì•½ í†µê³„ì  ê¸°ì¤€ ë¶„ì„
ì‘ì‹œì ì²´ë¥˜ ì‹œê°„ì˜ ìƒí•œì„ í†µê³„ì  ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •í•˜ëŠ” ë°©ë²•ë“¤ì„ ê²€í† 
"""

import pandas as pd
import numpy as np
from scipy import stats
from typing import Dict, List, Tuple
import warnings
warnings.filterwarnings('ignore')

class StayTimeConstraintAnalyzer:
    """ì²´ë¥˜ ì‹œê°„ ì œì•½ ë¶„ì„ê¸°"""
    
    def __init__(self, data_file: str = 'stay_time_individual_stats.xlsx'):
        """ì´ˆê¸°í™”"""
        self.df = pd.read_excel(data_file)
        self.stay_minutes = self.df['stay_duration_minutes'].values
        self.stay_hours = self.stay_minutes / 60
        
        print(f"ğŸ“Š ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.df)}ëª… ì§€ì›ì")
        print(f"  - í‰ê·  ì²´ë¥˜ì‹œê°„: {np.mean(self.stay_hours):.1f}ì‹œê°„")
        print(f"  - ìµœëŒ€ ì²´ë¥˜ì‹œê°„: {np.max(self.stay_hours):.1f}ì‹œê°„")
        print(f"  - í‘œì¤€í¸ì°¨: {np.std(self.stay_hours):.1f}ì‹œê°„")
    
    def analyze_basic_statistics(self) -> Dict:
        """ê¸°ë³¸ í†µê³„ ë¶„ì„"""
        print("\nğŸ“ˆ ê¸°ë³¸ í†µê³„ ë¶„ì„")
        print("=" * 50)
        
        stats_dict = {
            'count': len(self.stay_hours),
            'mean': np.mean(self.stay_hours),
            'median': np.median(self.stay_hours),
            'std': np.std(self.stay_hours),
            'min': np.min(self.stay_hours),
            'max': np.max(self.stay_hours),
            'q25': np.percentile(self.stay_hours, 25),
            'q75': np.percentile(self.stay_hours, 75),
            'q90': np.percentile(self.stay_hours, 90),
            'q95': np.percentile(self.stay_hours, 95),
            'q99': np.percentile(self.stay_hours, 99)
        }
        
        print(f"  í‰ê· : {stats_dict['mean']:.1f}ì‹œê°„")
        print(f"  ì¤‘ê°„ê°’: {stats_dict['median']:.1f}ì‹œê°„")
        print(f"  í‘œì¤€í¸ì°¨: {stats_dict['std']:.1f}ì‹œê°„")
        print(f"  75% ë¶„ìœ„ìˆ˜: {stats_dict['q75']:.1f}ì‹œê°„")
        print(f"  90% ë¶„ìœ„ìˆ˜: {stats_dict['q90']:.1f}ì‹œê°„")
        print(f"  95% ë¶„ìœ„ìˆ˜: {stats_dict['q95']:.1f}ì‹œê°„")
        print(f"  99% ë¶„ìœ„ìˆ˜: {stats_dict['q99']:.1f}ì‹œê°„")
        
        return stats_dict
    
    def analyze_job_based_constraints(self) -> Dict:
        """ì§ë¬´ë³„ ê¸°ë°˜ ì œì•½ ë¶„ì„"""
        print("\nğŸ¢ ì§ë¬´ë³„ ê¸°ë°˜ ì œì•½ ë¶„ì„")
        print("=" * 50)
        
        job_stats = self.df.groupby('job_code')['stay_duration_minutes'].agg([
            'count', 'mean', 'median', 'std', 'min', 'max',
            lambda x: np.percentile(x, 90),
            lambda x: np.percentile(x, 95)
        ]).round(1)
        
        job_stats.columns = ['count', 'mean', 'median', 'std', 'min', 'max', 'q90', 'q95']
        job_stats['mean_hours'] = job_stats['mean'] / 60
        job_stats['q90_hours'] = job_stats['q90'] / 60
        job_stats['q95_hours'] = job_stats['q95'] / 60
        
        print("ì§ë¬´ë³„ ì²´ë¥˜ì‹œê°„ í†µê³„ (ì‹œê°„ ë‹¨ìœ„):")
        print(job_stats[['count', 'mean_hours', 'q90_hours', 'q95_hours', 'max']].round(1))
        
        # ì§ë¬´ë³„ ê¶Œì¥ ì œì•½
        recommendations = {}
        for job_code in job_stats.index:
            q95_hours = job_stats.loc[job_code, 'q95_hours']
            max_hours = job_stats.loc[job_code, 'max'] / 60
            
            # 95% ë¶„ìœ„ìˆ˜ + ì—¬ìœ ë¶„ (30ë¶„)
            recommended_constraint = min(q95_hours + 0.5, max_hours)
            
            recommendations[job_code] = {
                'q95_hours': q95_hours,
                'max_hours': max_hours,
                'recommended_constraint': recommended_constraint,
                'coverage_rate': len(self.df[(self.df['job_code'] == job_code) & 
                                           (self.df['stay_duration_minutes'] <= recommended_constraint * 60)]) / 
                                len(self.df[self.df['job_code'] == job_code]) * 100
            }
        
        print("\nì§ë¬´ë³„ ê¶Œì¥ í•˜ë“œ ì œì•½:")
        for job_code, rec in recommendations.items():
            print(f"  {job_code}: {rec['recommended_constraint']:.1f}ì‹œê°„ "
                  f"(95% ë¶„ìœ„ìˆ˜: {rec['q95_hours']:.1f}ì‹œê°„, ì»¤ë²„ë¦¬ì§€: {rec['coverage_rate']:.1f}%)")
        
        return recommendations
    
    def analyze_percentile_based_constraints(self) -> Dict:
        """ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ì œì•½ ë¶„ì„"""
        print("\nğŸ“Š ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ì œì•½ ë¶„ì„")
        print("=" * 50)
        
        percentiles = [85, 90, 92, 95, 97, 98, 99]
        constraints = {}
        
        for p in percentiles:
            constraint_hours = np.percentile(self.stay_hours, p)
            coverage_count = np.sum(self.stay_hours <= constraint_hours)
            coverage_rate = coverage_count / len(self.stay_hours) * 100
            
            constraints[p] = {
                'constraint_hours': constraint_hours,
                'coverage_count': coverage_count,
                'coverage_rate': coverage_rate,
                'excluded_count': len(self.stay_hours) - coverage_count
            }
        
        print("ë¶„ìœ„ìˆ˜ë³„ í•˜ë“œ ì œì•½ ë¶„ì„:")
        for p, data in constraints.items():
            print(f"  {p}% ë¶„ìœ„ìˆ˜: {data['constraint_hours']:.1f}ì‹œê°„ "
                  f"(ì»¤ë²„ë¦¬ì§€: {data['coverage_rate']:.1f}%, ì œì™¸: {data['excluded_count']}ëª…)")
        
        return constraints
    
    def analyze_standard_deviation_based_constraints(self) -> Dict:
        """í‘œì¤€í¸ì°¨ ê¸°ë°˜ ì œì•½ ë¶„ì„"""
        print("\nğŸ“ í‘œì¤€í¸ì°¨ ê¸°ë°˜ ì œì•½ ë¶„ì„")
        print("=" * 50)
        
        mean_hours = np.mean(self.stay_hours)
        std_hours = np.std(self.stay_hours)
        
        std_constraints = {}
        for std_multiplier in [1.5, 2.0, 2.5, 3.0]:
            constraint_hours = mean_hours + (std_multiplier * std_hours)
            coverage_count = np.sum(self.stay_hours <= constraint_hours)
            coverage_rate = coverage_count / len(self.stay_hours) * 100
            
            std_constraints[std_multiplier] = {
                'constraint_hours': constraint_hours,
                'coverage_count': coverage_count,
                'coverage_rate': coverage_rate,
                'excluded_count': len(self.stay_hours) - coverage_count
            }
        
        print("í‘œì¤€í¸ì°¨ ê¸°ë°˜ í•˜ë“œ ì œì•½ ë¶„ì„:")
        for std_mult, data in std_constraints.items():
            print(f"  í‰ê·  + {std_mult}Ïƒ: {data['constraint_hours']:.1f}ì‹œê°„ "
                  f"(ì»¤ë²„ë¦¬ì§€: {data['coverage_rate']:.1f}%, ì œì™¸: {data['excluded_count']}ëª…)")
        
        return std_constraints
    
    def analyze_outlier_based_constraints(self) -> Dict:
        """ì´ìƒì¹˜ ê¸°ë°˜ ì œì•½ ë¶„ì„"""
        print("\nğŸ” ì´ìƒì¹˜ ê¸°ë°˜ ì œì•½ ë¶„ì„")
        print("=" * 50)
        
        # IQR ë°©ë²•ìœ¼ë¡œ ì´ìƒì¹˜ íƒì§€
        Q1 = np.percentile(self.stay_hours, 25)
        Q3 = np.percentile(self.stay_hours, 75)
        IQR = Q3 - Q1
        
        # ì´ìƒì¹˜ ê¸°ì¤€
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        # ìˆ˜ì •ëœ Z-score ë°©ë²•
        median_hours = np.median(self.stay_hours)
        mad = np.median(np.abs(self.stay_hours - median_hours))
        modified_z_scores = 0.6745 * (self.stay_hours - median_hours) / mad
        
        outlier_indices = np.abs(modified_z_scores) > 3.5
        
        outlier_constraints = {
            'iqr_upper_bound': upper_bound,
            'iqr_outlier_count': np.sum(self.stay_hours > upper_bound),
            'modified_z_outlier_count': np.sum(outlier_indices),
            'modified_z_threshold': median_hours + 3.5 * mad / 0.6745
        }
        
        print(f"IQR ìƒí•œ: {upper_bound:.1f}ì‹œê°„ (ì´ìƒì¹˜: {outlier_constraints['iqr_outlier_count']}ëª…)")
        print(f"ìˆ˜ì • Z-score ì„ê³„ê°’: {outlier_constraints['modified_z_threshold']:.1f}ì‹œê°„ "
              f"(ì´ìƒì¹˜: {outlier_constraints['modified_z_outlier_count']}ëª…)")
        
        return outlier_constraints
    
    def analyze_adaptive_constraints(self) -> Dict:
        """ì ì‘í˜• ì œì•½ ë¶„ì„"""
        print("\nğŸ”„ ì ì‘í˜• ì œì•½ ë¶„ì„")
        print("=" * 50)
        
        # ì§ë¬´ë³„ ê°€ì¤‘ í‰ê· 
        job_weights = self.df.groupby('job_code').size() / len(self.df)
        
        # ì§ë¬´ë³„ 95% ë¶„ìœ„ìˆ˜ ê³„ì‚°
        job_q95 = {}
        for job_code in self.df['job_code'].unique():
            job_data = self.df[self.df['job_code'] == job_code]['stay_duration_minutes'] / 60
            job_q95[job_code] = np.percentile(job_data, 95)
        
        # ê°€ì¤‘ í‰ê·  ì œì•½
        weighted_constraint = sum(job_q95[job] * job_weights[job] for job in job_q95.keys())
        
        # ì „ì²´ 95% ë¶„ìœ„ìˆ˜
        overall_q95 = np.percentile(self.stay_hours, 95)
        
        # ì ì‘í˜• ì œì•½ (ê°€ì¤‘ í‰ê·  + ì „ì²´ ë¶„ìœ„ìˆ˜ì˜ ì¡°í•©)
        adaptive_constraint = 0.7 * weighted_constraint + 0.3 * overall_q95
        
        adaptive_constraints = {
            'weighted_constraint': weighted_constraint,
            'overall_q95': overall_q95,
            'adaptive_constraint': adaptive_constraint,
            'coverage_rate': np.sum(self.stay_hours <= adaptive_constraint) / len(self.stay_hours) * 100
        }
        
        print(f"ê°€ì¤‘ í‰ê·  ì œì•½: {weighted_constraint:.1f}ì‹œê°„")
        print(f"ì „ì²´ 95% ë¶„ìœ„ìˆ˜: {overall_q95:.1f}ì‹œê°„")
        print(f"ì ì‘í˜• ì œì•½: {adaptive_constraint:.1f}ì‹œê°„ (ì»¤ë²„ë¦¬ì§€: {adaptive_constraints['coverage_rate']:.1f}%)")
        
        return adaptive_constraints
    
    def recommend_constraint_strategies(self) -> Dict:
        """ì œì•½ ì „ëµ ê¶Œì¥"""
        print("\nğŸ¯ í•˜ë“œ ì œì•½ ì „ëµ ê¶Œì¥")
        print("=" * 50)
        
        # ê° ë°©ë²•ë³„ ë¶„ì„ ì‹¤í–‰
        basic_stats = self.analyze_basic_statistics()
        job_constraints = self.analyze_job_based_constraints()
        percentile_constraints = self.analyze_percentile_based_constraints()
        std_constraints = self.analyze_standard_deviation_based_constraints()
        outlier_constraints = self.analyze_outlier_based_constraints()
        adaptive_constraints = self.analyze_adaptive_constraints()
        
        # ì „ëµë³„ ê¶Œì¥ì‚¬í•­
        strategies = {
            'conservative': {
                'method': '95% ë¶„ìœ„ìˆ˜',
                'constraint': percentile_constraints[95]['constraint_hours'],
                'coverage': percentile_constraints[95]['coverage_rate'],
                'description': 'ë³´ìˆ˜ì  ì ‘ê·¼ - 95% ì§€ì›ì ì»¤ë²„'
            },
            'balanced': {
                'method': 'ì ì‘í˜• ì œì•½',
                'constraint': adaptive_constraints['adaptive_constraint'],
                'coverage': adaptive_constraints['coverage_rate'],
                'description': 'ê· í˜•ì  ì ‘ê·¼ - ì§ë¬´ë³„ íŠ¹ì„± ë°˜ì˜'
            },
            'aggressive': {
                'method': '90% ë¶„ìœ„ìˆ˜',
                'constraint': percentile_constraints[90]['constraint_hours'],
                'coverage': percentile_constraints[90]['coverage_rate'],
                'description': 'ì ê·¹ì  ì ‘ê·¼ - 90% ì§€ì›ì ì»¤ë²„'
            },
            'outlier_based': {
                'method': 'ì´ìƒì¹˜ ì œê±°',
                'constraint': outlier_constraints['modified_z_threshold'],
                'coverage': np.sum(self.stay_hours <= outlier_constraints['modified_z_threshold']) / len(self.stay_hours) * 100,
                'description': 'ì´ìƒì¹˜ ê¸°ë°˜ - í†µê³„ì  ì´ìƒì¹˜ ì œê±°'
            }
        }
        
        print("ê¶Œì¥ ì „ëµ:")
        for strategy_name, strategy_data in strategies.items():
            print(f"  {strategy_name.upper()}: {strategy_data['constraint']:.1f}ì‹œê°„ "
                  f"(ì»¤ë²„ë¦¬ì§€: {strategy_data['coverage']:.1f}%)")
            print(f"    â†’ {strategy_data['description']}")
        
        return strategies
    
    def generate_implementation_formula(self) -> str:
        """êµ¬í˜„ ê³µì‹ ìƒì„±"""
        print("\nğŸ“ êµ¬í˜„ ê³µì‹")
        print("=" * 50)
        
        # ë™ì  ì œì•½ ê³„ì‚° ê³µì‹
        formula = """
# ë™ì  ì²´ë¥˜ì‹œê°„ í•˜ë“œ ì œì•½ ê³„ì‚° ê³µì‹

def calculate_dynamic_stay_constraint(stay_times_data, strategy='balanced'):
    '''
    ì²´ë¥˜ì‹œê°„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë™ì  í•˜ë“œ ì œì•½ ê³„ì‚°
    
    Parameters:
    - stay_times_data: ì²´ë¥˜ì‹œê°„ ë°ì´í„° (ì‹œê°„ ë‹¨ìœ„)
    - strategy: ì „ëµ ('conservative', 'balanced', 'aggressive', 'outlier_based')
    
    Returns:
    - constraint_hours: ê¶Œì¥ í•˜ë“œ ì œì•½ (ì‹œê°„)
    '''
    
    if strategy == 'conservative':
        # 95% ë¶„ìœ„ìˆ˜ ê¸°ë°˜
        return np.percentile(stay_times_data, 95)
    
    elif strategy == 'balanced':
        # ì§ë¬´ë³„ ê°€ì¤‘ í‰ê·  + ì „ì²´ ë¶„ìœ„ìˆ˜ ì¡°í•©
        job_weights = job_data.groupby('job_code').size() / len(job_data)
        job_q95 = job_data.groupby('job_code')['stay_hours'].quantile(0.95)
        weighted_constraint = sum(job_q95[job] * job_weights[job] for job in job_q95.index)
        overall_q95 = np.percentile(stay_times_data, 95)
        return 0.7 * weighted_constraint + 0.3 * overall_q95
    
    elif strategy == 'aggressive':
        # 90% ë¶„ìœ„ìˆ˜ ê¸°ë°˜
        return np.percentile(stay_times_data, 90)
    
    elif strategy == 'outlier_based':
        # ìˆ˜ì •ëœ Z-score ê¸°ë°˜ ì´ìƒì¹˜ ì œê±°
        median_hours = np.median(stay_times_data)
        mad = np.median(np.abs(stay_times_data - median_hours))
        return median_hours + 3.5 * mad / 0.6745
    
    else:
        raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” ì „ëµì…ë‹ˆë‹¤.")

# ì‚¬ìš© ì˜ˆì‹œ
constraint = calculate_dynamic_stay_constraint(stay_hours, strategy='balanced')
print(f"ê¶Œì¥ í•˜ë“œ ì œì•½: {constraint:.1f}ì‹œê°„")
"""
        
        print(formula)
        return formula

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("ğŸ” ì²´ë¥˜ì‹œê°„ í•˜ë“œ ì œì•½ í†µê³„ì  ê¸°ì¤€ ë¶„ì„")
    print("=" * 80)
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = StayTimeConstraintAnalyzer()
    
    # ì „ëµ ê¶Œì¥
    strategies = analyzer.recommend_constraint_strategies()
    
    # êµ¬í˜„ ê³µì‹ ìƒì„±
    analyzer.generate_implementation_formula()
    
    print("\nâœ… ë¶„ì„ ì™„ë£Œ!")
    print("\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
    print("1. ì´ˆê¸°ì—ëŠ” 'balanced' ì „ëµ ì‚¬ìš© (ì§ë¬´ë³„ íŠ¹ì„± ë°˜ì˜)")
    print("2. ìš´ì˜ ê²½í—˜ ì¶•ì  í›„ 'conservative' ë˜ëŠ” 'aggressive'ë¡œ ì¡°ì •")
    print("3. ì •ê¸°ì ìœ¼ë¡œ ë°ì´í„° ì¬ë¶„ì„í•˜ì—¬ ì œì•½ê°’ ì—…ë°ì´íŠ¸")
    print("4. ì§ë¬´ë³„ ì°¨ì´ê°€ í´ ê²½ìš° ì§ë¬´ë³„ ê°œë³„ ì œì•½ ê³ ë ¤")

if __name__ == "__main__":
    main() 