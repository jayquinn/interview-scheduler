#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
app.py ë””í´íŠ¸ ë°ì´í„° ìµœì í™”ëœ CP-SAT í…ŒìŠ¤íŠ¸
- ë³‘ëª© ë¶„ì„ ê²°ê³¼ ë°˜ì˜
- ë¡œê¹… ìµœì†Œí™”
- ë¹ ë¥¸ ìŠ¤ì¼€ì¤„ë§
"""

import logging
import sys
import os
from datetime import datetime, timedelta
import pandas as pd
from typing import Tuple

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from solver.api import schedule_interviews
from solver.types import SchedulingContext

# ë¡œê¹… ì„¤ì • (ìµœì†Œí™”)
def setup_logging():
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_filename = f"log/cpsat_optimized_{timestamp}.log"
    
    os.makedirs("log", exist_ok=True)
    
    logger = logging.getLogger()
    logger.setLevel(logging.WARNING)  # INFO â†’ WARNINGìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ë¡œê·¸ ìµœì†Œí™”
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬ (UTF-8 ì¸ì½”ë”©)
    file_handler = logging.FileHandler(log_filename, encoding='utf-8')
    file_handler.setLevel(logging.WARNING)
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)
    
    # í¬ë§·í„°
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)
    
    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)
    
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger

def get_app_default_data():
    """app.pyì˜ ë””í´íŠ¸ ë°ì´í„° ë°˜í™˜"""
    # ë‚ ì§œë³„ ê³„íš
    date_plans = {
        "2025-07-15": {
            "jobs": {"JOB01": 23, "JOB02": 23},
            "selected_activities": ["í† ë¡ ë©´ì ‘", "ë°œí‘œì¤€ë¹„", "ë°œí‘œë©´ì ‘"]
        },
        "2025-07-16": {
            "jobs": {"JOB03": 23, "JOB04": 23},
            "selected_activities": ["í† ë¡ ë©´ì ‘", "ë°œí‘œì¤€ë¹„", "ë°œí‘œë©´ì ‘"]
        },
        "2025-07-17": {
            "jobs": {"JOB05": 23, "JOB06": 23},
            "selected_activities": ["í† ë¡ ë©´ì ‘", "ë°œí‘œì¤€ë¹„", "ë°œí‘œë©´ì ‘"]
        },
        "2025-07-18": {
            "jobs": {"JOB07": 23},
            "selected_activities": ["í† ë¡ ë©´ì ‘", "ë°œí‘œì¤€ë¹„", "ë°œí‘œë©´ì ‘"]
        }
    }
    
    # í™œë™ ì •ì˜
    activities = {
        "í† ë¡ ë©´ì ‘": {
            "mode": "batched",
            "duration_min": 30,
            "room_type": "í† ë¡ ë©´ì ‘ì‹¤",
            "min_capacity": 4,
            "max_capacity": 6
        },
        "ë°œí‘œì¤€ë¹„": {
            "mode": "parallel",
            "duration_min": 5,
            "room_type": "ë°œí‘œì¤€ë¹„ì‹¤",
            "min_capacity": 1,
            "max_capacity": 2
        },
        "ë°œí‘œë©´ì ‘": {
            "mode": "individual",
            "duration_min": 15,
            "room_type": "ë°œí‘œë©´ì ‘ì‹¤",
            "min_capacity": 1,
            "max_capacity": 1
        }
    }
    
    # ë°© ì •ì˜
    rooms = {
        "í† ë¡ ë©´ì ‘ì‹¤A": {"type": "í† ë¡ ë©´ì ‘ì‹¤", "capacity": 6},
        "í† ë¡ ë©´ì ‘ì‹¤B": {"type": "í† ë¡ ë©´ì ‘ì‹¤", "capacity": 6},
        "ë°œí‘œì¤€ë¹„ì‹¤": {"type": "ë°œí‘œì¤€ë¹„ì‹¤", "capacity": 2},
        "ë°œí‘œë©´ì ‘ì‹¤A": {"type": "ë°œí‘œë©´ì ‘ì‹¤", "capacity": 1},
        "ë°œí‘œë©´ì ‘ì‹¤B": {"type": "ë°œí‘œë©´ì ‘ì‹¤", "capacity": 1}
    }
    
    # ì „ì—­ ì„¤ì •
    global_config = {
        "operating_hours": {
            "2025-07-15": ("09:00", "17:30"),
            "2025-07-16": ("09:00", "17:30"),
            "2025-07-17": ("09:00", "17:30"),
            "2025-07-18": ("09:00", "17:30")
        },
        "precedence_rules": [
            {"predecessor": "ë°œí‘œì¤€ë¹„", "successor": "ë°œí‘œë©´ì ‘", "gap_min": 0, "is_adjacent": True}
        ],
        "batched_group_sizes": {
            "í† ë¡ ë©´ì ‘": (4, 6)
        },
        "global_gap_min": 5,
        "max_stay_hours": 8
    }
    
    return date_plans, activities, rooms, global_config

def schedule_single_date_optimized(date_str: str, date_plan: dict, global_config: dict, 
                                 rooms: dict, activities: dict, logger: logging.Logger) -> Tuple[pd.DataFrame, bool]:
    """ë‹¨ì¼ ë‚ ì§œ ìµœì í™”ëœ ìŠ¤ì¼€ì¤„ë§"""
    logger.info(f"ğŸ“… [{date_str}] ì²˜ë¦¬ ì‹œì‘ ({sum(date_plan['jobs'].values())}ëª…)")
    
    try:
        # ìµœì í™”ëœ ì»¨í…ìŠ¤íŠ¸ (15ì´ˆ ì œí•œ, ë¡œê¹… ìµœì†Œí™”)
        context = SchedulingContext(
            time_limit_sec=15.0,  # 30ì´ˆ â†’ 15ì´ˆë¡œ ë‹¨ì¶•
            debug=False  # ë””ë²„ê·¸ ë¡œê¹… ë¹„í™œì„±í™”
        )
        
        # ì‹œê°„ ì¸¡ì • ì‹œì‘
        start_time = datetime.now()
        logger.info(f"â±ï¸ [{date_str}] CP-SAT ì‹œì‘: {start_time}")
        
        # schedule_interviews í˜¸ì¶œ
        result = schedule_interviews(
            date_plans={date_str: date_plan},
            global_config=global_config,
            rooms=rooms,
            activities=activities,
            logger=logger,
            context=context
        )
        
        # ì‹œê°„ ì¸¡ì • ì¢…ë£Œ
        end_time = datetime.now()
        elapsed = (end_time - start_time).total_seconds()
        logger.info(f"â±ï¸ [{date_str}] CP-SAT ì™„ë£Œ: {end_time} (ì†Œìš”ì‹œê°„: {elapsed:.2f}ì´ˆ)")
        
        # resultê°€ dictì¸ ê²½ìš° ì²˜ë¦¬
        if isinstance(result, dict):
            status = result.get('status', 'UNKNOWN')
            if status == "SUCCESS":
                df = result.get('schedule', pd.DataFrame())
                scheduled_applicants = result.get('summary', {}).get('scheduled_applicants', 0)
                total_applicants = result.get('summary', {}).get('total_applicants', 0)
                logger.info(f"âœ… [{date_str}] ì„±ê³µ! {scheduled_applicants}/{total_applicants}ëª… ìŠ¤ì¼€ì¤„ë§")
                return df, True
            elif status in ["PARTIAL", "FAILED"]:
                # ë¶€ë¶„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ë°˜í™˜
                partial_df = result.get('partial_schedule')
                if partial_df is not None and not partial_df.empty:
                    scheduled_applicants = result.get('scheduled_applicants', 0)
                    total_applicants = result.get('total_applicants', 0)
                    logger.info(f"âš ï¸ [{date_str}] ë¶€ë¶„ ì„±ê³µ! {scheduled_applicants}/{total_applicants}ëª… ìŠ¤ì¼€ì¤„ë§")
                    return partial_df, True
                else:
                    logger.error(f"âŒ [{date_str}] ì‹¤íŒ¨: {status}")
                    return pd.DataFrame(), False
            else:
                logger.error(f"âŒ [{date_str}] ì•Œ ìˆ˜ ì—†ëŠ” ìƒíƒœ: {status}")
                return pd.DataFrame(), False
        else:
            # MultiDateResult ê°ì²´ì¸ ê²½ìš° (ê¸°ì¡´ ë¡œì§)
            if result.status == "SUCCESS":
                logger.info(f"âœ… [{date_str}] ì„±ê³µ! {result.scheduled_applicants}/{result.total_applicants}ëª… ìŠ¤ì¼€ì¤„ë§")
                df = result.to_dataframe()
                return df, True
            elif result.status == "PARTIAL":
                logger.info(f"âš ï¸ [{date_str}] ë¶€ë¶„ ì„±ê³µ! {result.scheduled_applicants}/{result.total_applicants}ëª… ìŠ¤ì¼€ì¤„ë§")
                df = result.to_dataframe()
                return df, True
            else:
                logger.error(f"âŒ [{date_str}] ì‹¤íŒ¨: {result.status}")
                # ì‹¤íŒ¨í•´ë„ ë¶€ë¶„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ë°˜í™˜
                if hasattr(result, 'to_dataframe'):
                    df = result.to_dataframe()
                    if not df.empty:
                        logger.info(f"ğŸ“Š [{date_str}] ë¶€ë¶„ ê²°ê³¼ ë°˜í™˜: {len(df)}ê°œ í•­ëª©")
                        return df, False
                return pd.DataFrame(), False
            
    except Exception as e:
        logger.error(f"ğŸ’¥ [{date_str}] ì˜ˆì™¸ ë°œìƒ: {str(e)}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return pd.DataFrame(), False

def save_partial_results(all_results, filename):
    """ë¶€ë¶„ ê²°ê³¼ë¥¼ ì—‘ì…€ë¡œ ì €ì¥"""
    if not all_results:
        print("âŒ ì €ì¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ëª¨ë“  ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ í†µí•©
    all_dfs = []
    for date_str, (df, success) in all_results.items():
        if not df.empty:
            all_dfs.append(df)
    
    if not all_dfs:
        print("âŒ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    final_df = pd.concat(all_dfs, ignore_index=True)
    
    # ì—‘ì…€ë¡œ ì €ì¥
    try:
        with pd.ExcelWriter(filename, engine='openpyxl') as writer:
            # ì „ì²´ ìŠ¤ì¼€ì¤„
            final_df.to_excel(writer, sheet_name='ì „ì²´ìŠ¤ì¼€ì¤„', index=False)
            
            # ë‚ ì§œë³„ ìŠ¤ì¼€ì¤„
            for date_str, (df, success) in all_results.items():
                if not df.empty:
                    sheet_name = f"{date_str.replace('-', '')}"
                    df.to_excel(writer, sheet_name=sheet_name, index=False)
            
            # ìš”ì•½ ì •ë³´
            summary_data = []
            for date_str, (df, success) in all_results.items():
                summary_data.append({
                    'ë‚ ì§œ': date_str,
                    'ì„±ê³µì—¬ë¶€': 'ì„±ê³µ' if success else 'ë¶€ë¶„ì„±ê³µ',
                    'ìŠ¤ì¼€ì¤„ìˆ˜': len(df) if not df.empty else 0
                })
            
            summary_df = pd.DataFrame(summary_data)
            summary_df.to_excel(writer, sheet_name='ìš”ì•½', index=False)
        
        print(f"âœ… ì—‘ì…€ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename}")
        print(f"ğŸ“Š ì´ {len(final_df)}ê°œ ìŠ¤ì¼€ì¤„ ì €ì¥")
        
    except Exception as e:
        print(f"âŒ ì—‘ì…€ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    logger = setup_logging()
    
    print("=== app.py ë””í´íŠ¸ ë°ì´í„° ìµœì í™”ëœ CP-SAT í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    # app.py ë””í´íŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    date_plans, activities, rooms, global_config = get_app_default_data()
    
    total_applicants = sum(sum(plan['jobs'].values()) for plan in date_plans.values())
    print(f"ì´ ì§€ì›ì: {total_applicants}ëª…, ë‚ ì§œ: {len(date_plans)}ì¼")
    
    # ë‚ ì§œë³„ ìˆœì°¨ ì²˜ë¦¬ (ë³‘ëª© ë¶„ì„ ê²°ê³¼ ë°˜ì˜)
    all_results = {}
    
    for date_str, date_plan in date_plans.items():
        print(f"\nğŸ“… {date_str} ì²˜ë¦¬ ì¤‘...")
        
        # ë‹¨ì¼ ë‚ ì§œ ìŠ¤ì¼€ì¤„ë§
        df, success = schedule_single_date_optimized(
            date_str, date_plan, global_config, rooms, activities, logger
        )
        
        all_results[date_str] = (df, success)
        
        # ë¶€ë¶„ ê²°ê³¼ ì¦‰ì‹œ ì €ì¥
        if not df.empty:
            partial_filename = f"partial_result_{date_str.replace('-', '')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
            save_partial_results({date_str: (df, success)}, partial_filename)
    
    # ìµœì¢… ê²°ê³¼ ì €ì¥
    final_filename = f"optimized_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
    save_partial_results(all_results, final_filename)
    
    # ê²°ê³¼ ìš”ì•½
    success_count = sum(1 for _, success in all_results.values() if success)
    total_count = len(all_results)
    
    print(f"\n=== ìµœì¢… ê²°ê³¼ ===")
    print(f"ì„±ê³µ: {success_count}/{total_count}ì¼")
    print(f"ì´ ìŠ¤ì¼€ì¤„: {sum(len(df) for df, _ in all_results.values() if not df.empty)}ê°œ")
    
    if success_count == total_count:
        print("ğŸ‰ ëª¨ë“  ë‚ ì§œì—ì„œ ì„±ê³µ!")
    elif success_count > 0:
        print("ğŸ”¶ ì¼ë¶€ ë‚ ì§œì—ì„œ ì„±ê³µ")
    else:
        print("âŒ ëª¨ë“  ë‚ ì§œì—ì„œ ì‹¤íŒ¨")

if __name__ == "__main__":
    main() 